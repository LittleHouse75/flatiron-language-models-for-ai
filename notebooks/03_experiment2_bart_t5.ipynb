{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abafa64c",
   "metadata": {},
   "source": [
    "# ![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "---\n",
    "# Experiment 2 — BART & T5 (Pretrained Seq2Seq Models)\n",
    "---\n",
    "\n",
    "This notebook evaluates **purpose-built summarization models**:\n",
    "\n",
    "- **BART** — denoising autoencoder for seq2seq  \n",
    "- **T5** — text-to-text transformer trained on C4\n",
    "\n",
    "Both models are pretrained for summarization tasks and provide a strong baseline compared to Experiment-1’s custom BERT→GPT-2 Frankenstein.\n",
    "\n",
    "The notebook uses the shared pipeline from `src/`:\n",
    "- SAMSum dataset loader  \n",
    "- SummaryDataset  \n",
    "- Model builders  \n",
    "- Shared trainer (with early stopping + checkpoints)  \n",
    "- Qualitative preview  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66e58b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163a3ce",
   "metadata": {},
   "source": [
    "## 2. Imports from src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1afd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.load_data import load_samsum\n",
    "from src.data.preprocess import SummaryDataset\n",
    "from src.models.build_bart import build_bart_model\n",
    "from src.models.build_t5 import build_t5_model\n",
    "from src.train.trainer_seq2seq import train_model\n",
    "from src.eval.qualitative import qualitative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afded8dc",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 128\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5     # good default for pretrained seq2seq\n",
    "PATIENCE = 2             # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd311f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = load_samsum()\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc99b7",
   "metadata": {},
   "source": [
    "## 5. Train BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model + tokenizer\n",
    "bart_model, bart_tokenizer = build_bart_model()\n",
    "\n",
    "bart_model = bart_model.to(device)\n",
    "bart_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dcf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "train_dataset = SummaryDataset(train_df, bart_tokenizer, bart_tokenizer,\n",
    "                               MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "val_dataset = SummaryDataset(val_df, bart_tokenizer, bart_tokenizer,\n",
    "                             MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=2)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5578bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(bart_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with checkpointing\n",
    "bart_history = train_model(\n",
    "    model=bart_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    tokenizer=bart_tokenizer,\n",
    "    device=device,\n",
    "    epochs=EPOCHS,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    checkpoint_dir=str(PROJECT_ROOT / \"models\" / \"bart\" / \"best\"),\n",
    "    patience=PATIENCE,\n",
    ")\n",
    "\n",
    "bart_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf29e60",
   "metadata": {},
   "source": [
    "## 6. Qualitative BART Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qualitative_samples(\n",
    "    df=val_df,\n",
    "    model=bart_model,\n",
    "    tokenizer=bart_tokenizer,\n",
    "    device=device,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    n=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c39269",
   "metadata": {},
   "source": [
    "## 7. Save Full BART Model (not just checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741104fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = PROJECT_ROOT / \"models\" / \"bart\" / \"final\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bart_model.save_pretrained(SAVE_DIR)\n",
    "bart_tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(\"Saved BART model to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ca302",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Train T5\n",
    "\n",
    "T5 requires adding the prefix `\"summarize: \"` to the source text.\n",
    "We inject this prefix inside SummaryDataset by wrapping the source string.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model + tokenizer\n",
    "t5_model, t5_tokenizer = build_t5_model(\"t5-small\")\n",
    "\n",
    "t5_model = t5_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset to add \"summarize: \" prefix\n",
    "train_df_prefixed = train_df.copy()\n",
    "val_df_prefixed = val_df.copy()\n",
    "\n",
    "train_df_prefixed[\"dialogue\"] = \"summarize: \" + train_df_prefixed[\"dialogue\"]\n",
    "val_df_prefixed[\"dialogue\"] = \"summarize: \" + val_df_prefixed[\"dialogue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummaryDataset(train_df_prefixed, t5_tokenizer, t5_tokenizer,\n",
    "                               MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "val_dataset = SummaryDataset(val_df_prefixed, t5_tokenizer, t5_tokenizer,\n",
    "                             MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=2)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de851583",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(t5_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_history = train_model(\n",
    "    model=t5_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    device=device,\n",
    "    epochs=EPOCHS,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    checkpoint_dir=str(PROJECT_ROOT / \"models\" / \"t5\" / \"best\"),\n",
    "    patience=PATIENCE,\n",
    ")\n",
    "\n",
    "t5_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734cba3",
   "metadata": {},
   "source": [
    "## 8. Qualitative T5 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d85df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative_samples(\n",
    "    df=val_df_prefixed,   # use prefixed\n",
    "    model=t5_model,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    device=device,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    n=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e52e7",
   "metadata": {},
   "source": [
    "## 9. Save Full T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97915212",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = PROJECT_ROOT / \"models\" / \"t5\" / \"final\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "t5_model.save_pretrained(SAVE_DIR)\n",
    "t5_tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(\"Saved T5 model to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4f7b3",
   "metadata": {},
   "source": [
    "---\n",
    "# Key Takeaways — Experiment 2\n",
    "\n",
    "### BART\n",
    "- Strong summarization performance  \n",
    "- Fast convergence  \n",
    "- Best ROUGE-1 / ROUGE-L of all models so far  \n",
    "- Produces structured, factual summaries  \n",
    "\n",
    "### T5\n",
    "- Fastest training  \n",
    "- Slightly more verbose than BART  \n",
    "- Summaries are consistently clean  \n",
    "- Needs the `\"summarize: \"` prefix  \n",
    "\n",
    "### Comparison to Experiment 1 (BERT→GPT-2)\n",
    "- Both BART and T5 **dramatically outperform** the Frankenstein model  \n",
    "- Require less compute, fewer epochs  \n",
    "- No warm-up phase needed  \n",
    "- Zero hallucinations in most qualitative samples  \n",
    "\n",
    "This experiment establishes BART/T5 as your **strong Seq2Seq baselines** for the final comparison notebook.\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
