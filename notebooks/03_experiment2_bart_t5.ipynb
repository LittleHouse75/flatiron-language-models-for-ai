{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c33560b",
   "metadata": {},
   "source": [
    "# ![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "---\n",
    "# Experiment 2 — BART & T5 (Pretrained Seq2Seq Models)\n",
    "---\n",
    "\n",
    "This notebook evaluates **purpose-built summarization models**:\n",
    "\n",
    "- **BART** — denoising autoencoder for seq2seq  \n",
    "- **T5** — text-to-text transformer trained on C4  \n",
    "\n",
    "Both are pretrained encoder–decoder models and provide strong baselines compared to Experiment 1's custom BERT→GPT-2 Frankenstein.\n",
    "\n",
    "We reuse shared components from `src/`:\n",
    "\n",
    "- SAMSum dataset loader  \n",
    "- `SummaryDataset`  \n",
    "- BART / T5 model builders  \n",
    "- Shared seq2seq trainer (early stopping + checkpoints)  \n",
    "- Qualitative preview utilities  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9059c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ca81e",
   "metadata": {},
   "source": [
    "## 2. Imports from src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.load_data import load_samsum\n",
    "from src.data.preprocess import SummaryDataset\n",
    "from src.models.build_bart import build_bart_model\n",
    "from src.models.build_t5 import build_t5_model\n",
    "from src.train.trainer_seq2seq import train_model\n",
    "from src.eval.qualitative import qualitative_samples\n",
    "from src.utils.logging import heading, line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986eb1d",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAINING FLAGS - Set these to control what runs\n",
    "# =============================================================================\n",
    "RUN_TRAINING_BART = True   # Set False to load BART from checkpoint\n",
    "RUN_TRAINING_T5 = True     # Set False to load T5 from checkpoint\n",
    "\n",
    "# =============================================================================\n",
    "# HYPERPARAMETERS\n",
    "# =============================================================================\n",
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 128\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5     # good default for pretrained seq2seq\n",
    "PATIENCE = 2             # early stopping\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "\n",
    "# =============================================================================\n",
    "# PATHS\n",
    "# =============================================================================\n",
    "BART_CKPT_DIR = PROJECT_ROOT / \"models\" / \"bart\" / \"best\"\n",
    "BART_HIST_PATH = PROJECT_ROOT / \"models\" / \"bart\" / \"history.csv\"\n",
    "SAVE_DIR_BART = PROJECT_ROOT / \"models\" / \"bart\" / \"final\"\n",
    "\n",
    "T5_CKPT_DIR = PROJECT_ROOT / \"models\" / \"t5\" / \"best\"\n",
    "T5_HIST_PATH = PROJECT_ROOT / \"models\" / \"t5\" / \"history.csv\"\n",
    "SAVE_DIR_T5 = PROJECT_ROOT / \"models\" / \"t5\" / \"final\"\n",
    "\n",
    "T5_PREFIX_DEFAULT = \"summarize: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adfd38",
   "metadata": {},
   "source": [
    "## 4. Load SAMSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ad2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = load_samsum()\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598da568",
   "metadata": {},
   "source": [
    "---\n",
    "# BART\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e383756",
   "metadata": {},
   "source": [
    "## 5. Build or Load BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, GenerationConfig\n",
    "\n",
    "if RUN_TRAINING_BART:\n",
    "    # Build fresh model for training\n",
    "    bart_model, bart_tokenizer = build_bart_model()\n",
    "    bart_model = bart_model.to(device)\n",
    "    \n",
    "    # Configure generation to respect our target length\n",
    "    gen_cfg = bart_model.generation_config\n",
    "    gen_cfg.max_length = MAX_TARGET_LEN\n",
    "    gen_cfg.min_length = 5\n",
    "    gen_cfg.no_repeat_ngram_size = 3\n",
    "    gen_cfg.length_penalty = 2.0\n",
    "    gen_cfg.num_beams = 4\n",
    "    \n",
    "    print(\"Built fresh BART model for training.\")\n",
    "    \n",
    "else:\n",
    "    # Load from checkpoint\n",
    "    print(\"Loading BART from checkpoint...\")\n",
    "    \n",
    "    # Try to load from best checkpoint first, fall back to final\n",
    "    if BART_CKPT_DIR.exists():\n",
    "        load_dir = BART_CKPT_DIR\n",
    "    elif SAVE_DIR_BART.exists():\n",
    "        load_dir = SAVE_DIR_BART\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No saved BART model found.\\n\"\n",
    "            f\"Checked: {BART_CKPT_DIR}\\n\"\n",
    "            f\"Checked: {SAVE_DIR_BART}\\n\"\n",
    "            f\"Set RUN_TRAINING_BART=True to train a new model.\"\n",
    "        )\n",
    "    \n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(load_dir).to(device)\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(load_dir)\n",
    "    \n",
    "    # ADD THIS BLOCK:\n",
    "    # Load training metadata if available\n",
    "    metadata_path = load_dir / \"training_metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            bart_metadata = json.load(f)\n",
    "        print(f\"  Training metadata:\")\n",
    "        print(f\"    Best epoch: {bart_metadata.get('best_epoch')}\")\n",
    "        print(f\"    Weights from epoch: {bart_metadata.get('weights_epoch')}\")\n",
    "        if bart_metadata.get('early_stopped'):\n",
    "            print(f\"    (Training stopped early)\")\n",
    "    else:\n",
    "        print(\"  No training metadata found.\")\n",
    "    \n",
    "    # Load generation config if available\n",
    "    try:\n",
    "        bart_model.generation_config = GenerationConfig.from_pretrained(load_dir)\n",
    "        print(f\"Loaded BART model and generation config from: {load_dir}\")\n",
    "    except Exception:\n",
    "        print(f\"Loaded BART model from: {load_dir}\")\n",
    "        print(\"No saved generation config found. Setting defaults.\")\n",
    "        gen_cfg = bart_model.generation_config\n",
    "        gen_cfg.max_length = MAX_TARGET_LEN\n",
    "        gen_cfg.min_length = 5\n",
    "        gen_cfg.no_repeat_ngram_size = 3\n",
    "        gen_cfg.length_penalty = 2.0\n",
    "        gen_cfg.num_beams = 4\n",
    "\n",
    "bart_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba314d1",
   "metadata": {},
   "source": [
    "## 6. Prepare BART Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c486541",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"BART: Prepare datasets\")\n",
    "\n",
    "bart_train_dataset = SummaryDataset(\n",
    "    train_df,\n",
    "    encoder_tokenizer=bart_tokenizer,\n",
    "    decoder_tokenizer=bart_tokenizer,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=\"\",  # No prefix for BART\n",
    ")\n",
    "\n",
    "bart_val_dataset = SummaryDataset(\n",
    "    val_df,\n",
    "    encoder_tokenizer=bart_tokenizer,\n",
    "    decoder_tokenizer=bart_tokenizer,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=\"\",  # No prefix for BART\n",
    ")\n",
    "\n",
    "bart_train_loader = DataLoader(\n",
    "    bart_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "bart_val_loader = DataLoader(\n",
    "    bart_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(bart_train_loader)}, Val batches: {len(bart_val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb6abe",
   "metadata": {},
   "source": [
    "## 7. Train BART (or Load History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING_BART:\n",
    "    heading(\"BART: Training\")\n",
    "    \n",
    "    bart_optimizer = optim.AdamW(bart_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    bart_history = train_model(\n",
    "        model=bart_model,\n",
    "        train_loader=bart_train_loader,\n",
    "        val_loader=bart_val_loader,\n",
    "        optimizer=bart_optimizer,\n",
    "        tokenizer=bart_tokenizer,\n",
    "        device=device,\n",
    "        epochs=EPOCHS,\n",
    "        max_target_len=MAX_TARGET_LEN,\n",
    "        checkpoint_dir=str(BART_CKPT_DIR),\n",
    "        patience=PATIENCE,\n",
    "        grad_accum_steps=GRAD_ACCUM_STEPS,\n",
    "        use_amp=True, \n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    BART_HIST_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    bart_history.to_csv(BART_HIST_PATH, index=False)\n",
    "    print(f\"Saved BART training history to: {BART_HIST_PATH}\")\n",
    "    \n",
    "else:\n",
    "    heading(\"BART: Loading training history\")\n",
    "    \n",
    "    if BART_HIST_PATH.exists():\n",
    "        bart_history = pd.read_csv(BART_HIST_PATH)\n",
    "        print(f\"Loaded BART training history from: {BART_HIST_PATH}\")\n",
    "    else:\n",
    "        bart_history = None\n",
    "        print(\"No training history found for BART.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bart_history is not None:\n",
    "    display(bart_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598bb11",
   "metadata": {},
   "source": [
    "## 8. BART Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dec1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bart_history is not None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0].plot(bart_history[\"epoch\"], bart_history[\"train_loss\"], label=\"Train Loss\")\n",
    "    axes[0].plot(bart_history[\"epoch\"], bart_history[\"val_loss\"], label=\"Val Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"BART — Loss Curves\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROUGE curves\n",
    "    axes[1].plot(bart_history[\"epoch\"], bart_history[\"rouge1\"], label=\"ROUGE-1\")\n",
    "    axes[1].plot(bart_history[\"epoch\"], bart_history[\"rouge2\"], label=\"ROUGE-2\")\n",
    "    axes[1].plot(bart_history[\"epoch\"], bart_history[\"rougeL\"], label=\"ROUGE-L\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"ROUGE Score\")\n",
    "    axes[1].set_title(\"BART — ROUGE Scores\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e99d6",
   "metadata": {},
   "source": [
    "## 9. Qualitative BART Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c66913",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"BART: Qualitative samples\")\n",
    "\n",
    "qualitative_samples(\n",
    "    df=val_df,\n",
    "    model=bart_model,\n",
    "    encoder_tokenizer=bart_tokenizer,\n",
    "    decoder_tokenizer=bart_tokenizer,\n",
    "    device=device,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=\"\",  # No prefix for BART\n",
    "    n=5,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49f90b",
   "metadata": {},
   "source": [
    "## 10. Save Full BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING_BART:\n",
    "    heading(\"BART: Saving final model\")\n",
    "    \n",
    "    SAVE_DIR_BART.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    bart_model.save_pretrained(SAVE_DIR_BART)\n",
    "    bart_tokenizer.save_pretrained(SAVE_DIR_BART)\n",
    "    \n",
    "    # Also save generation config\n",
    "    if hasattr(bart_model, 'generation_config'):\n",
    "        bart_model.generation_config.save_pretrained(SAVE_DIR_BART)\n",
    "    \n",
    "    print(f\"Saved BART model to: {SAVE_DIR_BART}\")\n",
    "else:\n",
    "    print(\"Skipping BART save (model was loaded from checkpoint).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282395d",
   "metadata": {},
   "source": [
    "---\n",
    "# T5\n",
    "---\n",
    "\n",
    "T5 is a text-to-text model. For summarization it expects a task prefix like:\n",
    "\n",
    "`\"summarize: {dialogue_text}\"`\n",
    "\n",
    "We apply this prefix to the **source** text only; targets stay as the human summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9845b",
   "metadata": {},
   "source": [
    "## 11. Build or Load T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0164df",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"T5: Build model and tokenizer\")\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, GenerationConfig\n",
    "\n",
    "if RUN_TRAINING_T5:\n",
    "    # Build fresh model for training\n",
    "    t5_model, t5_tokenizer = build_t5_model(\"t5-small\")\n",
    "    t5_model = t5_model.to(device)\n",
    "    \n",
    "    # Configure generation\n",
    "    gen_cfg_t5 = t5_model.generation_config\n",
    "    gen_cfg_t5.max_length = MAX_TARGET_LEN\n",
    "    gen_cfg_t5.min_length = 5\n",
    "    gen_cfg_t5.no_repeat_ngram_size = 3\n",
    "    gen_cfg_t5.length_penalty = 2.0\n",
    "    gen_cfg_t5.num_beams = 4\n",
    "    \n",
    "    # Use the default prefix for new training\n",
    "    t5_prefix_used = T5_PREFIX_DEFAULT\n",
    "    print(f\"Built fresh T5 model for training with prefix: '{t5_prefix_used}'\")\n",
    "    \n",
    "else:\n",
    "    # Load from checkpoint\n",
    "    print(\"Loading T5 from checkpoint...\")\n",
    "    \n",
    "    # Try to load from best checkpoint first, fall back to final\n",
    "    if T5_CKPT_DIR.exists():\n",
    "        load_dir = T5_CKPT_DIR\n",
    "    elif SAVE_DIR_T5.exists():\n",
    "        load_dir = SAVE_DIR_T5\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No saved T5 model found.\\n\"\n",
    "            f\"Checked: {T5_CKPT_DIR}\\n\"\n",
    "            f\"Checked: {SAVE_DIR_T5}\\n\"\n",
    "            f\"Set RUN_TRAINING_T5=True to train a new model.\"\n",
    "        )\n",
    "    \n",
    "    t5_model = T5ForConditionalGeneration.from_pretrained(load_dir).to(device)\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(load_dir)\n",
    "    \n",
    "    # CRITICAL: Load the prefix that was used during training\n",
    "    prefix_path = load_dir / \"source_prefix.txt\"\n",
    "    if prefix_path.exists():\n",
    "        t5_prefix_used = prefix_path.read_text().strip()\n",
    "        print(f\"  ✓ Loaded source prefix from checkpoint: '{t5_prefix_used}'\")\n",
    "        \n",
    "        # Warn if it differs from the default (just for user awareness)\n",
    "        if t5_prefix_used != T5_PREFIX_DEFAULT:\n",
    "            print(f\"    (Note: differs from default '{T5_PREFIX_DEFAULT}')\")\n",
    "    else:\n",
    "        # This is a PROBLEM - we don't know what prefix was used!\n",
    "        print(f\"  ⚠️  WARNING: No source_prefix.txt found in checkpoint!\")\n",
    "        print(f\"      The model may have been trained with a different prefix.\")\n",
    "        print(f\"      Assuming default prefix: '{T5_PREFIX_DEFAULT}'\")\n",
    "        print(f\"      If results are poor, check what prefix was used during training.\")\n",
    "        t5_prefix_used = T5_PREFIX_DEFAULT\n",
    "    \n",
    "    # Load generation config if available\n",
    "    try:\n",
    "        t5_model.generation_config = GenerationConfig.from_pretrained(load_dir)\n",
    "        print(f\"  ✓ Loaded generation config from checkpoint\")\n",
    "    except Exception:\n",
    "        print(f\"  ⚠️  No saved generation config found. Setting defaults.\")\n",
    "        gen_cfg_t5 = t5_model.generation_config\n",
    "        gen_cfg_t5.max_length = MAX_TARGET_LEN\n",
    "        gen_cfg_t5.min_length = 5\n",
    "        gen_cfg_t5.no_repeat_ngram_size = 3\n",
    "        gen_cfg_t5.length_penalty = 2.0\n",
    "        gen_cfg_t5.num_beams = 4\n",
    "\n",
    "    metadata_path = load_dir / \"training_metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            t5_metadata = json.load(f)\n",
    "        print(f\"  ✓ Training metadata:\")\n",
    "        print(f\"      Best epoch: {t5_metadata.get('best_epoch')}\")\n",
    "        print(f\"      Weights from epoch: {t5_metadata.get('weights_epoch')}\")\n",
    "        if t5_metadata.get('early_stopped'):\n",
    "            print(f\"      (Training stopped early)\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  No training metadata found (older checkpoint format)\")\n",
    "\n",
    "t5_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33842c09",
   "metadata": {},
   "source": [
    "## 12. Prepare T5 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"T5: Prepare datasets (with 'summarize:' prefix)\")\n",
    "\n",
    "t5_train_dataset = SummaryDataset(\n",
    "    train_df,\n",
    "    encoder_tokenizer=t5_tokenizer,\n",
    "    decoder_tokenizer=t5_tokenizer,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=t5_prefix_used,\n",
    ")\n",
    "\n",
    "t5_val_dataset = SummaryDataset(\n",
    "    val_df,\n",
    "    encoder_tokenizer=t5_tokenizer,\n",
    "    decoder_tokenizer=t5_tokenizer,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=t5_prefix_used,\n",
    ")\n",
    "\n",
    "t5_train_loader = DataLoader(\n",
    "    t5_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "t5_val_loader = DataLoader(\n",
    "    t5_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(t5_train_loader)}, Val batches: {len(t5_val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f34f2",
   "metadata": {},
   "source": [
    "## 13. Train T5 (or Load History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING_T5:\n",
    "    heading(\"T5: Training\")\n",
    "    \n",
    "    # Ensure checkpoint directory exists\n",
    "    T5_CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # IMPORTANT: Save prefix BEFORE training starts\n",
    "    # This ensures it's always present if a checkpoint exists, even if\n",
    "    # training is interrupted or crashes partway through.\n",
    "    # =========================================================================\n",
    "    prefix_path_ckpt = T5_CKPT_DIR / \"source_prefix.txt\"\n",
    "    prefix_path_ckpt.write_text(t5_prefix_used)\n",
    "    print(f\"Saved source prefix to: {prefix_path_ckpt}\")\n",
    "    print(f\"Using source prefix: '{t5_prefix_used}'\")\n",
    "    \n",
    "    t5_optimizer = optim.AdamW(t5_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    t5_history = train_model(\n",
    "        model=t5_model,\n",
    "        train_loader=t5_train_loader,\n",
    "        val_loader=t5_val_loader,\n",
    "        optimizer=t5_optimizer,\n",
    "        tokenizer=t5_tokenizer,\n",
    "        device=device,\n",
    "        epochs=EPOCHS,\n",
    "        max_target_len=MAX_TARGET_LEN,\n",
    "        checkpoint_dir=str(T5_CKPT_DIR),\n",
    "        patience=PATIENCE,\n",
    "        grad_accum_steps=GRAD_ACCUM_STEPS,\n",
    "        use_amp=True, \n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    T5_HIST_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    t5_history.to_csv(T5_HIST_PATH, index=False)\n",
    "    print(f\"Saved T5 training history to: {T5_HIST_PATH}\")\n",
    "    \n",
    "else:\n",
    "    heading(\"T5: Loading training history\")\n",
    "    \n",
    "    if T5_HIST_PATH.exists():\n",
    "        t5_history = pd.read_csv(T5_HIST_PATH)\n",
    "        print(f\"Loaded T5 training history from: {T5_HIST_PATH}\")\n",
    "    else:\n",
    "        t5_history = None\n",
    "        print(\"No training history found for T5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if t5_history is not None:\n",
    "    display(t5_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2be05",
   "metadata": {},
   "source": [
    "## 14. T5 Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if t5_history is not None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0].plot(t5_history[\"epoch\"], t5_history[\"train_loss\"], label=\"Train Loss\")\n",
    "    axes[0].plot(t5_history[\"epoch\"], t5_history[\"val_loss\"], label=\"Val Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"T5 — Loss Curves\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROUGE curves\n",
    "    axes[1].plot(t5_history[\"epoch\"], t5_history[\"rouge1\"], label=\"ROUGE-1\")\n",
    "    axes[1].plot(t5_history[\"epoch\"], t5_history[\"rouge2\"], label=\"ROUGE-2\")\n",
    "    axes[1].plot(t5_history[\"epoch\"], t5_history[\"rougeL\"], label=\"ROUGE-L\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"ROUGE Score\")\n",
    "    axes[1].set_title(\"T5 — ROUGE Scores\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a69997",
   "metadata": {},
   "source": [
    "## 15. Qualitative T5 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c95445",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"T5: Qualitative samples\")\n",
    "\n",
    "qualitative_samples(\n",
    "    df=val_df,\n",
    "    model=t5_model,\n",
    "    encoder_tokenizer=t5_tokenizer,\n",
    "    decoder_tokenizer=t5_tokenizer,\n",
    "    device=device,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=t5_prefix_used,\n",
    "    n=5,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24e595",
   "metadata": {},
   "source": [
    "## 16. Save Full T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING_T5:\n",
    "    heading(\"T5: Saving final model\")\n",
    "    \n",
    "    SAVE_DIR_T5.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    t5_model.save_pretrained(SAVE_DIR_T5)\n",
    "    t5_tokenizer.save_pretrained(SAVE_DIR_T5)\n",
    "    \n",
    "    # Save generation config\n",
    "    if hasattr(t5_model, 'generation_config'):\n",
    "        t5_model.generation_config.save_pretrained(SAVE_DIR_T5)\n",
    "    \n",
    "    # CRITICAL: Save the prefix used during training\n",
    "    # Without this, future users won't know how to use the model!\n",
    "    prefix_path = SAVE_DIR_T5 / \"source_prefix.txt\"\n",
    "    prefix_path.write_text(t5_prefix_used)\n",
    "    \n",
    "    # Verify the save worked\n",
    "    saved_prefix = prefix_path.read_text().strip()\n",
    "    if saved_prefix != t5_prefix_used:\n",
    "        raise RuntimeError(f\"Prefix save verification failed! Expected '{t5_prefix_used}', got '{saved_prefix}'\")\n",
    "    \n",
    "    print(f\"✓ Saved T5 model to: {SAVE_DIR_T5}\")\n",
    "    print(f\"✓ Saved source prefix: '{t5_prefix_used}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING_T5:\n",
    "    heading(\"T5: Creating usage documentation\")\n",
    "    \n",
    "    # Use an f-string so the actual prefix is included in the documentation\n",
    "    readme_content = f\"\"\"# T5 Dialogue Summarization Model\n",
    "\n",
    "## Usage\n",
    "\n",
    "This model was fine-tuned for dialogue summarization. \n",
    "\n",
    "**IMPORTANT:** You must prepend `\"{t5_prefix_used}\"` to your input text!\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"path/to/this/model\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"path/to/this/model\")\n",
    "\n",
    "dialogue = \\\"\\\"\\\"\n",
    "Hannah: Hey, do you have Betty's number?\n",
    "Amanda: Lemme check\n",
    "Amanda: Sorry, I don't\n",
    "Hannah: Ok, thanks\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "# IMPORTANT: Add the prefix!\n",
    "input_text = \"{t5_prefix_used}\" + dialogue\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(**inputs, max_length=128)\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(summary)\n",
    "```\n",
    "\n",
    "## Training Details\n",
    "\n",
    "- Base model: t5-small\n",
    "- Dataset: SAMSum\n",
    "- Source prefix: `\"{t5_prefix_used}\"`\n",
    "- Max source length: {MAX_SOURCE_LEN}\n",
    "- Max target length: {MAX_TARGET_LEN}\n",
    "\n",
    "## Files in this directory\n",
    "\n",
    "- `pytorch_model.bin` or `model.safetensors`: Model weights\n",
    "- `config.json`: Model configuration\n",
    "- `tokenizer_config.json`, `spiece.model`, etc.: Tokenizer files\n",
    "- `generation_config.json`: Generation settings\n",
    "- `source_prefix.txt`: The prefix used during training (for programmatic access)\n",
    "- `README.md`: This file\n",
    "\"\"\"\n",
    "    \n",
    "    readme_path = SAVE_DIR_T5 / \"README.md\"\n",
    "    readme_path.write_text(readme_content)\n",
    "    print(f\"Created usage documentation at: {readme_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039c376",
   "metadata": {},
   "source": [
    "---\n",
    "# 17. Side-by-Side Comparison\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"Side-by-Side: BART vs T5\")\n",
    "\n",
    "# Compare on the same samples\n",
    "comparison_samples = val_df.sample(3, random_state=42)\n",
    "\n",
    "for idx, row in comparison_samples.iterrows():\n",
    "    dialog = row[\"dialogue\"]\n",
    "    ref = row[\"summary\"]\n",
    "    \n",
    "    # Generate BART summary\n",
    "    from src.eval.qualitative import generate_summary\n",
    "    \n",
    "    bart_pred = generate_summary(\n",
    "        model=bart_model,\n",
    "        encoder_tokenizer=bart_tokenizer,\n",
    "        decoder_tokenizer=bart_tokenizer,\n",
    "        text=dialog,\n",
    "        device=device,\n",
    "        max_source_len=MAX_SOURCE_LEN,\n",
    "        max_target_len=MAX_TARGET_LEN,\n",
    "        source_prefix=\"\",\n",
    "    )\n",
    "    \n",
    "    t5_pred = generate_summary(\n",
    "        model=t5_model,\n",
    "        encoder_tokenizer=t5_tokenizer,\n",
    "        decoder_tokenizer=t5_tokenizer,\n",
    "        text=dialog,\n",
    "        device=device,\n",
    "        max_source_len=MAX_SOURCE_LEN,\n",
    "        max_target_len=MAX_TARGET_LEN,\n",
    "        source_prefix=t5_prefix_used,\n",
    "    )\n",
    "    \n",
    "    print(f\"=== Example {idx} ===\")\n",
    "    print(f\"DIALOGUE: {dialog[:300].replace(chr(10), ' | ')}...\")\n",
    "    print(f\"HUMAN:    {ref}\")\n",
    "    print(f\"BART:     {bart_pred}\")\n",
    "    print(f\"T5:       {t5_pred}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bdcd1",
   "metadata": {},
   "source": [
    "---\n",
    "# 18. Summary Comparison Table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc564b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading(\"Final ROUGE Comparison\")\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "def get_best_epoch_row(history_df):\n",
    "    \"\"\"\n",
    "    Get the row corresponding to the best epoch.\n",
    "    Uses the 'improved' column if available, otherwise falls back to finding min val_loss.\n",
    "    \"\"\"\n",
    "    # The best epoch is the LAST one that improved (since each improvement becomes the new best)\n",
    "    if \"improved\" in history_df.columns:\n",
    "        improved_rows = history_df[history_df[\"improved\"] == True]\n",
    "        if len(improved_rows) > 0:\n",
    "            return improved_rows.iloc[-1]  # Last improvement = final best\n",
    "    \n",
    "    # Fallback: find the row with minimum validation loss\n",
    "    return history_df.loc[history_df[\"val_loss\"].idxmin()]\n",
    "\n",
    "\n",
    "if bart_history is not None:\n",
    "    best_bart = get_best_epoch_row(bart_history)\n",
    "    summary_data.append({\n",
    "        \"Model\": \"BART\",\n",
    "        \"Best Epoch\": int(best_bart[\"epoch\"]),\n",
    "        \"Val Loss\": f\"{best_bart['val_loss']:.4f}\",\n",
    "        \"ROUGE-1\": f\"{best_bart['rouge1']:.4f}\",\n",
    "        \"ROUGE-2\": f\"{best_bart['rouge2']:.4f}\",\n",
    "        \"ROUGE-L\": f\"{best_bart['rougeL']:.4f}\",\n",
    "    })\n",
    "\n",
    "if t5_history is not None:\n",
    "    best_t5 = get_best_epoch_row(t5_history)\n",
    "    summary_data.append({\n",
    "        \"Model\": \"T5\",\n",
    "        \"Best Epoch\": int(best_t5[\"epoch\"]),\n",
    "        \"Val Loss\": f\"{best_t5['val_loss']:.4f}\",\n",
    "        \"ROUGE-1\": f\"{best_t5['rouge1']:.4f}\",\n",
    "        \"ROUGE-2\": f\"{best_t5['rouge2']:.4f}\",\n",
    "        \"ROUGE-L\": f\"{best_t5['rougeL']:.4f}\",\n",
    "    })\n",
    "\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)\n",
    "else:\n",
    "    print(\"No training history available to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f0de9",
   "metadata": {},
   "source": [
    "---\n",
    "# 19. Key Takeaways — Experiment 2\n",
    "\n",
    "*Fill this in after training completes:*\n",
    "\n",
    "- Which model achieved better ROUGE scores?\n",
    "- How many epochs did each model need before early stopping?\n",
    "- Qualitative differences in summary style?\n",
    "- Training time comparison?\n",
    "- Any notable failure cases?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
