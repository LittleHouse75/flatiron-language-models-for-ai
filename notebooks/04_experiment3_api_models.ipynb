{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# ![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "---\n",
    "# Experiment 3 ‚Äî Frontier LLMs via OpenRouter API\n",
    "### Zero-Shot Dialogue Summarization with GPT, Claude, Gemini, and More\n",
    "---\n",
    "\n",
    "This experiment completes our three-part investigation by testing **frontier large language models** on dialogue summarization‚Äîno training required, just inference via API.\n",
    "\n",
    "**The Question**\n",
    "\n",
    "Experiments 1 and 2 showed what's possible with fine-tuned local models: the custom DistilBERT‚ÜíDistilGPT2 architecture reached ROUGE-L 30.29, while purpose-built BART achieved 42.13. But what happens if we skip training entirely and just *ask* the most capable models in the world to summarize conversations?\n",
    "\n",
    "This is the approach many teams try first in practice. Before investing in custom fine-tuning infrastructure, it's natural to wonder: *\"Can we just prompt GPT/Claude/Gemini and call it a day?\"*\n",
    "\n",
    "**The Models**\n",
    "\n",
    "We evaluate five frontier models via the OpenRouter API, selected to span the major providers and price points:\n",
    "\n",
    "| Model | Provider | Parameters | Context | Input Cost | Output Cost |\n",
    "|-------|----------|------------|---------|------------|-------------|\n",
    "| **GPT-5 Mini** | OpenAI | Compact | 400K | $0.25/M | $2.00/M |\n",
    "| **Gemini 2.5 Flash** | Google | Workhorse | 1.05M | $0.30/M | $2.50/M |\n",
    "| **Claude 4.5 Haiku** | Anthropic | Fast | 200K | $1.00/M | $5.00/M |\n",
    "| **Qwen 2.5 72B** | Alibaba | 72B active | 33K | $0.07/M | $0.26/M |\n",
    "| **Kimi K2** | Moonshot AI | 1T total (32B active) | 262K | $0.39/M | $1.90/M |\n",
    "\n",
    "This selection includes:\n",
    "- **The \"big three\" frontier labs:** OpenAI, Anthropic, and Google\n",
    "- **Two strong Chinese models:** Qwen (open-weight) and Kimi K2 (trillion-parameter MoE)\n",
    "- **A 70√ó cost spread:** From Qwen at $0.07/M input to Claude at $1.00/M input\n",
    "\n",
    "The diversity lets us explore whether price correlates with summarization quality.\n",
    "\n",
    "**Why This Matters**\n",
    "\n",
    "Zero-shot API models offer compelling advantages:\n",
    "- **No training required** ‚Äî deploy immediately\n",
    "- **No GPU infrastructure** ‚Äî runs anywhere with internet\n",
    "- **Always up-to-date** ‚Äî models improve without your intervention\n",
    "- **Massive scale** ‚Äî billions of parameters, trillions of training tokens\n",
    "\n",
    "But they also have costs:\n",
    "- **Per-query pricing** ‚Äî every summary costs money\n",
    "- **Latency variability** ‚Äî depends on provider load and geography\n",
    "- **Privacy concerns** ‚Äî data leaves your infrastructure\n",
    "- **Less control** ‚Äî you can't fine-tune for your domain\n",
    "\n",
    "This experiment measures whether the \"just use GPT\" approach actually works for dialogue summarization, and how it compares to the fine-tuned models from Experiments 1 and 2.\n",
    "\n",
    "**What This Notebook Covers**\n",
    "\n",
    "1. Configuration and API client setup\n",
    "2. Loading the SAMSum test set (same 819 examples as Experiments 1 & 2)\n",
    "3. Zero-shot prompt construction\n",
    "4. Running API calls with caching and retry logic\n",
    "5. ROUGE evaluation on the held-out test set\n",
    "6. Latency analysis and qualitative examples\n",
    "7. Initial comparison to fine-tuned baselines\n",
    "\n",
    "The detailed cross-experiment analysis will follow in the final comparison notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/timnevits/projects/flatiron-language-models-for-ai\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Mute common warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Project root for imports\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "All hyperparameters and paths in one place for easy modification.\n",
    "\n",
    "**Important:** \n",
    "- Set `RUN_API_CALLS` to `False` to load cached results instead of making new API calls\n",
    "- Set `EVALUATION_MODE` to `\"full\"` for final results on the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "  Evaluation mode: full\n",
      "  Sample size: FULL test set\n",
      "  Max target length: 64 (aligned with Experiments 1 & 2)\n",
      "  Models configured: 5\n",
      "  Output directory: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# API CALL FLAGS\n",
    "# =============================================================================\n",
    "\n",
    "# Master switch: Set False to load ALL results from cache (no API calls).\n",
    "# Useful for re-running analysis without incurring API costs or waiting for\n",
    "# network requests. Results are cached per-model in CACHE_DIR.\n",
    "RUN_API_CALLS = True\n",
    "\n",
    "# Per-model control: Set individual models to False to skip them.\n",
    "# Only matters if RUN_API_CALLS = True. Useful for debugging a single model\n",
    "# or re-running only models that failed in a previous run.\n",
    "MODELS_TO_RUN = {\n",
    "    \"gpt5_mini\":                True,\n",
    "    \"gemini_25_flash\":          True,\n",
    "    \"claude_45_haiku\":          True,\n",
    "    \"qwen25_72b\":               True,\n",
    "    \"kimi_k2\":                  True,\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION MODE\n",
    "# =============================================================================\n",
    "\n",
    "# \"test\": Use a small sample (fast, cheap) for development and debugging.\n",
    "#         Helps verify the pipeline works before committing to full API costs.\n",
    "# \"full\": Use entire test set (819 examples) for final results.\n",
    "#         Required for fair comparison with Experiments 1 & 2, which also\n",
    "#         evaluated on the complete SAMSum test split.\n",
    "EVALUATION_MODE = \"full\"  # Change to \"full\" for final evaluation\n",
    "\n",
    "# How many samples to use in \"test\" mode (ignored in \"full\" mode).\n",
    "# 10 samples is enough to verify API connectivity, prompt formatting, and\n",
    "# basic output quality without significant cost or time investment.\n",
    "TEST_MODE_SAMPLES = 10\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATION PARAMETERS\n",
    "# (Aligned with Experiments 1 & 2 for fair comparison)\n",
    "# =============================================================================\n",
    "\n",
    "# Max tokens for model responses. Set to 64 to match the max_target_len used\n",
    "# in Experiments 1 & 2. SAMSum summaries average ~20 words (~30 tokens), so\n",
    "# 64 provides headroom while preventing runaway generation. Note that API\n",
    "# models may produce shorter outputs if they finish the summary naturally.\n",
    "MAX_TARGET_LEN = 64\n",
    "\n",
    "# Low temperature for consistent, deterministic outputs. Higher values (0.7+)\n",
    "# would produce more varied summaries, but we want reproducible results that\n",
    "# can be fairly compared across runs. 0.2 keeps outputs focused while allowing\n",
    "# minor variation to avoid pure greedy decoding artifacts.\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# Documented for reference: Experiments 1 & 2 used beam search with 4 beams.\n",
    "# API models use different decoding strategies (typically nucleus sampling),\n",
    "# so this parameter doesn't apply directly, but we note it for transparency.\n",
    "NUM_BEAMS = 4\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL DEFINITIONS\n",
    "# =============================================================================\n",
    "# We evaluate five frontier models spanning major providers and price points.\n",
    "#\n",
    "# Selection criteria:\n",
    "# - Major frontier labs: OpenAI, Google, Anthropic (the \"big three\")\n",
    "# - Open-source alternatives: Qwen (Alibaba), Kimi K2 (Moonshot AI)\n",
    "# - Fast/efficient variants: Mini, Flash, Haiku (not full-size flagships)\n",
    "# - Price diversity: From $0.07/M (Qwen) to $1.00/M (Claude) input tokens\n",
    "#\n",
    "# Pricing as of December 2025 (via OpenRouter):\n",
    "# - GPT-5 Mini:        $0.25/M input, $2.00/M output (400K context)\n",
    "# - Gemini 2.5 Flash:  $0.30/M input, $2.50/M output (1.05M context)\n",
    "# - Claude 4.5 Haiku:  $1.00/M input, $5.00/M output (200K context)\n",
    "# - Qwen 2.5 72B:      $0.07/M input, $0.26/M output (33K context)\n",
    "# - Kimi K2:           $0.39/M input, $1.90/M output (262K context)\n",
    "\n",
    "OPENROUTER_MODELS = {\n",
    "    # OpenAI GPT-5 Mini: Compact version of GPT-5 for lighter reasoning tasks.\n",
    "    # Successor to o4-mini. Good balance of capability and cost.\n",
    "    # 400K context, $0.25/M input, $2.00/M output\n",
    "    \"gpt5_mini\":       \"openai/gpt-5-mini\",\n",
    "\n",
    "    # Google Gemini 2.5 Flash: Speed-optimized workhorse model with built-in\n",
    "    # \"thinking\" capabilities. Designed for advanced reasoning and coding.\n",
    "    # 1.05M context (largest), $0.30/M input, $2.50/M output\n",
    "    \"gemini_25_flash\": \"google/gemini-2.5-flash\",\n",
    "\n",
    "    # Anthropic Claude 4.5 Haiku: Fastest Claude model, near-frontier quality\n",
    "    # at lower latency. Extended thinking support, strong at coding (73% SWE-bench).\n",
    "    # 200K context, $1.00/M input (most expensive), $5.00/M output\n",
    "    \"claude_45_haiku\": \"anthropic/claude-haiku-4.5\",\n",
    "\n",
    "    # Qwen 2.5 72B Instruct: Alibaba's open-weight model. 72B parameters,\n",
    "    # strong multilingual support (29 languages), improved coding/math.\n",
    "    # 33K context (smallest), $0.07/M input (cheapest), $0.26/M output\n",
    "    \"qwen25_72b\":      \"qwen/qwen-2.5-72b-instruct\",\n",
    "\n",
    "    # Moonshot Kimi K2: 1 trillion total parameters (32B active per forward).\n",
    "    # MoE architecture, optimized for agentic/tool-use tasks.\n",
    "    # 262K context, $0.39/M input, $1.90/M output\n",
    "    \"kimi_k2\":         \"moonshotai/kimi-k2-0905\",\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PATHS\n",
    "# =============================================================================\n",
    "# All artifacts for this experiment live under models/api-frontier.\n",
    "# Separating from Experiments 1 & 2 keeps results organized and allows\n",
    "# independent re-runs without overwriting fine-tuned model outputs.\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"models\" / \"api-frontier\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cache directory for API responses. Each model's predictions are saved\n",
    "# separately, allowing partial re-runs if some models fail or need updates.\n",
    "# This is critical for cost control‚Äîwe don't want to re-run successful models.\n",
    "CACHE_DIR = OUTPUT_DIR / \"cache\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Test results path matches the format from Experiments 1 & 2 for easy\n",
    "# consolidation in the final comparison notebook.\n",
    "TEST_RESULTS_PATH = OUTPUT_DIR / \"test_results.csv\"\n",
    "\n",
    "# Individual model predictions saved here for qualitative analysis and\n",
    "# debugging. Format matches Experiments 1 & 2 (dialogue, summary, prediction).\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"  Evaluation mode: {EVALUATION_MODE}\")\n",
    "if EVALUATION_MODE == \"test\":\n",
    "    print(f\"  Sample size: {TEST_MODE_SAMPLES} examples\")\n",
    "else:\n",
    "    print(f\"  Sample size: FULL test set\")\n",
    "print(f\"  Max target length: {MAX_TARGET_LEN} (aligned with Experiments 1 & 2)\")\n",
    "print(f\"  Models configured: {len(OPENROUTER_MODELS)}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf633f",
   "metadata": {},
   "source": [
    "### Model Selection Rationale\n",
    "\n",
    "We chose these five models to answer specific questions:\n",
    "\n",
    "1. **Do the \"big three\" labs (OpenAI, Google, Anthropic) outperform each other?**\n",
    "   - GPT-5 Mini, Gemini 2.5 Flash, and Claude 4.5 Haiku represent each lab's fast/efficient offering\n",
    "\n",
    "2. **Can open-weight models compete with proprietary APIs?**\n",
    "   - Qwen 2.5 72B is fully open-weight and 14√ó cheaper than Claude\n",
    "   - Kimi K2 is a trillion-parameter MoE from an emerging Chinese lab\n",
    "\n",
    "3. **Does price predict quality?**\n",
    "   - Our price range spans from $0.07/M (Qwen) to $1.00/M (Claude)‚Äîa 14√ó spread\n",
    "\n",
    "4. **How do context windows and architecture choices affect summarization?**\n",
    "   - Context ranges from 33K (Qwen) to 1.05M (Gemini)\n",
    "   - Kimi K2 uses MoE (32B active of 1T total), others are dense\n",
    "\n",
    "All models are accessed through OpenRouter for unified API handling, consistent rate limiting, and comparable latency measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-client-header",
   "metadata": {},
   "source": [
    "## 3. OpenRouter API Client\n",
    "\n",
    "All API interaction code is defined here for transparency and reproducibility.\n",
    "\n",
    "**Design choices:**\n",
    "- **Retry logic:** Up to 3 attempts with exponential backoff for transient failures\n",
    "- **Timeout handling:** 10s connect, 60s read to handle slow model responses\n",
    "- **Error tracking:** Failed calls return a unique prefix (`[__OPENROUTER_ERROR__:`) for filtering during evaluation\n",
    "- **Rate limiting:** Small delay between requests to avoid throttling\n",
    "- **Reasoning config:** Models with chain-of-thought capabilities use \"minimal\" effort to reduce latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "api-client-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OpenRouter API key loaded (ends with ...5990)\n",
      "\n",
      "API client functions defined.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OPENROUTER API CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "# Load API key from environment variable\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if OPENROUTER_API_KEY is None:\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENROUTER_API_KEY environment variable not set.\")\n",
    "    print(\"   Set it with: export OPENROUTER_API_KEY='your-key-here'\")\n",
    "    print(\"   API calls will fail until this is set.\")\n",
    "else:\n",
    "    print(f\"‚úì OpenRouter API key loaded (ends with ...{OPENROUTER_API_KEY[-4:]})\")\n",
    "\n",
    "# API configuration\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "REQUEST_TIMEOUT = (10, 60)  # (connect_timeout, read_timeout) in seconds\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Unique error prefix for identifying API failures in results\n",
    "ERROR_PREFIX = \"[__OPENROUTER_ERROR__:\"\n",
    "\n",
    "\n",
    "def _get_api_headers():\n",
    "    \"\"\"Get headers for API requests. Raises if key not set.\"\"\"\n",
    "    if OPENROUTER_API_KEY is None:\n",
    "        raise RuntimeError(\n",
    "            \"OPENROUTER_API_KEY environment variable not set.\\n\"\n",
    "            \"Set it with: export OPENROUTER_API_KEY='your-key-here'\"\n",
    "        )\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "\n",
    "def _get_reasoning_config(model: str) -> dict:\n",
    "    \"\"\"\n",
    "    Return reasoning config for models that support it.\n",
    "    Uses \"minimal\" effort to reduce latency/cost.\n",
    "    \"\"\"\n",
    "    base = model.split(\"/\")[-1].lower()\n",
    "    \n",
    "    # Models that support reasoning\n",
    "    reasoning_prefixes = (\"gpt-5-mini\",)\n",
    "    \n",
    "    for prefix in reasoning_prefixes:\n",
    "        if base.startswith(prefix):\n",
    "            return {\"effort\": \"minimal\", \"exclude\": True}\n",
    "    \n",
    "    return {\"effort\": \"none\", \"exclude\": True}\n",
    "\n",
    "\n",
    "def call_openrouter_api(\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 64,\n",
    "    temperature: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Call an LLM via OpenRouter API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        OpenRouter model identifier (e.g., \"openai/gpt-5-mini\")\n",
    "    prompt : str\n",
    "        The user prompt to send\n",
    "    max_tokens : int\n",
    "        Maximum tokens in response\n",
    "    temperature : float\n",
    "        Sampling temperature (lower = more deterministic)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (response_text, latency_seconds)\n",
    "        On error, response_text starts with ERROR_PREFIX\n",
    "    \"\"\"\n",
    "    headers = _get_api_headers()\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You summarize chat conversations accurately and concisely.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    # Add reasoning config if applicable\n",
    "    reasoning_config = _get_reasoning_config(model)\n",
    "    if reasoning_config:\n",
    "        payload[\"reasoning\"] = reasoning_config\n",
    "    \n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                OPENROUTER_BASE_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=REQUEST_TIMEOUT,\n",
    "            )\n",
    "            t1 = time.time()\n",
    "            \n",
    "            # Small delay for rate limiting\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                data = response.json()\n",
    "            except Exception as json_err:\n",
    "                raise RuntimeError(f\"Failed to parse JSON: {json_err}\")\n",
    "            \n",
    "            # Check HTTP status\n",
    "            if response.status_code != 200:\n",
    "                error_msg = data.get(\"error\", {}).get(\"message\", response.text) if data else response.text\n",
    "                raise RuntimeError(f\"API error {response.status_code}: {error_msg}\")\n",
    "            \n",
    "            # Extract response text\n",
    "            try:\n",
    "                if not data:\n",
    "                    raise ValueError(\"Empty response\")\n",
    "                \n",
    "                choices = data.get(\"choices\")\n",
    "                if not choices or len(choices) == 0:\n",
    "                    raise ValueError(f\"No choices in response: {data}\")\n",
    "                \n",
    "                message = choices[0].get(\"message\")\n",
    "                if not message:\n",
    "                    raise ValueError(f\"No message in choice: {choices[0]}\")\n",
    "                \n",
    "                text = message.get(\"content\", \"\")\n",
    "                \n",
    "                if not isinstance(text, str):\n",
    "                    text = str(text) if text is not None else \"\"\n",
    "                \n",
    "                if text.strip() == \"\":\n",
    "                    text = f\"{ERROR_PREFIX} EMPTY_RESPONSE]\"\n",
    "                    \n",
    "            except (KeyError, IndexError, TypeError, ValueError) as extract_err:\n",
    "                text = f\"{ERROR_PREFIX} MALFORMED_RESPONSE: {extract_err}]\"\n",
    "            \n",
    "            latency = t1 - t0\n",
    "            return text, latency\n",
    "            \n",
    "        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "            last_error = e\n",
    "            if attempt < MAX_RETRIES:\n",
    "                # Exponential backoff\n",
    "                time.sleep(0.5 * (2 ** (attempt - 1)))\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        except RuntimeError:\n",
    "            raise\n",
    "    \n",
    "    # All retries failed\n",
    "    return f\"{ERROR_PREFIX} Request failed after {MAX_RETRIES} attempts: {last_error}]\", float('nan')\n",
    "\n",
    "\n",
    "print(\"\\nAPI client functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 4. Load SAMSum Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "data-load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "  Train:      14,731 examples\n",
      "  Validation: 818 examples\n",
      "  Test:       819 examples\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_samsum\n",
    "\n",
    "train_df, val_df, test_df = load_samsum()\n",
    "\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"  Train:      {len(train_df):,} examples\")\n",
    "print(f\"  Validation: {len(val_df):,} examples\")\n",
    "print(f\"  Test:       {len(test_df):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "data-sample-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dialogue:\n",
      "----------------------------------------\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "H ...\n",
      "\n",
      "Sample summary:\n",
      "----------------------------------------\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "# Quick peek at the data\n",
    "print(\"Sample dialogue:\")\n",
    "print(\"-\" * 40)\n",
    "print(test_df.iloc[0][\"dialogue\"][:300], \"...\")\n",
    "print()\n",
    "print(\"Sample summary:\")\n",
    "print(\"-\" * 40)\n",
    "print(test_df.iloc[0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-sample-header",
   "metadata": {},
   "source": [
    "## 5. Prepare Evaluation Sample\n",
    "\n",
    "We use a consistent sample for reproducibility. The sample is cached to ensure\n",
    "the same examples are used across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eval-sample-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° FULL EVALUATION MODE: Using ALL 819 test examples\n",
      "   ‚ö†Ô∏è  This will take a while and cost more in API calls!\n",
      "\n",
      "‚úì Loaded cached sample of 819 examples\n",
      "  (seed=42, hash=f67f1de0...)\n",
      "\n",
      "Evaluation sample: 819 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13862856</td>\n",
       "      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13729565</td>\n",
       "      <td>Eric: MACHINE!\\nRob: That's so gr8!\\nEric: I k...</td>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13680171</td>\n",
       "      <td>Lenny: Babe, can you help me with something?\\n...</td>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13729438</td>\n",
       "      <td>Will: hey babe, what do you want for dinner to...</td>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13828600</td>\n",
       "      <td>Ollie: Hi , are you in Warsaw\\nJane: yes, just...</td>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           dialogue  \\\n",
       "0  13862856  Hannah: Hey, do you have Betty's number?\\nAman...   \n",
       "1  13729565  Eric: MACHINE!\\nRob: That's so gr8!\\nEric: I k...   \n",
       "2  13680171  Lenny: Babe, can you help me with something?\\n...   \n",
       "3  13729438  Will: hey babe, what do you want for dinner to...   \n",
       "4  13828600  Ollie: Hi , are you in Warsaw\\nJane: yes, just...   \n",
       "\n",
       "                                             summary  \n",
       "0  Hannah needs Betty's number but Amanda doesn't...  \n",
       "1  Eric and Rob are going to watch a stand-up on ...  \n",
       "2  Lenny can't decide which trousers to buy. Bob ...  \n",
       "3  Emma will be home soon and she will let Will k...  \n",
       "4  Jane is in Warsaw. Ollie and Jane has a party....  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_evaluation_sample(test_df, n_samples, seed, cache_dir):\n",
    "    \"\"\"\n",
    "    Get evaluation sample with caching for reproducibility.\n",
    "    \n",
    "    Saves metadata to ensure we're using consistent samples across runs.\n",
    "    \"\"\"\n",
    "    sample_path = cache_dir / \"evaluation_sample.csv\"\n",
    "    metadata_path = cache_dir / \"evaluation_sample_metadata.json\"\n",
    "    \n",
    "    # Create fingerprint of source data\n",
    "    source_len = len(test_df)\n",
    "    dialogue_lengths = test_df['dialogue'].str.len().tolist()\n",
    "    \n",
    "    fingerprint_data = {\n",
    "        \"length\": source_len,\n",
    "        \"dialogue_length_sum\": sum(dialogue_lengths),\n",
    "        \"first_dialogue\": test_df['dialogue'].iloc[0][:200] if source_len > 0 else \"\",\n",
    "        \"last_dialogue\": test_df['dialogue'].iloc[-1][:200] if source_len > 0 else \"\",\n",
    "    }\n",
    "    \n",
    "    data_fingerprint = hashlib.md5(\n",
    "        json.dumps(fingerprint_data, sort_keys=True).encode()\n",
    "    ).hexdigest()[:16]\n",
    "    \n",
    "    # Check for valid cached sample\n",
    "    if sample_path.exists() and metadata_path.exists():\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                saved_meta = json.load(f)\n",
    "            \n",
    "            if (saved_meta.get('n_samples') == n_samples and\n",
    "                saved_meta.get('seed') == seed and\n",
    "                saved_meta.get('data_hash') == data_fingerprint):\n",
    "                \n",
    "                existing_sample = pd.read_csv(sample_path)\n",
    "                \n",
    "                if len(existing_sample) == n_samples:\n",
    "                    print(f\"‚úì Loaded cached sample of {len(existing_sample)} examples\")\n",
    "                    print(f\"  (seed={seed}, hash={data_fingerprint[:8]}...)\")\n",
    "                    return existing_sample\n",
    "                    \n",
    "        except (json.JSONDecodeError, KeyError):\n",
    "            pass\n",
    "    \n",
    "    # Create new sample\n",
    "    if n_samples >= len(test_df):\n",
    "        sample = test_df.copy().reset_index(drop=True)\n",
    "        print(f\"Using full test set: {len(sample)} examples\")\n",
    "    else:\n",
    "        sample = test_df.sample(n=n_samples, random_state=seed).reset_index(drop=True)\n",
    "        print(f\"Created sample of {len(sample)} examples (seed={seed})\")\n",
    "    \n",
    "    # Save sample and metadata\n",
    "    sample.to_csv(sample_path, index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        'n_samples': n_samples,\n",
    "        'seed': seed,\n",
    "        'data_hash': data_fingerprint,\n",
    "        'source_len': source_len,\n",
    "        'created_at': pd.Timestamp.now().isoformat(),\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved to cache: {sample_path.name}\")\n",
    "    \n",
    "    return sample\n",
    "\n",
    "\n",
    "# Determine sample size based on evaluation mode\n",
    "if EVALUATION_MODE == \"full\":\n",
    "    N_SAMPLES = len(test_df)\n",
    "    print(f\"\\n‚ö° FULL EVALUATION MODE: Using ALL {N_SAMPLES} test examples\")\n",
    "    print(f\"   ‚ö†Ô∏è  This will take a while and cost more in API calls!\\n\")\n",
    "else:\n",
    "    N_SAMPLES = TEST_MODE_SAMPLES\n",
    "    print(f\"\\nüß™ TEST MODE: Using {N_SAMPLES} examples (for development)\")\n",
    "    print(f\"   Change EVALUATION_MODE to 'full' for final results.\\n\")\n",
    "\n",
    "# Get the evaluation sample\n",
    "eval_df = get_evaluation_sample(test_df, N_SAMPLES, SEED, CACHE_DIR)\n",
    "\n",
    "print(f\"\\nEvaluation sample: {len(eval_df)} examples\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-header",
   "metadata": {},
   "source": [
    "## 6. Prompt Construction\n",
    "\n",
    "We use a consistent zero-shot prompt across all models. The prompt is designed to:\n",
    "\n",
    "- **Match SAMSum style:** Request 1‚Äì2 sentences, 15‚Äì30 words\n",
    "- **Focus on outcomes:** Emphasize decisions, requests, and action items\n",
    "- **Reduce hallucination:** Explicitly instruct not to add unsupported details\n",
    "- **Stay simple:** No few-shot examples, no complex formatting\n",
    "\n",
    "This keeps the comparison fair across models and isolates their raw zero-shot capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prompt-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt:\n",
      "============================================================\n",
      "Summarize the following conversation in 1-2 sentences. Keep it brief ‚Äî aim for 15-30 words. Focus on the main point, decisions, requests, or outcomes. Ignore small talk and do not add details that aren't supported by the text.\n",
      "\n",
      "DIALOGUE:\n",
      "-----\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be s...\n"
     ]
    }
   ],
   "source": [
    "def build_summarization_prompt(dialogue: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a zero-shot summarization prompt for frontier LLMs.\n",
    "    \n",
    "    The prompt is designed to produce concise summaries similar\n",
    "    to the SAMSum reference summaries (typically 15-30 words).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"Summarize the following conversation in 1-2 sentences. \"\n",
    "        \"Keep it brief ‚Äî aim for 15-30 words. \"\n",
    "        \"Focus on the main point, decisions, requests, or outcomes. \"\n",
    "        \"Ignore small talk and do not add details that aren't supported by the text.\\n\\n\"\n",
    "        \"DIALOGUE:\\n\"\n",
    "        \"-----\\n\"\n",
    "        f\"{dialogue}\\n\"\n",
    "        \"-----\\n\\n\"\n",
    "        \"SUMMARY:\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the prompt\n",
    "print(\"Example prompt:\")\n",
    "print(\"=\" * 60)\n",
    "example_prompt = build_summarization_prompt(eval_df['dialogue'].iloc[0])\n",
    "print(example_prompt[:500] + \"...\" if len(example_prompt) > 500 else example_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-calls-header",
   "metadata": {},
   "source": [
    "## 7. Run API Calls\n",
    "\n",
    "Generate summaries for each model. Results are cached per-model for efficiency.\n",
    "\n",
    "**Caching strategy:**\n",
    "- Each model's results are saved to `{model_label}_predictions.csv` in the cache directory\n",
    "- If `RUN_API_CALLS=True`, we re-run even if cache exists (for fresh results)\n",
    "- If `RUN_API_CALLS=False`, we load from cache only\n",
    "- This allows mixing cached and fresh results during development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "api-helpers-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_model_cache_path(model_label: str) -> Path:\n",
    "    \"\"\"Get the cache path for a model's results.\"\"\"\n",
    "    return CACHE_DIR / f\"{model_label}_predictions.csv\"\n",
    "\n",
    "\n",
    "def load_cached_predictions(model_label: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Load cached predictions for a model if they exist.\"\"\"\n",
    "    path = get_model_cache_path(model_label)\n",
    "    if path.exists():\n",
    "        return pd.read_csv(path)\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_model_predictions(model_label: str, model_id: str, eval_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run API calls for a single model and return results DataFrame.\n",
    "    \n",
    "    Returns DataFrame with columns:\n",
    "    - dialogue\n",
    "    - reference_summary (human)\n",
    "    - model_summary (prediction)\n",
    "    - latency_seconds\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for idx, row in tqdm(eval_df.iterrows(), total=len(eval_df), desc=model_label):\n",
    "        dialogue = row[\"dialogue\"]\n",
    "        reference = row[\"summary\"]\n",
    "        prompt = build_summarization_prompt(dialogue)\n",
    "        \n",
    "        try:\n",
    "            prediction, latency = call_openrouter_api(\n",
    "                model=model_id,\n",
    "                prompt=prompt,\n",
    "                max_tokens=MAX_TARGET_LEN,\n",
    "                temperature=TEMPERATURE,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            prediction = f\"{ERROR_PREFIX} {e}]\"\n",
    "            latency = np.nan\n",
    "        \n",
    "        rows.append({\n",
    "            \"dialogue\": dialogue,\n",
    "            \"reference_summary\": reference,\n",
    "            \"model_summary\": prediction,\n",
    "            \"latency_seconds\": latency,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "api-calls-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING MODEL EVALUATIONS\n",
      "======================================================================\n",
      "\n",
      "gpt5_mini: Cache exists, re-running (RUN_API_CALLS=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpt5_mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [17:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Saved 819 results to gpt5_mini_predictions.csv\n",
      "\n",
      "gemini_25_flash: Cache exists, re-running (RUN_API_CALLS=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gemini_25_flash: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [09:32<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Saved 819 results to gemini_25_flash_predictions.csv\n",
      "\n",
      "claude_45_haiku: Cache exists, re-running (RUN_API_CALLS=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claude_45_haiku: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [24:14<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Saved 819 results to claude_45_haiku_predictions.csv\n",
      "\n",
      "qwen25_72b: Cache exists, re-running (RUN_API_CALLS=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qwen25_72b: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [40:55<00:00,  3.00s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Saved 819 results to qwen25_72b_predictions.csv\n",
      "\n",
      "kimi_k2: Cache exists, re-running (RUN_API_CALLS=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kimi_k2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [30:43<00:00,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Saved 819 results to kimi_k2_predictions.csv\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "  Models run (API calls):  5 - ['gpt5_mini', 'gemini_25_flash', 'claude_45_haiku', 'qwen25_72b', 'kimi_k2']\n",
      "  Models loaded (cache):   0 - []\n",
      "  Models skipped:          0 - []\n",
      "  Total models available:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RUNNING MODEL EVALUATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_by_model = {}\n",
    "models_run = []\n",
    "models_loaded = []\n",
    "models_skipped = []\n",
    "\n",
    "for label, model_id in OPENROUTER_MODELS.items():\n",
    "    cache_path = get_model_cache_path(label)\n",
    "    \n",
    "    # Check if we should run this model\n",
    "    should_run = RUN_API_CALLS and MODELS_TO_RUN.get(label, True)\n",
    "    \n",
    "    if should_run:\n",
    "        if cache_path.exists():\n",
    "            print(f\"\\n{label}: Cache exists, re-running (RUN_API_CALLS=True)\")\n",
    "        else:\n",
    "            print(f\"\\n{label}: Running API calls...\")\n",
    "        \n",
    "        # Run predictions\n",
    "        df_results = run_model_predictions(label, model_id, eval_df)\n",
    "        \n",
    "        # Cache results\n",
    "        df_results.to_csv(cache_path, index=False)\n",
    "        print(f\"  ‚úì Saved {len(df_results)} results to {cache_path.name}\")\n",
    "        \n",
    "        results_by_model[label] = df_results\n",
    "        models_run.append(label)\n",
    "        \n",
    "    else:\n",
    "        # Try to load from cache\n",
    "        cached = load_cached_predictions(label)\n",
    "        \n",
    "        if cached is not None:\n",
    "            results_by_model[label] = cached\n",
    "            models_loaded.append(label)\n",
    "            print(f\"{label}: Loaded {len(cached)} cached results\")\n",
    "        else:\n",
    "            models_skipped.append(label)\n",
    "            print(f\"{label}: No cache found (skipping)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Models run (API calls):  {len(models_run)} - {models_run}\")\n",
    "print(f\"  Models loaded (cache):   {len(models_loaded)} - {models_loaded}\")\n",
    "print(f\"  Models skipped:          {len(models_skipped)} - {models_skipped}\")\n",
    "print(f\"  Total models available:  {len(results_by_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rouge-header",
   "metadata": {},
   "source": [
    "## 8. ROUGE Evaluation\n",
    "\n",
    "Compute ROUGE scores using the same methodology as Experiments 1 and 2.\n",
    "\n",
    "**Important:** We use identical settings (`use_stemmer=True`) and the same test split to ensure scores are directly comparable. Any errors (API failures, malformed responses) are filtered before computing ROUGE to avoid penalizing models for infrastructure issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rouge-setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_rouge(predictions: list, references: list) -> dict:\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores for predictions vs references.\n",
    "    \n",
    "    Uses the same configuration as Experiments 1 and 2 for consistency.\n",
    "    \n",
    "    Returns dict with rouge1, rouge2, rougeL, rougeLsum as percentages (0-100).\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    def clean_text(text):\n",
    "        if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "            return \"\"\n",
    "        return str(text).strip()\n",
    "    \n",
    "    predictions = [clean_text(p) for p in predictions]\n",
    "    references = [clean_text(r) for r in references]\n",
    "    \n",
    "    result = rouge_metric.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        use_stemmer=True,  # Same as experiments 1 & 2\n",
    "    )\n",
    "    \n",
    "    # Convert to percentages for consistency with Experiments 1 & 2\n",
    "    result = {k: round(v * 100, 2) for k, v in result.items()}\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"ROUGE evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rouge-eval-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ROUGE EVALUATION\n",
      "======================================================================\n",
      "‚ö†Ô∏è  qwen25_72b: 30 errors (3.7%), evaluating 789 responses\n",
      "\n",
      "============================================================\n",
      "‚ö†Ô∏è  COMPARABILITY WARNING\n",
      "============================================================\n",
      "Models evaluated on different sample sizes (789 to 819)\n",
      "ROUGE scores may not be directly comparable.\n",
      "============================================================\n",
      "\n",
      "ROUGE Scores (sorted by ROUGE-L):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini_25_flash</th>\n",
       "      <td>44.60</td>\n",
       "      <td>17.85</td>\n",
       "      <td>35.49</td>\n",
       "      <td>35.51</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen25_72b</th>\n",
       "      <td>44.15</td>\n",
       "      <td>17.31</td>\n",
       "      <td>35.17</td>\n",
       "      <td>35.19</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_45_haiku</th>\n",
       "      <td>43.62</td>\n",
       "      <td>16.55</td>\n",
       "      <td>34.58</td>\n",
       "      <td>34.59</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kimi_k2</th>\n",
       "      <td>41.42</td>\n",
       "      <td>13.22</td>\n",
       "      <td>32.36</td>\n",
       "      <td>32.38</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt5_mini</th>\n",
       "      <td>41.56</td>\n",
       "      <td>14.34</td>\n",
       "      <td>32.15</td>\n",
       "      <td>32.17</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rouge1  rouge2  rougeL  rougeLsum  n_samples\n",
       "model                                                        \n",
       "gemini_25_flash   44.60   17.85   35.49      35.51        819\n",
       "qwen25_72b        44.15   17.31   35.17      35.19        789\n",
       "claude_45_haiku   43.62   16.55   34.58      34.59        819\n",
       "kimi_k2           41.42   13.22   32.36      32.38        819\n",
       "gpt5_mini         41.56   14.34   32.15      32.17        819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ROUGE EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rouge_scores = {}\n",
    "sample_counts = {}\n",
    "\n",
    "for label, df in results_by_model.items():\n",
    "    # Filter out API errors\n",
    "    valid_mask = ~df[\"model_summary\"].str.startswith(ERROR_PREFIX)\n",
    "    valid_df = df[valid_mask]\n",
    "    \n",
    "    if len(valid_df) == 0:\n",
    "        print(f\"‚ùå {label}: No valid responses (all failed)\")\n",
    "        continue\n",
    "    \n",
    "    error_count = len(df) - len(valid_df)\n",
    "    if error_count > 0:\n",
    "        error_pct = error_count / len(df) * 100\n",
    "        print(f\"‚ö†Ô∏è  {label}: {error_count} errors ({error_pct:.1f}%), evaluating {len(valid_df)} responses\")\n",
    "    \n",
    "    # Compute ROUGE (returns percentages)\n",
    "    scores = compute_rouge(\n",
    "        predictions=valid_df[\"model_summary\"].tolist(),\n",
    "        references=valid_df[\"reference_summary\"].tolist(),\n",
    "    )\n",
    "    \n",
    "    rouge_scores[label] = scores\n",
    "    sample_counts[label] = len(valid_df)\n",
    "\n",
    "# Create summary DataFrame\n",
    "if rouge_scores:\n",
    "    rouge_df = pd.DataFrame.from_dict(rouge_scores, orient=\"index\")\n",
    "    rouge_df.index.name = \"model\"\n",
    "    rouge_df[\"n_samples\"] = pd.Series(sample_counts)\n",
    "    rouge_df = rouge_df.sort_values(by=\"rougeL\", ascending=False)\n",
    "    \n",
    "    # Check for comparability\n",
    "    min_samples = rouge_df[\"n_samples\"].min()\n",
    "    max_samples = rouge_df[\"n_samples\"].max()\n",
    "    \n",
    "    if min_samples != max_samples:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚ö†Ô∏è  COMPARABILITY WARNING\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Models evaluated on different sample sizes ({min_samples} to {max_samples})\")\n",
    "        print(\"ROUGE scores may not be directly comparable.\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nROUGE Scores (sorted by ROUGE-L):\")\n",
    "    display(rouge_df)\n",
    "    \n",
    "else:\n",
    "    rouge_df = None\n",
    "    print(\"No ROUGE scores to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latency-header",
   "metadata": {},
   "source": [
    "## 9. Latency Analysis\n",
    "\n",
    "Latency is measured end-to-end from request initiation to response parsing. This includes:\n",
    "- Network round-trip time\n",
    "- Model inference time\n",
    "- Any provider-side queuing\n",
    "\n",
    "**Note:** Latency varies by time of day, provider load, and geographic location. These measurements represent a single run and may not generalize to all conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "latency-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LATENCY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Latency Statistics (seconds, sorted by mean):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini_25_flash</th>\n",
       "      <td>819.0</td>\n",
       "      <td>0.647544</td>\n",
       "      <td>0.171487</td>\n",
       "      <td>0.455604</td>\n",
       "      <td>0.616910</td>\n",
       "      <td>0.752706</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>2.646552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt5_mini</th>\n",
       "      <td>819.0</td>\n",
       "      <td>1.199934</td>\n",
       "      <td>0.334696</td>\n",
       "      <td>0.709175</td>\n",
       "      <td>1.132372</td>\n",
       "      <td>1.491899</td>\n",
       "      <td>1.642712</td>\n",
       "      <td>5.808657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_45_haiku</th>\n",
       "      <td>819.0</td>\n",
       "      <td>1.723604</td>\n",
       "      <td>0.726473</td>\n",
       "      <td>1.003187</td>\n",
       "      <td>1.625675</td>\n",
       "      <td>2.172446</td>\n",
       "      <td>2.405935</td>\n",
       "      <td>11.445165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kimi_k2</th>\n",
       "      <td>819.0</td>\n",
       "      <td>2.198808</td>\n",
       "      <td>2.043115</td>\n",
       "      <td>0.309427</td>\n",
       "      <td>1.179483</td>\n",
       "      <td>5.025968</td>\n",
       "      <td>6.343143</td>\n",
       "      <td>11.416361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen25_72b</th>\n",
       "      <td>819.0</td>\n",
       "      <td>2.946368</td>\n",
       "      <td>2.351451</td>\n",
       "      <td>0.427573</td>\n",
       "      <td>2.165694</td>\n",
       "      <td>5.675332</td>\n",
       "      <td>8.087161</td>\n",
       "      <td>14.889447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean       std       min       p50       p90  \\\n",
       "model                                                                      \n",
       "gemini_25_flash  819.0  0.647544  0.171487  0.455604  0.616910  0.752706   \n",
       "gpt5_mini        819.0  1.199934  0.334696  0.709175  1.132372  1.491899   \n",
       "claude_45_haiku  819.0  1.723604  0.726473  1.003187  1.625675  2.172446   \n",
       "kimi_k2          819.0  2.198808  2.043115  0.309427  1.179483  5.025968   \n",
       "qwen25_72b       819.0  2.946368  2.351451  0.427573  2.165694  5.675332   \n",
       "\n",
       "                      p95        max  \n",
       "model                                 \n",
       "gemini_25_flash  0.808989   2.646552  \n",
       "gpt5_mini        1.642712   5.808657  \n",
       "claude_45_haiku  2.405935  11.445165  \n",
       "kimi_k2          6.343143  11.416361  \n",
       "qwen25_72b       8.087161  14.889447  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LATENCY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "latency_stats = {}\n",
    "\n",
    "for label, df in results_by_model.items():\n",
    "    latencies = df[\"latency_seconds\"].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(latencies) == 0:\n",
    "        continue\n",
    "    \n",
    "    stats = latencies.describe(percentiles=[0.5, 0.9, 0.95])\n",
    "    latency_stats[label] = stats\n",
    "\n",
    "if latency_stats:\n",
    "    latency_df = pd.DataFrame(latency_stats).T\n",
    "    latency_df.index.name = \"model\"\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    latency_df = latency_df.rename(columns={\n",
    "        \"50%\": \"p50\",\n",
    "        \"90%\": \"p90\",\n",
    "        \"95%\": \"p95\",\n",
    "    })\n",
    "    \n",
    "    # Sort by mean latency\n",
    "    latency_df = latency_df.sort_values(by=\"mean\", ascending=True)\n",
    "    \n",
    "    print(\"\\nLatency Statistics (seconds, sorted by mean):\")\n",
    "    display(latency_df[[\"count\", \"mean\", \"std\", \"min\", \"p50\", \"p90\", \"p95\", \"max\"]])\n",
    "    \n",
    "else:\n",
    "    latency_df = None\n",
    "    print(\"No latency data to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## 10. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "visualization-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/rouge_latency_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if rouge_df is not None and len(rouge_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROUGE scores bar chart (matching style of Experiments 1 & 2)\n",
    "    ax = axes[0]\n",
    "    models = rouge_df.index.tolist()\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    r1 = rouge_df[\"rouge1\"].tolist()\n",
    "    r2 = rouge_df[\"rouge2\"].tolist()\n",
    "    rL = rouge_df[\"rougeL\"].tolist()\n",
    "    \n",
    "    ax.bar(x - width, r1, width, label=\"ROUGE-1\")\n",
    "    ax.bar(x, r2, width, label=\"ROUGE-2\")\n",
    "    ax.bar(x + width, rL, width, label=\"ROUGE-L\")\n",
    "    \n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_ylabel(\"ROUGE Score\")\n",
    "    ax.set_title(\"Experiment 3 ‚Äî ROUGE Scores by Model\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "    \n",
    "    # Latency bar chart\n",
    "    ax = axes[1]\n",
    "    if latency_df is not None and len(latency_df) > 0:\n",
    "        latency_models = latency_df.index.tolist()\n",
    "        latency_means = latency_df[\"mean\"].tolist()\n",
    "        x_lat = np.arange(len(latency_models))\n",
    "        \n",
    "        ax.bar(x_lat, latency_means, color=\"coral\")\n",
    "        ax.set_xlabel(\"Model\")\n",
    "        ax.set_ylabel(\"Mean Latency (seconds)\")\n",
    "        ax.set_title(\"Experiment 3 ‚Äî API Latency by Model\")\n",
    "        ax.set_xticks(x_lat)\n",
    "        ax.set_xticklabels(latency_models, rotation=45, ha=\"right\")\n",
    "        ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No latency data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.set_title(\"API Latency by Model\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = OUTPUT_DIR / \"rouge_latency_comparison.png\"\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to: {fig_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualitative-header",
   "metadata": {},
   "source": [
    "## 11. Test Set Qualitative Examples\n",
    "\n",
    "Examine sample outputs from each model to understand quality beyond ROUGE scores.\n",
    "\n",
    "ROUGE measures n-gram overlap but can't capture:\n",
    "- **Semantic accuracy:** Does the summary mean the right thing?\n",
    "- **Fluency:** Does it read naturally?\n",
    "- **Completeness:** Are key details included?\n",
    "- **Hallucination:** Does it invent information?\n",
    "\n",
    "Manual inspection of representative examples helps identify these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "qualitative-single-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET: Qualitative Examples ‚Äî gpt5_mini\n",
      "============================================================\n",
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 86\n",
      "DIALOGUE: Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thinking about partying somewhere\n",
      "Nathalie: part ...\n",
      "HUMAN: Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
      "MODEL: They decide against opera and agree to a classy New Year‚Äôs Eve party at a Soho club (Breakfast at Tiffany‚Äôs theme), and plan to buy tickets soon.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 432\n",
      "DIALOGUE: Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did sh ...\n",
      "HUMAN: Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "MODEL: Javier asks for English-speaking tattoo parlors; Judie recommends Warsaw Ink and says her girlfriend got a tattoo there for $1000, so Javier decides to get tattooed in Colombia instead.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 799\n",
      "DIALOGUE: Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don't, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it's from Crazy Lenses. They have quite reasonable prices and very fast ...\n",
      "HUMAN: Martha likes Ophelia's lenses and wants to buy similar ones. Ophelia got them from Crazy Lenses.\n",
      "MODEL: Martha asked Ophelia about the lenses in her profile picture; Ophelia said they‚Äôre from Crazy Lenses, which has reasonable prices and fast shipping.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 417\n",
      "DIALOGUE: Miranda: Hi S, could we cancel tomorrow's meeting?\n",
      "Stephanie: again? what happened?\n",
      "Miranda: I have to work :(\n",
      "Stephanie: you work 20 hours a day!\n",
      "Miranda: that's what young doctors do\n",
      "Stephanie: they kill themselves working\n",
      "Miranda: no they come close to death but survive and it makes them immortal ...\n",
      "HUMAN: Miranda can't make her meeting with Stephanie as she has to work. \n",
      "MODEL: Miranda asks to cancel tomorrow's meeting because she has to work long hours as a young doctor; Stephanie reluctantly accepts as long as she has an explanation.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 678\n",
      "DIALOGUE: Sam: Where are you?\n",
      "Kate: downstairs\n",
      "Sam: already?\n",
      "Kate: sure, come down\n",
      "Jeff: We're in the little room next to the reception\n",
      "Kate: have you noticed the woman making a cake?\n",
      "Sam: yes\n",
      "Kate: did you see the cake?\n",
      "Sam: I didn't pay attention, why?\n",
      "Kate: there was a huge penis on it\n",
      "Kate: made of marzip ...\n",
      "HUMAN: Kate and Jeff are downstairs in a room next to the reception. Some lady is making a marzipan cake. \n",
      "MODEL: Kate tells Sam and Jeff they're downstairs and describes seeing a woman in the kitchen making a shockingly explicit marzipan cake, prompting laughter and curiosity.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "TEST SET: Qualitative Examples ‚Äî gemini_25_flash\n",
      "============================================================\n",
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 86\n",
      "DIALOGUE: Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thinking about partying somewhere\n",
      "Nathalie: part ...\n",
      "HUMAN: Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
      "MODEL: The group decided to go to a club in Soho for New Year's Eve, after considering opera and a \"Breakfast at Tiffany's\" party. They need to buy tickets soon.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 432\n",
      "DIALOGUE: Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did sh ...\n",
      "HUMAN: Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "MODEL: Javier asked Judie for English-speaking tattoo parlor recommendations. Judie suggested Warsaw Ink, but Javier decided against it due to the high price.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 799\n",
      "DIALOGUE: Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don't, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it's from Crazy Lenses. They have quite reasonable prices and very fast ...\n",
      "HUMAN: Martha likes Ophelia's lenses and wants to buy similar ones. Ophelia got them from Crazy Lenses.\n",
      "MODEL: Martha asked Ophelia about her contact lenses. Ophelia recommended Crazy Lenses, citing reasonable prices and fast shipping.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 417\n",
      "DIALOGUE: Miranda: Hi S, could we cancel tomorrow's meeting?\n",
      "Stephanie: again? what happened?\n",
      "Miranda: I have to work :(\n",
      "Stephanie: you work 20 hours a day!\n",
      "Miranda: that's what young doctors do\n",
      "Stephanie: they kill themselves working\n",
      "Miranda: no they come close to death but survive and it makes them immortal ...\n",
      "HUMAN: Miranda can't make her meeting with Stephanie as she has to work. \n",
      "MODEL: Miranda requested to cancel tomorrow's meeting due to work, which Stephanie reluctantly accepted after Miranda's explanation.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 678\n",
      "DIALOGUE: Sam: Where are you?\n",
      "Kate: downstairs\n",
      "Sam: already?\n",
      "Kate: sure, come down\n",
      "Jeff: We're in the little room next to the reception\n",
      "Kate: have you noticed the woman making a cake?\n",
      "Sam: yes\n",
      "Kate: did you see the cake?\n",
      "Sam: I didn't pay attention, why?\n",
      "Kate: there was a huge penis on it\n",
      "Kate: made of marzip ...\n",
      "HUMAN: Kate and Jeff are downstairs in a room next to the reception. Some lady is making a marzipan cake. \n",
      "MODEL: Kate and Jeff are downstairs, near reception. Kate saw a woman decorating a cake with a large marzipan penis, which Sam now wants to see.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "TEST SET: Qualitative Examples ‚Äî claude_45_haiku\n",
      "============================================================\n",
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 86\n",
      "DIALOGUE: Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thinking about partying somewhere\n",
      "Nathalie: part ...\n",
      "HUMAN: Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
      "MODEL: The group decided to celebrate New Year's Eve at a classy club in Soho instead of the opera, and agreed to purchase tickets soon.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 432\n",
      "DIALOGUE: Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did sh ...\n",
      "HUMAN: Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "MODEL: Javier asks Judie for English-speaking tattoo parlor recommendations. Judie suggests Warsaw Ink, where her girlfriend got a tattoo for 1000 (currency unspecified), prompting Javier to consider getting one in Colombia instead.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 799\n",
      "DIALOGUE: Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don't, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it's from Crazy Lenses. They have quite reasonable prices and very fast ...\n",
      "HUMAN: Martha likes Ophelia's lenses and wants to buy similar ones. Ophelia got them from Crazy Lenses.\n",
      "MODEL: Martha asked Ophelia about lenses from her profile picture. Ophelia recommended Crazy Lenses, citing reasonable prices and fast shipping.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 417\n",
      "DIALOGUE: Miranda: Hi S, could we cancel tomorrow's meeting?\n",
      "Stephanie: again? what happened?\n",
      "Miranda: I have to work :(\n",
      "Stephanie: you work 20 hours a day!\n",
      "Miranda: that's what young doctors do\n",
      "Stephanie: they kill themselves working\n",
      "Miranda: no they come close to death but survive and it makes them immortal ...\n",
      "HUMAN: Miranda can't make her meeting with Stephanie as she has to work. \n",
      "MODEL: Miranda requests to cancel tomorrow's meeting due to work obligations. Stephanie agrees after Miranda explains her demanding schedule as a young doctor.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 678\n",
      "DIALOGUE: Sam: Where are you?\n",
      "Kate: downstairs\n",
      "Sam: already?\n",
      "Kate: sure, come down\n",
      "Jeff: We're in the little room next to the reception\n",
      "Kate: have you noticed the woman making a cake?\n",
      "Sam: yes\n",
      "Kate: did you see the cake?\n",
      "Sam: I didn't pay attention, why?\n",
      "Kate: there was a huge penis on it\n",
      "Kate: made of marzip ...\n",
      "HUMAN: Kate and Jeff are downstairs in a room next to the reception. Some lady is making a marzipan cake. \n",
      "MODEL: Kate spotted a woman decorating an unusual cake featuring a penis made of marzipan with chocolate details, ordered by a customer. Sam wants to see it in the kitchen downstairs.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "TEST SET: Qualitative Examples ‚Äî qwen25_72b\n",
      "============================================================\n",
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 532\n",
      "DIALOGUE: Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just  ...\n",
      "HUMAN: Pete will get a pear yogurt for Jen if they have it.\n",
      "MODEL: Pete will check for pear yogurt; if unavailable, he won't get any yogurt as Jen doesn't like other flavors.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 42\n",
      "DIALOGUE: Ola: Hello Kate, sorry for not keeping in touch properly. As expected, we have hardly any connectivity here in Cuba. But we're doing fine and enjoying our trip. How are the things at home?\n",
      "Kate: At long last! Started to worry. Nothing new happening, if you disregard all that Xmas craze. Momo has rec ...\n",
      "HUMAN: Ola is in Cuba and is enjoying her trip. She has problems with connectivity there. Momo has recovered from her injury. Ola doesn't like the clothes in Cuba. Ola will try to find a blouse for mum in Cuba, as Kate suggested.\n",
      "MODEL: Ola and Kate discuss Ola's trip to Cuba and the challenge of finding a quality scarf or blouse. Ola agrees to look for a blouse for Kate's mum.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 219\n",
      "DIALOGUE: Nova: Do know that people are photoshoping Timoth√©e Chalamet into artworks? :D\n",
      "Nova: It's hilarious, check it out: <file_other>\n",
      "Dominic: lol XD\n",
      "Dominic: it kinda looks good\n",
      "Nova: Right? :D\n",
      "Dominic: he looks like a typical young man from a 19th-century portrait\n",
      "Nova: omg you're so right! :D he looks  ...\n",
      "HUMAN: People are photoshopping Timoth√©e Chalamet into artworks. Dominic and Nova agree that he looks like a 19th century man.\n",
      "MODEL: Nova and Dominic discuss and laugh over photoshopped images of Timoth√©e Chalamet in 19th-century art, noting his fitting appearance.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 207\n",
      "DIALOGUE: Daisy: hey whats up\n",
      "Linda: Not much\n",
      "Linda: Im just packing\n",
      "Daisy: off on a vacation\n",
      "Linda: didn't I tell ya?\n",
      "Linda: I'm moving\n",
      "Daisy: really?\n",
      "Daisy: what happened?\n",
      "Daisy: you had a great place!\n",
      "Linda: got a new job\n",
      "Linda: I'm moving to Ohio\n",
      "Daisy: OHIO!\n",
      "Daisy: that so far away :(\n",
      "Linda: yeah well\n",
      "Li ...\n",
      "HUMAN: Linda got a new job and is moving to Ohio for 6 months. Her brother will stay at her current apartment. Daisy will come by Linda's place to meet her and help her pack as she is too busy to go out.\n",
      "MODEL: Linda is moving to Ohio for a new job for 6 months, and Daisy will help her pack before she leaves. \n",
      "--------------------------------------------------------------------------------\n",
      "ID 243\n",
      "DIALOGUE: Rory: Hey Mitch, how are you? I hope you're doing ok. We are thinking of signing up Bill for that International camp. Sammy will be going too. Do you think it would be possible for you to take Bill and Sammy if you go down?\n",
      "Mitch: I'm doing well - pretty tired. Yes, I do think that's possible :)\n",
      "Ror ...\n",
      "HUMAN: Rory wants Mitch to take Bill and Sammy and they'll chip in for gas. Mitch will be leaving Sunday, the 29th to get there by 9 am on Monday. Bill will arrive around 10 am Sunday and Joanna will be picking him. Mitch will meet Bill after.\n",
      "MODEL: Mitch will drive Bill and Sammy to the International camp in Croatia, leaving on July 29th. Rory will send Bill by Flixbus, arriving Sunday morning.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "TEST SET: Qualitative Examples ‚Äî kimi_k2\n",
      "============================================================\n",
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 86\n",
      "DIALOGUE: Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thinking about partying somewhere\n",
      "Nathalie: part ...\n",
      "HUMAN: Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
      "MODEL: Group agrees on a ‚Äúclassy‚Äù New Year‚Äôs Eve: they‚Äôll buy tickets for the Breakfast-at-Tiffany‚Äôs-themed party at Soho club.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 432\n",
      "DIALOGUE: Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did sh ...\n",
      "HUMAN: Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "MODEL: Javier asked for an English-speaking tattoo parlor; Judie recommended Warsaw Ink, but after hearing the 1000 price, Javier decided to get tattooed in Colombia instead.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 799\n",
      "DIALOGUE: Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don't, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it's from Crazy Lenses. They have quite reasonable prices and very fast ...\n",
      "HUMAN: Martha likes Ophelia's lenses and wants to buy similar ones. Ophelia got them from Crazy Lenses.\n",
      "MODEL: Martha asked Ophelia where her profile-picture lenses came from; Ophelia identified Crazy Lenses and recommended it.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 417\n",
      "DIALOGUE: Miranda: Hi S, could we cancel tomorrow's meeting?\n",
      "Stephanie: again? what happened?\n",
      "Miranda: I have to work :(\n",
      "Stephanie: you work 20 hours a day!\n",
      "Miranda: that's what young doctors do\n",
      "Stephanie: they kill themselves working\n",
      "Miranda: no they come close to death but survive and it makes them immortal ...\n",
      "HUMAN: Miranda can't make her meeting with Stephanie as she has to work. \n",
      "MODEL: Miranda canceled tomorrow‚Äôs meeting due to work; Stephanie accepted after some teasing about doctors‚Äô grueling hours.\n",
      "--------------------------------------------------------------------------------\n",
      "ID 678\n",
      "DIALOGUE: Sam: Where are you?\n",
      "Kate: downstairs\n",
      "Sam: already?\n",
      "Kate: sure, come down\n",
      "Jeff: We're in the little room next to the reception\n",
      "Kate: have you noticed the woman making a cake?\n",
      "Sam: yes\n",
      "Kate: did you see the cake?\n",
      "Sam: I didn't pay attention, why?\n",
      "Kate: there was a huge penis on it\n",
      "Kate: made of marzip ...\n",
      "HUMAN: Kate and Jeff are downstairs in a room next to the reception. Some lady is making a marzipan cake. \n",
      "MODEL: Kate tells Sam about a marzipan penis cake she saw being made in the room under the stairs, and Sam wants to go see it.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def show_qualitative_examples(df, model_label, n=5, max_dialogue_chars=300, seed=42):\n",
    "    \"\"\"\n",
    "    Display qualitative examples for a single model.\n",
    "    \n",
    "    Shows dialogue, human reference, and model prediction side by side.\n",
    "    Matches the format used in Experiments 1 & 2.\n",
    "    \"\"\"\n",
    "    # Filter out errors\n",
    "    valid_df = df[~df[\"model_summary\"].str.startswith(ERROR_PREFIX)]\n",
    "    \n",
    "    if len(valid_df) == 0:\n",
    "        print(f\"No valid examples for {model_label}\")\n",
    "        return\n",
    "    \n",
    "    # Sample examples\n",
    "    sample = valid_df.sample(n=min(n, len(valid_df)), random_state=seed)\n",
    "    \n",
    "    print(f\"--- {n} qualitative samples (seed={seed}) ---\")\n",
    "    \n",
    "    for i, (idx, row) in enumerate(sample.iterrows()):\n",
    "        dialogue = row[\"dialogue\"]\n",
    "        if len(dialogue) > max_dialogue_chars:\n",
    "            dialogue = dialogue[:max_dialogue_chars] + \" ...\"\n",
    "        \n",
    "        print(f\"ID {idx}\")\n",
    "        print(f\"DIALOGUE: {dialogue}\")\n",
    "        print(f\"HUMAN: {row['reference_summary']}\")\n",
    "        # Pad model output to fixed width for alignment\n",
    "        model_summary = row['model_summary']\n",
    "        print(f\"MODEL: {model_summary:<100}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# Show examples for each model\n",
    "for label in results_by_model:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST SET: Qualitative Examples ‚Äî {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    show_qualitative_examples(results_by_model[label], label, n=5, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## 12. Side-by-Side Model Comparison\n",
    "\n",
    "Compare how different models summarize the same dialogues.\n",
    "\n",
    "This reveals stylistic differences that ROUGE scores obscure:\n",
    "- Some models are more concise, others more elaborate\n",
    "- Some focus on outcomes, others on process\n",
    "- Some add interpretive framing, others stay strictly factual\n",
    "\n",
    "Seeing the same dialogue processed by all five models makes these patterns visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "comparison-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SIDE-BY-SIDE MODEL COMPARISON\n",
      "======================================================================\n",
      "Found 819 dialogues common to all 5 models.\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 1\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Ryan: I have a bad feeling about this\n",
      "Ryan: <file_other>\n",
      "Sebastian: Ukraine...\n",
      "Sebastian: This russian circus will never end...\n",
      "Ryan: I hope the leaders of of nations will react somehow to this shit.\n",
      "Sebastian: I hope so too :(\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Ryan and Sebastian are worried about the political situation in Ukraine.\n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : Ryan and Sebastian express concern and frustration about Russia‚Äôs actions in Ukraine, hoping international leaders will respond.\n",
      "  gemini_25_flash     : Ryan and Sebastian are concerned about the ongoing conflict in Ukraine, hoping for international intervention to resolve the situation.\n",
      "  claude_45_haiku     : Ryan and Sebastian express concern about the situation in Ukraine and hope that world leaders will respond to the ongoing Russian conflict.\n",
      "  qwen25_72b          : Ryan and Sebastian express concern about the situation in Ukraine, hoping for a response from world leaders.\n",
      "  kimi_k2             : Ryan and Sebastian shared concern over the ongoing Russia-Ukraine conflict and hoped world leaders would respond.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 2\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Jane: Are u free now? Could u help me with that thesis?\n",
      "Ainsley: I'm sick won't be of much help sorry. I've got a cold and I'm sneezing like a little bitch every 2 seconds\n",
      "Jane: Oh... hmm ok. Hope u will get better soon...\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Ainsley is sick, so she's not able to help Jane with her thesis now.\n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : Jane asked Ainsley for help with her thesis; Ainsley declined because she's sick with a bad cold, and Jane wished her well.\n",
      "  gemini_25_flash     : Jane asked Ainsley for help with her thesis, but Ainsley declined because she is sick.\n",
      "  claude_45_haiku     : Jane asked Ainsley for help with her thesis, but Ainsley declined because she's sick with a cold.\n",
      "  qwen25_72b          : Ainsley can't help Jane with her thesis due to being sick with a cold. Jane wishes Ainsley a quick recovery.\n",
      "  kimi_k2             : Jane asked Ainsley for thesis help; Ainsley declined, citing illness.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 3\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Clint: are you better today?\n",
      "Alice: not really\n",
      "Alice: I have never had such a terrible flu \n",
      "Alice: I think I'm dying \n",
      "Clint: don't be silly \n",
      "Clint: it's just a flu \n",
      "Alice: I know but my whole body aches, I have fever and I'm sneezing all the time\n",
      "Alice: I'm home for 10 days and it seems I need more\n",
      "Clint: poor you :(\n",
      "Clint: how is it possible that vaccine did not work?\n",
      "Alice: I haven't taken any v...\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Alice has a terrible flu. She's forgotten to vaccinate herself.\n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : Alice is very sick with a severe flu, feeling feverish and bedridden beyond her planned 10 days, having forgotten to get vaccinated; Clint expresses c...\n",
      "  gemini_25_flash     : Alice is suffering from a severe flu, which she attributes to forgetting to get vaccinated. Clint expresses sympathy and questions why she didn't get ...\n",
      "  claude_45_haiku     : Alice is suffering from a severe flu with body aches, fever, and sneezing. She hasn't been vaccinated and regrets not getting the vaccine earlier.\n",
      "  qwen25_72b          : Alice is suffering from a severe flu for 10 days, experiencing body aches, fever, and constant sneezing, and hasn't taken a vaccine.\n",
      "  kimi_k2             : Alice is severely ill with the flu after forgetting to get vaccinated, and Clint expresses sympathy.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SIDE-BY-SIDE MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(results_by_model) < 2:\n",
    "    print(\"Need at least 2 models for comparison.\")\n",
    "else:\n",
    "    # Find dialogues common to all models\n",
    "    dialogue_sets = {\n",
    "        label: set(df[\"dialogue\"].tolist())\n",
    "        for label, df in results_by_model.items()\n",
    "    }\n",
    "    \n",
    "    common_dialogues = set.intersection(*dialogue_sets.values())\n",
    "    \n",
    "    if len(common_dialogues) == 0:\n",
    "        print(\"No common dialogues across all models.\")\n",
    "    else:\n",
    "        print(f\"Found {len(common_dialogues)} dialogues common to all {len(results_by_model)} models.\")\n",
    "        \n",
    "        # Sample a few for comparison\n",
    "        n_compare = min(3, len(common_dialogues))\n",
    "        common_list = list(common_dialogues)\n",
    "        \n",
    "        rng = np.random.default_rng(SEED)\n",
    "        sample_indices = rng.choice(len(common_list), size=n_compare, replace=False)\n",
    "        sample_dialogues = [common_list[i] for i in sample_indices]\n",
    "        \n",
    "        # Get reference from first model's data\n",
    "        first_model = list(results_by_model.keys())[0]\n",
    "        first_df = results_by_model[first_model]\n",
    "        \n",
    "        for i, dialogue in enumerate(sample_dialogues, 1):\n",
    "            ref_row = first_df[first_df[\"dialogue\"] == dialogue].iloc[0]\n",
    "            reference = ref_row[\"reference_summary\"]\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"COMPARISON EXAMPLE {i}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # Truncate long dialogues\n",
    "            display_dialogue = dialogue[:400] + \"...\" if len(dialogue) > 400 else dialogue\n",
    "            print(f\"\\n[DIALOGUE]\\n{display_dialogue}\")\n",
    "            print(f\"\\n[HUMAN SUMMARY]\\n{reference}\")\n",
    "            print(f\"\\n[MODEL SUMMARIES]\")\n",
    "            \n",
    "            for label, df in results_by_model.items():\n",
    "                match = df[df[\"dialogue\"] == dialogue]\n",
    "                if len(match) > 0:\n",
    "                    summary = match.iloc[0][\"model_summary\"]\n",
    "                    # Truncate long summaries\n",
    "                    if len(summary) > 150:\n",
    "                        summary = summary[:150] + \"...\"\n",
    "                    print(f\"  {label:20s}: {summary}\")\n",
    "                else:\n",
    "                    print(f\"  {label:20s}: [NOT FOUND]\")\n",
    "            \n",
    "            print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-results-header",
   "metadata": {},
   "source": [
    "## 13. Save Test Results\n",
    "\n",
    "Save final results for comparison with Experiments 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "save-results-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "‚úì Saved ROUGE summary to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/rouge_summary.csv\n",
      "‚úì Saved latency summary to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/latency_summary.csv\n",
      "‚úì Saved test results to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/test_results.csv\n",
      "\n",
      "Test Results (for comparison with Experiments 1 & 2):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini_25_flash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.60</td>\n",
       "      <td>17.85</td>\n",
       "      <td>35.49</td>\n",
       "      <td>35.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen25_72b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.15</td>\n",
       "      <td>17.31</td>\n",
       "      <td>35.17</td>\n",
       "      <td>35.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude_45_haiku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.62</td>\n",
       "      <td>16.55</td>\n",
       "      <td>34.58</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimi_k2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.42</td>\n",
       "      <td>13.22</td>\n",
       "      <td>32.36</td>\n",
       "      <td>32.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt5_mini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.56</td>\n",
       "      <td>14.34</td>\n",
       "      <td>32.15</td>\n",
       "      <td>32.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  test_loss  rouge1  rouge2  rougeL  rougeLsum\n",
       "0  gemini_25_flash        NaN   44.60   17.85   35.49      35.51\n",
       "1       qwen25_72b        NaN   44.15   17.31   35.17      35.19\n",
       "2  claude_45_haiku        NaN   43.62   16.55   34.58      34.59\n",
       "3          kimi_k2        NaN   41.42   13.22   32.36      32.38\n",
       "4        gpt5_mini        NaN   41.56   14.34   32.15      32.17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Predictions saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/predictions\n",
      "  - gpt5_mini_test_predictions.csv\n",
      "  - gemini_25_flash_test_predictions.csv\n",
      "  - claude_45_haiku_test_predictions.csv\n",
      "  - qwen25_72b_test_predictions.csv\n",
      "  - kimi_k2_test_predictions.csv\n",
      "\n",
      "‚úì Saved evaluation metadata to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/evaluation_metadata.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save ROUGE summary\n",
    "if rouge_df is not None:\n",
    "    rouge_summary_path = OUTPUT_DIR / \"rouge_summary.csv\"\n",
    "    rouge_df.to_csv(rouge_summary_path)\n",
    "    print(f\"\\n‚úì Saved ROUGE summary to: {rouge_summary_path}\")\n",
    "\n",
    "# Save latency summary\n",
    "if latency_df is not None:\n",
    "    latency_summary_path = OUTPUT_DIR / \"latency_summary.csv\"\n",
    "    latency_df.to_csv(latency_summary_path)\n",
    "    print(f\"‚úì Saved latency summary to: {latency_summary_path}\")\n",
    "\n",
    "# Save combined test results (for notebook 05 comparison)\n",
    "# Format matches Experiments 1 & 2 exactly\n",
    "if rouge_df is not None:\n",
    "    test_results_data = []\n",
    "    \n",
    "    for model in rouge_df.index:\n",
    "        row = {\n",
    "            \"model\": model,\n",
    "            \"test_loss\": np.nan,  # N/A for API models\n",
    "            \"rouge1\": rouge_df.loc[model, \"rouge1\"],  # Already in percentage\n",
    "            \"rouge2\": rouge_df.loc[model, \"rouge2\"],\n",
    "            \"rougeL\": rouge_df.loc[model, \"rougeL\"],\n",
    "            \"rougeLsum\": rouge_df.loc[model, \"rougeLsum\"],\n",
    "        }\n",
    "        test_results_data.append(row)\n",
    "    \n",
    "    test_results_df = pd.DataFrame(test_results_data)\n",
    "    test_results_df.to_csv(TEST_RESULTS_PATH, index=False)\n",
    "    print(f\"‚úì Saved test results to: {TEST_RESULTS_PATH}\")\n",
    "    \n",
    "    print(\"\\nTest Results (for comparison with Experiments 1 & 2):\")\n",
    "    display(test_results_df)\n",
    "\n",
    "# Save predictions for each model\n",
    "print(f\"\\n‚úì Predictions saved to: {PREDICTIONS_DIR}\")\n",
    "for label, df in results_by_model.items():\n",
    "    # Rename columns to match Experiments 1 & 2 format\n",
    "    pred_df = df.rename(columns={\n",
    "        \"reference_summary\": \"summary\",\n",
    "        \"model_summary\": \"model_prediction\",\n",
    "    })\n",
    "    pred_path = PREDICTIONS_DIR / f\"{label}_test_predictions.csv\"\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(f\"  - {pred_path.name}\")\n",
    "\n",
    "# Save evaluation metadata\n",
    "eval_metadata = {\n",
    "    \"evaluation_mode\": EVALUATION_MODE,\n",
    "    \"n_samples\": len(eval_df),\n",
    "    \"seed\": SEED,\n",
    "    \"max_target_len\": MAX_TARGET_LEN,\n",
    "    \"temperature\": TEMPERATURE,\n",
    "    \"models_evaluated\": list(results_by_model.keys()),\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "}\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"evaluation_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(eval_metadata, f, indent=2)\n",
    "print(f\"\\n‚úì Saved evaluation metadata to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPERIMENT 3 ‚Äî FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Evaluation Configuration:\n",
      "  Mode: full\n",
      "  Test samples: 819\n",
      "  Models evaluated: 5\n",
      "\n",
      "Generation Parameters:\n",
      "  Max target length: 64 (aligned with Experiments 1 & 2)\n",
      "  Temperature: 0.2\n",
      "\n",
      "Test Set Performance (sorted by ROUGE-L):\n",
      "\n",
      "  gemini_25_flash:\n",
      "    ROUGE-1: 44.60\n",
      "    ROUGE-2: 17.85\n",
      "    ROUGE-L: 35.49\n",
      "    (n=819 samples)\n",
      "\n",
      "  qwen25_72b:\n",
      "    ROUGE-1: 44.15\n",
      "    ROUGE-2: 17.31\n",
      "    ROUGE-L: 35.17\n",
      "    (n=789 samples)\n",
      "\n",
      "  claude_45_haiku:\n",
      "    ROUGE-1: 43.62\n",
      "    ROUGE-2: 16.55\n",
      "    ROUGE-L: 34.58\n",
      "    (n=819 samples)\n",
      "\n",
      "  kimi_k2:\n",
      "    ROUGE-1: 41.42\n",
      "    ROUGE-2: 13.22\n",
      "    ROUGE-L: 32.36\n",
      "    (n=819 samples)\n",
      "\n",
      "  gpt5_mini:\n",
      "    ROUGE-1: 41.56\n",
      "    ROUGE-2: 14.34\n",
      "    ROUGE-L: 32.15\n",
      "    (n=819 samples)\n",
      "\n",
      "  Best Model: gemini_25_flash (ROUGE-L: 35.49)\n",
      "\n",
      "  Fastest Model: gemini_25_flash (mean: 0.65s)\n",
      "\n",
      "Artifacts saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier\n",
      "  - ROUGE summary: rouge_summary.csv\n",
      "  - Latency summary: latency_summary.csv\n",
      "  - Test results: test_results.csv\n",
      "  - Predictions: predictions/\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT 3 ‚Äî FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nEvaluation Configuration:\")\n",
    "print(f\"  Mode: {EVALUATION_MODE}\")\n",
    "print(f\"  Test samples: {len(eval_df)}\")\n",
    "print(f\"  Models evaluated: {len(results_by_model)}\")\n",
    "\n",
    "print(f\"\\nGeneration Parameters:\")\n",
    "print(f\"  Max target length: {MAX_TARGET_LEN} (aligned with Experiments 1 & 2)\")\n",
    "print(f\"  Temperature: {TEMPERATURE}\")\n",
    "\n",
    "if rouge_df is not None and len(rouge_df) > 0:\n",
    "    print(f\"\\nTest Set Performance (sorted by ROUGE-L):\")\n",
    "    \n",
    "    for model in rouge_df.index:\n",
    "        r1 = rouge_df.loc[model, \"rouge1\"]\n",
    "        r2 = rouge_df.loc[model, \"rouge2\"]\n",
    "        rL = rouge_df.loc[model, \"rougeL\"]\n",
    "        n = rouge_df.loc[model, \"n_samples\"]\n",
    "        \n",
    "        print(f\"\\n  {model}:\")\n",
    "        print(f\"    ROUGE-1: {r1:.2f}\")\n",
    "        print(f\"    ROUGE-2: {r2:.2f}\")\n",
    "        print(f\"    ROUGE-L: {rL:.2f}\")\n",
    "        print(f\"    (n={int(n)} samples)\")\n",
    "    \n",
    "    # Best model\n",
    "    best_model = rouge_df.index[0]  # Already sorted by rougeL descending\n",
    "    best_rougeL = rouge_df.loc[best_model, \"rougeL\"]\n",
    "    \n",
    "    print(f\"\\n  Best Model: {best_model} (ROUGE-L: {best_rougeL:.2f})\")\n",
    "\n",
    "if latency_df is not None and len(latency_df) > 0:\n",
    "    fastest = latency_df[\"mean\"].idxmin()\n",
    "    fastest_latency = latency_df.loc[fastest, \"mean\"]\n",
    "    print(f\"\\n  Fastest Model: {fastest} (mean: {fastest_latency:.2f}s)\")\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {OUTPUT_DIR}\")\n",
    "print(f\"  - ROUGE summary: rouge_summary.csv\")\n",
    "print(f\"  - Latency summary: latency_summary.csv\")\n",
    "print(f\"  - Test results: test_results.csv\")\n",
    "print(f\"  - Predictions: predictions/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways-header",
   "metadata": {},
   "source": [
    "## 15. Key Takeaways\n",
    "\n",
    "### The Surprise: Fine-Tuned Local Models Win on ROUGE\n",
    "\n",
    "The most striking finding from this experiment is that **zero-shot frontier models underperform our fine-tuned local baselines** on automatic metrics:\n",
    "\n",
    "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Type |\n",
    "|-------|---------|---------|---------|------|\n",
    "| **BART (Exp 2)** | **50.27** | **25.71** | **42.13** | Fine-tuned local |\n",
    "| T5 (Exp 2) | 47.43 | 22.92 | 39.08 | Fine-tuned local |\n",
    "| Gemini 2.5 Flash | 44.60 | 17.85 | 35.49 | Zero-shot API |\n",
    "| Qwen 2.5 72B | 44.15 | 17.31 | 35.17 | Zero-shot API |\n",
    "| Claude 4.5 Haiku | 43.62 | 16.55 | 34.58 | Zero-shot API |\n",
    "| DistilBERT‚ÜíGPT2 (Exp 1) | 37.73 | 14.26 | 30.29 | Fine-tuned local |\n",
    "| Kimi K2 | 41.42 | 13.22 | 32.36 | Zero-shot API |\n",
    "| GPT-5 Mini | 41.56 | 14.34 | 32.15 | Zero-shot API |\n",
    "\n",
    "**Key observation:** The best frontier model (Gemini 2.5 Flash at ROUGE-L 35.49) falls **6.64 points below** fine-tuned BART (42.13). Even our \"Frankenstein\" DistilBERT‚ÜíDistilGPT2 model from Experiment 1 is competitive with GPT-5 Mini and Kimi K2.\n",
    "\n",
    "**Why does this happen?** \n",
    "\n",
    "Zero-shot models optimize for *general helpfulness*, not SAMSum-style summaries specifically. They tend to:\n",
    "- Write longer, more elaborate summaries than SAMSum's terse 15‚Äì30 word references\n",
    "- Include contextual framing (\"The group decided...\", \"After discussion...\")\n",
    "- Occasionally add interpretive commentary\n",
    "\n",
    "Fine-tuned models, by contrast, learn exactly what SAMSum annotators considered a \"good\" summary‚Äîmatching their length, style, and focus on outcomes over process.\n",
    "\n",
    "---\n",
    "\n",
    "### Price vs. Performance: No Clear Winner\n",
    "\n",
    "One might expect that more expensive models produce better summaries. The data tells a different story:\n",
    "\n",
    "| Model | Input Cost | Output Cost | ROUGE-L | Rank |\n",
    "|-------|------------|-------------|---------|------|\n",
    "| **Qwen 2.5 72B** | **$0.07/M** | **$0.26/M** | **35.17** | **2nd** |\n",
    "| GPT-5 Mini | $0.25/M | $2.00/M | 32.15 | 5th |\n",
    "| Gemini 2.5 Flash | $0.30/M | $2.50/M | 35.49 | 1st |\n",
    "| Kimi K2 | $0.39/M | $1.90/M | 32.36 | 4th |\n",
    "| Claude 4.5 Haiku | $1.00/M | $5.00/M | 34.58 | 3rd |\n",
    "\n",
    "**Key observations:**\n",
    "- **Qwen 2.5 72B** is the **cheapest** model ($0.07/M input) yet ranks **2nd** on ROUGE-L\n",
    "- **Claude 4.5 Haiku** is the **most expensive** (14√ó Qwen's input cost) yet ranks only **3rd**\n",
    "- **Gemini 2.5 Flash** offers the best ROUGE-L (35.49) at mid-tier pricing\n",
    "\n",
    "For dialogue summarization specifically, the open-weight Qwen model delivers near-frontier quality at a fraction of the cost. This challenges the assumption that \"bigger lab = better results.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Zero-Shot Summary Quality: Good but Verbose\n",
    "\n",
    "From the qualitative examples, frontier models produce **fluent, accurate summaries** that capture the main points. The issue is style mismatch, not comprehension.\n",
    "\n",
    "**Example 1 (Test ID 432 ‚Äî Tattoo Parlor):**\n",
    "\n",
    "| Source | Summary |\n",
    "|--------|---------|\n",
    "| **Human** | \"Javier was initially eager to have a tattoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tattoo done in Colombia.\" |\n",
    "| **BART** | \"Javier will get a Warsaw ink tattoo back in colombia.\" |\n",
    "| **Gemini** | \"Javier asked Judie for English-speaking tattoo parlor recommendations. Judie suggested Warsaw Ink, but Javier decided against it due to the high price.\" |\n",
    "| **GPT-5 Mini** | \"Javier asks for English-speaking tattoo parlors; Judie recommends Warsaw Ink and says her girlfriend got a tattoo there for $1000, so Javier decides to get tattooed in Colombia instead.\" |\n",
    "\n",
    "The frontier models tell the *story* well‚ÄîGPT-5 Mini even includes the price point ($1000) that explains Javier's decision. But ROUGE penalizes the extra words that don't appear in the reference.\n",
    "\n",
    "**Example 2 (Test ID 86 ‚Äî New Year's Eve Planning):**\n",
    "\n",
    "| Source | Summary |\n",
    "|--------|---------|\n",
    "| **Human** | \"Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\" |\n",
    "| **BART** | \"Olafur and Nathalie will go to Tiffany's party for New Year's Eve.\" |\n",
    "| **Gemini** | \"The group decided to go to a club in Soho for New Year's Eve, after considering opera and a 'Breakfast at Tiffany's' party. They need to buy tickets soon.\" |\n",
    "| **Kimi K2** | \"Group agrees on a 'classy' New Year's Eve: they'll buy tickets for the Breakfast-at-Tiffany's-themed party at Soho club.\" |\n",
    "\n",
    "Notice how BART is concise but drops Zoe entirely. The frontier models capture more context (the opera discussion, the ticket purchase) but use more words doing so. Kimi K2 even preserves the \"classy\" requirement that was important to Nathalie.\n",
    "\n",
    "**Example 3 (Test ID 417 ‚Äî Cancelled Meeting):**\n",
    "\n",
    "| Source | Summary |\n",
    "|--------|---------|\n",
    "| **Human** | \"Miranda can't make her meeting with Stephanie as she has to work.\" |\n",
    "| **BART** | \"Miranda has to work 20 hours a day.\" |\n",
    "| **Claude** | \"Miranda requests to cancel tomorrow's meeting due to work obligations. Stephanie agrees after Miranda explains her demanding schedule as a young doctor.\" |\n",
    "| **Kimi K2** | \"Miranda canceled tomorrow's meeting due to work; Stephanie accepted after some teasing about doctors' grueling hours.\" |\n",
    "\n",
    "Here BART misses the point entirely‚Äîfocusing on the \"20 hours\" detail rather than the meeting cancellation. Claude and Kimi K2 both capture the actual outcome (meeting cancelled, Stephanie agreed) plus the interpersonal dynamic. This is a case where the frontier models genuinely outperform on *semantic accuracy* even if ROUGE doesn't reflect it.\n",
    "\n",
    "---\n",
    "\n",
    "### Latency: Faster Than Expected, but Variable\n",
    "\n",
    "| Model | Mean Latency | P50 | P95 | Max |\n",
    "|-------|-------------|-----|-----|-----|\n",
    "| **Gemini 2.5 Flash** | **0.65s** | 0.62s | 0.81s | 2.65s |\n",
    "| GPT-5 Mini | 1.20s | 1.13s | 1.64s | 5.81s |\n",
    "| Claude 4.5 Haiku | 1.72s | 1.63s | 2.41s | 11.45s |\n",
    "| Kimi K2 | 2.20s | 1.18s | 6.34s | 11.42s |\n",
    "| Qwen 2.5 72B | 2.95s | 2.17s | 8.09s | 14.89s |\n",
    "\n",
    "**Comparison to local models:**\n",
    "- BART (Exp 2): 0.20s mean\n",
    "- T5 (Exp 2): 0.23s mean\n",
    "- DistilBERT‚ÜíGPT2 (Exp 1): 0.40s mean\n",
    "\n",
    "The fastest API model (Gemini 2.5 Flash at 0.65s) is **~3√ó slower** than fine-tuned BART running locally. For batch processing, this adds up quickly‚Äîsummarizing 1,000 conversations takes ~11 minutes with Gemini vs ~3 minutes with local BART.\n",
    "\n",
    "**Latency observations:**\n",
    "- **Gemini 2.5 Flash** lives up to its \"Flash\" name‚Äîfastest by a wide margin\n",
    "- **Chinese models (Kimi K2, Qwen)** showed higher variance, likely due to geographic routing from US-based testing\n",
    "- **Tail latency matters:** P95 values reach 6‚Äì8s for some models, which could cause timeouts in production\n",
    "\n",
    "---\n",
    "\n",
    "### Reliability: Mostly Solid, One Outlier\n",
    "\n",
    "Most models completed all 819 test examples without errors. The exception:\n",
    "\n",
    "- **Qwen 2.5 72B:** 30 errors (3.7% failure rate)\n",
    "\n",
    "These failures were API timeouts or malformed responses, not content issues. Despite its low cost and strong ROUGE scores, Qwen's reliability would need monitoring in production. The US-based frontier providers (OpenAI, Google, Anthropic) had zero failures across all test examples.\n",
    "\n",
    "---\n",
    "\n",
    "### Cost Projection: The Real Math\n",
    "\n",
    "For a messaging platform at scale, let's estimate costs for summarizing 1M conversations/month:\n",
    "\n",
    "**Assumptions:**\n",
    "- Average dialogue: ~100 words ‚Üí ~150 tokens input\n",
    "- Average summary: ~25 words ‚Üí ~40 tokens output\n",
    "- 1M conversations/month\n",
    "\n",
    "| Model | Monthly Input Cost | Monthly Output Cost | **Total/Month** |\n",
    "|-------|-------------------|--------------------:|----------------:|\n",
    "| Qwen 2.5 72B | $10.50 | $10.40 | **$20.90** |\n",
    "| GPT-5 Mini | $37.50 | $80.00 | **$117.50** |\n",
    "| Gemini 2.5 Flash | $45.00 | $100.00 | **$145.00** |\n",
    "| Kimi K2 | $58.50 | $76.00 | **$134.50** |\n",
    "| Claude 4.5 Haiku | $150.00 | $200.00 | **$350.00** |\n",
    "\n",
    "**vs. Fine-tuned local model:**\n",
    "- One-time training cost: ~$10‚Äì50 in GPU time\n",
    "- Inference: Free (your own hardware)\n",
    "- Monthly cost at scale: **~$0** (just electricity)\n",
    "\n",
    "At 1M conversations/month, even the cheapest API model (Qwen) costs ~$250/year. Claude would cost ~$4,200/year. Fine-tuned BART costs essentially nothing after the initial training investment.\n",
    "\n",
    "---\n",
    "\n",
    "### The Real Trade-off\n",
    "\n",
    "This experiment reveals that the choice between fine-tuned local models and frontier APIs isn't primarily about quality‚Äîit's about operational trade-offs:\n",
    "\n",
    "| Factor | Fine-Tuned Local | Zero-Shot API |\n",
    "|--------|-----------------|---------------|\n",
    "| **ROUGE scores** | Higher (style-matched) | Lower (verbose) |\n",
    "| **Summary fluency** | Good | Excellent |\n",
    "| **Semantic accuracy** | Sometimes misses nuance | Often more complete |\n",
    "| **Latency** | 0.2‚Äì0.4s | 0.6‚Äì3.0s |\n",
    "| **Cost at 1M/month** | ~$0 | $21‚Äì350 |\n",
    "| **Privacy** | Data stays local | Data leaves infra |\n",
    "| **Setup effort** | Hours of training | Minutes of prompting |\n",
    "| **Customization** | Full control | Prompt engineering only |\n",
    "| **Reliability** | Deterministic | Provider-dependent |\n",
    "\n",
    "For a quick prototype or low-volume use case, API models are the obvious choice‚Äîespecially Qwen at $0.07/M input. For production at scale with specific style requirements, fine-tuning wins decisively.\n",
    "\n",
    "---\n",
    "\n",
    "### What's Next\n",
    "\n",
    "The final comparison notebook will:\n",
    "- Consolidate all ROUGE and latency metrics into unified tables\n",
    "- Analyze error patterns across all three experiments\n",
    "- Discuss deployment trade-offs in more depth\n",
    "- Provide final recommendations for the \"Acme Communications\" use case\n",
    "\n",
    "For now, the key insight is clear: **fine-tuning matters for metrics, but zero-shot models aren't wrong‚Äîthey're just different.** Even relatively small models (BART at 139M parameters, T5 at 60M) can outperform frontier giants on ROUGE when properly trained. But as the qualitative examples show, ROUGE doesn't tell the whole story. Sometimes the verbose, context-rich frontier summary is actually *better*‚Äîit just doesn't match the reference annotator's style.\n",
    "\n",
    "The \"just use GPT\" approach is convenient, but it's not a free lunch‚Äîand for this task, the lunch you get depends heavily on how you measure \"good.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
