{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# ![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "---\n",
    "# Experiment 3 ‚Äî Frontier LLMs via OpenRouter API\n",
    "### Zero-Shot Dialogue Summarization with GPT, Claude, Gemini, and More\n",
    "---\n",
    "\n",
    "This notebook implements **Experiment 3** for the capstone project:\n",
    "\n",
    "**Goal:**  \n",
    "Evaluate frontier large language models on dialogue summarization using the OpenRouter API:\n",
    "\n",
    "- **OpenAI GPT-5 family** (nano, mini, full)\n",
    "- **OpenAI open-weight models** (20B, 120B)\n",
    "- **Google Gemini 2.5 Flash**\n",
    "- **Anthropic Claude 4.5 Sonnet**\n",
    "- **Qwen 2.5 72B**\n",
    "\n",
    "Unlike Experiments 1 and 2 which fine-tune models locally, this experiment uses\n",
    "**zero-shot prompting** ‚Äî no training, just inference via API calls.\n",
    "\n",
    "This establishes the **upper-bound performance baseline** for the project.\n",
    "\n",
    "**What This Notebook Covers:**\n",
    "1. Configuration and API setup\n",
    "2. Loading SAMSum test data\n",
    "3. Prompt construction for zero-shot summarization\n",
    "4. Running API calls (with caching and retry logic)\n",
    "5. ROUGE evaluation on **test set**\n",
    "6. Latency analysis\n",
    "7. Qualitative examples and model comparison\n",
    "\n",
    "**Note:** This notebook parallels the structure of `02_experiment1_bert_gpt2-revised.ipynb`\n",
    "and `03_experiment2_bart_t5-revised.ipynb` for consistency across experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/timnevits/projects/flatiron-language-models-for-ai\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Mute common warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "All hyperparameters and paths in one place for easy modification.\n",
    "\n",
    "**Important:** \n",
    "- Set `RUN_API_CALLS` to `False` to load cached results instead of making new API calls\n",
    "- Set `EVALUATION_MODE` to `\"full\"` for final results on the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "config-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "  Evaluation mode: test\n",
      "  Sample size: 10 examples\n",
      "  Models configured: 5\n",
      "  Output directory: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# API CALL FLAGS\n",
    "# =============================================================================\n",
    "\n",
    "# Master switch: Set False to load ALL results from cache (no API calls)\n",
    "RUN_API_CALLS = True\n",
    "\n",
    "# Per-model control: Set individual models to False to skip them\n",
    "# Only matters if RUN_API_CALLS = True\n",
    "MODELS_TO_RUN = {\n",
    "    \"gpt5_mini\":                False,\n",
    "    \"gemini_25_flash\":          False,\n",
    "    \"claude_45_haiku\":          False,\n",
    "    \"qwen25_72b\":               False,\n",
    "    \"kimi_k2\":                  False,\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION MODE\n",
    "# =============================================================================\n",
    "\n",
    "# \"test\": Use a small sample (fast, cheap) for development\n",
    "# \"full\": Use entire test set (slow, expensive) for final results\n",
    "EVALUATION_MODE = \"test\"  # Change to \"full\" for final evaluation\n",
    "\n",
    "# How many samples to use in \"test\" mode (ignored in \"full\" mode)\n",
    "TEST_MODE_SAMPLES = 10\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATION PARAMETERS\n",
    "# =============================================================================\n",
    "MAX_OUTPUT_TOKENS = 128   # Max tokens for model responses\n",
    "TEMPERATURE = 0.2         # Low temperature for consistent summaries\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL DEFINITIONS\n",
    "# =============================================================================\n",
    "OPENROUTER_MODELS = {\n",
    "    # OpenAI \n",
    "    \"gpt5_mini\":       \"openai/gpt-5-mini\",\n",
    "\n",
    "    # Google Gemini\n",
    "    \"gemini_25_flash\": \"google/gemini-2.5-flash\",\n",
    "\n",
    "    # Anthropic Claude\n",
    "    \"claude_45_haiku\": \"anthropic/claude-haiku-4.5\",\n",
    "\n",
    "    # Qwen\n",
    "    \"qwen25_72b\":      \"qwen/qwen-2.5-72b-instruct\",\n",
    "\n",
    "    # Moonshot Kimi K2\n",
    "    \"kimi_k2\":         \"moonshotai/kimi-k2-0905\",\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PATHS\n",
    "# =============================================================================\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"models\" / \"api-frontier\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CACHE_DIR = OUTPUT_DIR / \"cache\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_RESULTS_PATH = OUTPUT_DIR / \"test_results.csv\"\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\"\n",
    "PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"  Evaluation mode: {EVALUATION_MODE}\")\n",
    "if EVALUATION_MODE == \"test\":\n",
    "    print(f\"  Sample size: {TEST_MODE_SAMPLES} examples\")\n",
    "else:\n",
    "    print(f\"  Sample size: FULL test set\")\n",
    "print(f\"  Models configured: {len(OPENROUTER_MODELS)}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-client-header",
   "metadata": {},
   "source": [
    "## 3. OpenRouter API Client\n",
    "\n",
    "All API interaction code is defined here inline for transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "api-client-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OpenRouter API key loaded (ends with ...5990)\n",
      "\n",
      "API client functions defined.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OPENROUTER API CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "# Load API key from environment variable\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if OPENROUTER_API_KEY is None:\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENROUTER_API_KEY environment variable not set.\")\n",
    "    print(\"   Set it with: export OPENROUTER_API_KEY='your-key-here'\")\n",
    "    print(\"   API calls will fail until this is set.\")\n",
    "else:\n",
    "    print(f\"‚úì OpenRouter API key loaded (ends with ...{OPENROUTER_API_KEY[-4:]})\")\n",
    "\n",
    "# API configuration\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "REQUEST_TIMEOUT = (10, 60)  # (connect_timeout, read_timeout) in seconds\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Unique error prefix for identifying API failures in results\n",
    "ERROR_PREFIX = \"[__OPENROUTER_ERROR__:\"\n",
    "\n",
    "\n",
    "def _get_api_headers():\n",
    "    \"\"\"Get headers for API requests. Raises if key not set.\"\"\"\n",
    "    if OPENROUTER_API_KEY is None:\n",
    "        raise RuntimeError(\n",
    "            \"OPENROUTER_API_KEY environment variable not set.\\n\"\n",
    "            \"Set it with: export OPENROUTER_API_KEY='your-key-here'\"\n",
    "        )\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "\n",
    "def _get_reasoning_config(model: str) -> dict:\n",
    "    \"\"\"\n",
    "    Return reasoning config for models that support it.\n",
    "    Uses \"minimal\" effort to reduce latency/cost.\n",
    "    \"\"\"\n",
    "    base = model.split(\"/\")[-1].lower()\n",
    "    \n",
    "    # Models that support reasoning\n",
    "    reasoning_prefixes = (\"gpt-5-mini\")\n",
    "    \n",
    "    for prefix in reasoning_prefixes:\n",
    "        if base.startswith(prefix):\n",
    "            return {\"effort\": \"minimal\", \"exclude\": True}\n",
    "    \n",
    "    return {\"effort\": \"none\", \"exclude\": True}\n",
    "\n",
    "\n",
    "def call_openrouter_api(\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 128,\n",
    "    temperature: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Call an LLM via OpenRouter API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        OpenRouter model identifier (e.g., \"openai/gpt-5-nano\")\n",
    "    prompt : str\n",
    "        The user prompt to send\n",
    "    max_tokens : int\n",
    "        Maximum tokens in response\n",
    "    temperature : float\n",
    "        Sampling temperature (lower = more deterministic)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (response_text, latency_seconds)\n",
    "        On error, response_text starts with ERROR_PREFIX\n",
    "    \"\"\"\n",
    "    headers = _get_api_headers()\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You summarize chat conversations accurately and concisely.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    # Add reasoning config if applicable\n",
    "    reasoning_config = _get_reasoning_config(model)\n",
    "    if reasoning_config:\n",
    "        payload[\"reasoning\"] = reasoning_config\n",
    "    \n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                OPENROUTER_BASE_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=REQUEST_TIMEOUT,\n",
    "            )\n",
    "            t1 = time.time()\n",
    "            \n",
    "            # Small delay for rate limiting\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            try:\n",
    "                data = response.json()\n",
    "            except Exception as json_err:\n",
    "                raise RuntimeError(f\"Failed to parse JSON: {json_err}\")\n",
    "            \n",
    "            # Check HTTP status\n",
    "            if response.status_code != 200:\n",
    "                error_msg = data.get(\"error\", {}).get(\"message\", response.text) if data else response.text\n",
    "                raise RuntimeError(f\"API error {response.status_code}: {error_msg}\")\n",
    "            \n",
    "            # Extract response text\n",
    "            try:\n",
    "                if not data:\n",
    "                    raise ValueError(\"Empty response\")\n",
    "                \n",
    "                choices = data.get(\"choices\")\n",
    "                if not choices or len(choices) == 0:\n",
    "                    raise ValueError(f\"No choices in response: {data}\")\n",
    "                \n",
    "                message = choices[0].get(\"message\")\n",
    "                if not message:\n",
    "                    raise ValueError(f\"No message in choice: {choices[0]}\")\n",
    "                \n",
    "                text = message.get(\"content\", \"\")\n",
    "                \n",
    "                if not isinstance(text, str):\n",
    "                    text = str(text) if text is not None else \"\"\n",
    "                \n",
    "                if text.strip() == \"\":\n",
    "                    text = f\"{ERROR_PREFIX} EMPTY_RESPONSE]\"\n",
    "                    \n",
    "            except (KeyError, IndexError, TypeError, ValueError) as extract_err:\n",
    "                text = f\"{ERROR_PREFIX} MALFORMED_RESPONSE: {extract_err}]\"\n",
    "            \n",
    "            latency = t1 - t0\n",
    "            return text, latency\n",
    "            \n",
    "        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "            last_error = e\n",
    "            if attempt < MAX_RETRIES:\n",
    "                # Exponential backoff\n",
    "                time.sleep(0.5 * (2 ** (attempt - 1)))\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        except RuntimeError:\n",
    "            raise\n",
    "    \n",
    "    # All retries failed\n",
    "    return f\"{ERROR_PREFIX} Request failed after {MAX_RETRIES} attempts: {last_error}]\", float('nan')\n",
    "\n",
    "\n",
    "print(\"\\nAPI client functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 4. Load SAMSum Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "data-load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAMSum dataset...\n",
      "\n",
      "Dataset sizes:\n",
      "  Train:      14,731 examples\n",
      "  Validation: 818 examples\n",
      "  Test:       819 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load SAMSum dataset\n",
    "print(\"Loading SAMSum dataset...\")\n",
    "ds = load_dataset(\"knkarthick/samsum\")\n",
    "\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "val_df = ds[\"validation\"].to_pandas()\n",
    "test_df = ds[\"test\"].to_pandas()\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train:      {len(train_df):,} examples\")\n",
    "print(f\"  Validation: {len(val_df):,} examples\")\n",
    "print(f\"  Test:       {len(test_df):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "data-sample-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dialogue:\n",
      "----------------------------------------\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "H ...\n",
      "\n",
      "Sample summary:\n",
      "----------------------------------------\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "# Quick peek at the data\n",
    "print(\"Sample dialogue:\")\n",
    "print(\"-\" * 40)\n",
    "print(test_df.iloc[0][\"dialogue\"][:300], \"...\")\n",
    "print()\n",
    "print(\"Sample summary:\")\n",
    "print(\"-\" * 40)\n",
    "print(test_df.iloc[0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-sample-header",
   "metadata": {},
   "source": [
    "## 5. Prepare Evaluation Sample\n",
    "\n",
    "We use a consistent sample for reproducibility. The sample is cached to ensure\n",
    "the same examples are used across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eval-sample-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ TEST MODE: Using 10 examples (for development)\n",
      "   Change EVALUATION_MODE to 'full' for final results.\n",
      "\n",
      "‚úì Loaded cached sample of 10 examples\n",
      "  (seed=42, hash=f67f1de0...)\n",
      "\n",
      "Evaluation sample: 10 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13820547</td>\n",
       "      <td>Olafur: are we doing anything for New Year's E...</td>\n",
       "      <td>Nathalie, Olafur and Zoe are planning the New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13682134</td>\n",
       "      <td>Javier: Hey do you know any tattoo parlors ove...</td>\n",
       "      <td>Javier was initially eager to have a tatoo don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13611508</td>\n",
       "      <td>Martha: Hey, can I ask you a question?\\nOpheli...</td>\n",
       "      <td>Martha likes Ophelia's lenses and wants to buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13829744</td>\n",
       "      <td>Miranda: Hi S, could we cancel tomorrow's meet...</td>\n",
       "      <td>Miranda can't make her meeting with Stephanie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13864860</td>\n",
       "      <td>Sam: Where are you?\\nKate: downstairs\\nSam: al...</td>\n",
       "      <td>Kate and Jeff are downstairs in a room next to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           dialogue  \\\n",
       "0  13820547  Olafur: are we doing anything for New Year's E...   \n",
       "1  13682134  Javier: Hey do you know any tattoo parlors ove...   \n",
       "2  13611508  Martha: Hey, can I ask you a question?\\nOpheli...   \n",
       "3  13829744  Miranda: Hi S, could we cancel tomorrow's meet...   \n",
       "4  13864860  Sam: Where are you?\\nKate: downstairs\\nSam: al...   \n",
       "\n",
       "                                             summary  \n",
       "0  Nathalie, Olafur and Zoe are planning the New ...  \n",
       "1  Javier was initially eager to have a tatoo don...  \n",
       "2  Martha likes Ophelia's lenses and wants to buy...  \n",
       "3  Miranda can't make her meeting with Stephanie ...  \n",
       "4  Kate and Jeff are downstairs in a room next to...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_evaluation_sample(test_df, n_samples, seed, cache_dir):\n",
    "    \"\"\"\n",
    "    Get evaluation sample with caching for reproducibility.\n",
    "    \n",
    "    Saves metadata to ensure we're using consistent samples across runs.\n",
    "    \"\"\"\n",
    "    sample_path = cache_dir / \"evaluation_sample.csv\"\n",
    "    metadata_path = cache_dir / \"evaluation_sample_metadata.json\"\n",
    "    \n",
    "    # Create fingerprint of source data\n",
    "    source_len = len(test_df)\n",
    "    dialogue_lengths = test_df['dialogue'].str.len().tolist()\n",
    "    \n",
    "    fingerprint_data = {\n",
    "        \"length\": source_len,\n",
    "        \"dialogue_length_sum\": sum(dialogue_lengths),\n",
    "        \"first_dialogue\": test_df['dialogue'].iloc[0][:200] if source_len > 0 else \"\",\n",
    "        \"last_dialogue\": test_df['dialogue'].iloc[-1][:200] if source_len > 0 else \"\",\n",
    "    }\n",
    "    \n",
    "    data_fingerprint = hashlib.md5(\n",
    "        json.dumps(fingerprint_data, sort_keys=True).encode()\n",
    "    ).hexdigest()[:16]\n",
    "    \n",
    "    # Check for valid cached sample\n",
    "    if sample_path.exists() and metadata_path.exists():\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                saved_meta = json.load(f)\n",
    "            \n",
    "            if (saved_meta.get('n_samples') == n_samples and\n",
    "                saved_meta.get('seed') == seed and\n",
    "                saved_meta.get('data_hash') == data_fingerprint):\n",
    "                \n",
    "                existing_sample = pd.read_csv(sample_path)\n",
    "                \n",
    "                if len(existing_sample) == n_samples:\n",
    "                    print(f\"‚úì Loaded cached sample of {len(existing_sample)} examples\")\n",
    "                    print(f\"  (seed={seed}, hash={data_fingerprint[:8]}...)\")\n",
    "                    return existing_sample\n",
    "                    \n",
    "        except (json.JSONDecodeError, KeyError):\n",
    "            pass\n",
    "    \n",
    "    # Create new sample\n",
    "    if n_samples >= len(test_df):\n",
    "        sample = test_df.copy().reset_index(drop=True)\n",
    "        print(f\"Using full test set: {len(sample)} examples\")\n",
    "    else:\n",
    "        sample = test_df.sample(n=n_samples, random_state=seed).reset_index(drop=True)\n",
    "        print(f\"Created sample of {len(sample)} examples (seed={seed})\")\n",
    "    \n",
    "    # Save sample and metadata\n",
    "    sample.to_csv(sample_path, index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        'n_samples': n_samples,\n",
    "        'seed': seed,\n",
    "        'data_hash': data_fingerprint,\n",
    "        'source_len': source_len,\n",
    "        'created_at': pd.Timestamp.now().isoformat(),\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved to cache: {sample_path.name}\")\n",
    "    \n",
    "    return sample\n",
    "\n",
    "\n",
    "# Determine sample size based on evaluation mode\n",
    "if EVALUATION_MODE == \"full\":\n",
    "    N_SAMPLES = len(test_df)\n",
    "    print(f\"\\nüìä FULL EVALUATION MODE: Using ALL {N_SAMPLES} test examples\")\n",
    "    print(f\"   ‚ö†Ô∏è  This will take a while and cost more in API calls!\\n\")\n",
    "else:\n",
    "    N_SAMPLES = TEST_MODE_SAMPLES\n",
    "    print(f\"\\nüß™ TEST MODE: Using {N_SAMPLES} examples (for development)\")\n",
    "    print(f\"   Change EVALUATION_MODE to 'full' for final results.\\n\")\n",
    "\n",
    "# Get the evaluation sample\n",
    "eval_df = get_evaluation_sample(test_df, N_SAMPLES, SEED, CACHE_DIR)\n",
    "\n",
    "print(f\"\\nEvaluation sample: {len(eval_df)} examples\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-header",
   "metadata": {},
   "source": [
    "## 6. Prompt Construction\n",
    "\n",
    "We use a consistent zero-shot prompt across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "prompt-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt:\n",
      "============================================================\n",
      "Summarize the following conversation in 1-2 sentences. Keep it brief ‚Äî aim for 15-30 words. Focus on the main point, decisions, requests, or outcomes. Ignore small talk and do not add details that aren't supported by the text.\n",
      "\n",
      "DIALOGUE:\n",
      "-----\n",
      "Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thin...\n"
     ]
    }
   ],
   "source": [
    "def build_summarization_prompt(dialogue: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a zero-shot summarization prompt for frontier LLMs.\n",
    "    \n",
    "    The prompt is designed to produce concise summaries similar\n",
    "    to the SAMSum reference summaries (typically 15-30 words).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"Summarize the following conversation in 1-2 sentences. \"\n",
    "        \"Keep it brief ‚Äî aim for 15-30 words. \"\n",
    "        \"Focus on the main point, decisions, requests, or outcomes. \"\n",
    "        \"Ignore small talk and do not add details that aren't supported by the text.\\n\\n\"\n",
    "        \"DIALOGUE:\\n\"\n",
    "        \"-----\\n\"\n",
    "        f\"{dialogue}\\n\"\n",
    "        \"-----\\n\\n\"\n",
    "        \"SUMMARY:\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Test the prompt\n",
    "print(\"Example prompt:\")\n",
    "print(\"=\" * 60)\n",
    "example_prompt = build_summarization_prompt(eval_df['dialogue'].iloc[0])\n",
    "print(example_prompt[:500] + \"...\" if len(example_prompt) > 500 else example_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-calls-header",
   "metadata": {},
   "source": [
    "## 7. Run API Calls\n",
    "\n",
    "Generate summaries for each model. Results are cached per-model for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "api-helpers-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_model_cache_path(model_label: str) -> Path:\n",
    "    \"\"\"Get the cache path for a model's results.\"\"\"\n",
    "    return CACHE_DIR / f\"{model_label}_predictions.csv\"\n",
    "\n",
    "\n",
    "def load_cached_predictions(model_label: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Load cached predictions for a model if they exist.\"\"\"\n",
    "    path = get_model_cache_path(model_label)\n",
    "    if path.exists():\n",
    "        return pd.read_csv(path)\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_model_predictions(model_label: str, model_id: str, eval_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run API calls for a single model and return results DataFrame.\n",
    "    \n",
    "    Returns DataFrame with columns:\n",
    "    - dialogue\n",
    "    - reference_summary (human)\n",
    "    - model_summary (prediction)\n",
    "    - latency_seconds\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for idx, row in tqdm(eval_df.iterrows(), total=len(eval_df), desc=model_label):\n",
    "        dialogue = row[\"dialogue\"]\n",
    "        reference = row[\"summary\"]\n",
    "        prompt = build_summarization_prompt(dialogue)\n",
    "        \n",
    "        try:\n",
    "            prediction, latency = call_openrouter_api(\n",
    "                model=model_id,\n",
    "                prompt=prompt,\n",
    "                max_tokens=MAX_OUTPUT_TOKENS,\n",
    "                temperature=TEMPERATURE,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            prediction = f\"{ERROR_PREFIX} {e}]\"\n",
    "            latency = np.nan\n",
    "        \n",
    "        rows.append({\n",
    "            \"dialogue\": dialogue,\n",
    "            \"reference_summary\": reference,\n",
    "            \"model_summary\": prediction,\n",
    "            \"latency_seconds\": latency,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "api-calls-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING MODEL EVALUATIONS\n",
      "======================================================================\n",
      "gpt5_mini: Loaded 10 cached results\n",
      "gemini_25_flash: Loaded 10 cached results\n",
      "claude_45_haiku: Loaded 10 cached results\n",
      "qwen25_72b: Loaded 10 cached results\n",
      "kimi_k2: Loaded 10 cached results\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "  Models run (API calls):  0 - []\n",
      "  Models loaded (cache):   5 - ['gpt5_mini', 'gemini_25_flash', 'claude_45_haiku', 'qwen25_72b', 'kimi_k2']\n",
      "  Models skipped:          0 - []\n",
      "  Total models available:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RUNNING MODEL EVALUATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_by_model = {}\n",
    "models_run = []\n",
    "models_loaded = []\n",
    "models_skipped = []\n",
    "\n",
    "for label, model_id in OPENROUTER_MODELS.items():\n",
    "    cache_path = get_model_cache_path(label)\n",
    "    \n",
    "    # Check if we should run this model\n",
    "    should_run = RUN_API_CALLS and MODELS_TO_RUN.get(label, True)\n",
    "    \n",
    "    if should_run:\n",
    "        if cache_path.exists():\n",
    "            print(f\"\\n{label}: Cache exists, re-running (RUN_API_CALLS=True)\")\n",
    "        else:\n",
    "            print(f\"\\n{label}: Running API calls...\")\n",
    "        \n",
    "        # Run predictions\n",
    "        df_results = run_model_predictions(label, model_id, eval_df)\n",
    "        \n",
    "        # Cache results\n",
    "        df_results.to_csv(cache_path, index=False)\n",
    "        print(f\"  ‚úì Saved {len(df_results)} results to {cache_path.name}\")\n",
    "        \n",
    "        results_by_model[label] = df_results\n",
    "        models_run.append(label)\n",
    "        \n",
    "    else:\n",
    "        # Try to load from cache\n",
    "        cached = load_cached_predictions(label)\n",
    "        \n",
    "        if cached is not None:\n",
    "            results_by_model[label] = cached\n",
    "            models_loaded.append(label)\n",
    "            print(f\"{label}: Loaded {len(cached)} cached results\")\n",
    "        else:\n",
    "            models_skipped.append(label)\n",
    "            print(f\"{label}: No cache found (skipping)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Models run (API calls):  {len(models_run)} - {models_run}\")\n",
    "print(f\"  Models loaded (cache):   {len(models_loaded)} - {models_loaded}\")\n",
    "print(f\"  Models skipped:          {len(models_skipped)} - {models_skipped}\")\n",
    "print(f\"  Total models available:  {len(results_by_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rouge-header",
   "metadata": {},
   "source": [
    "## 8. ROUGE Evaluation\n",
    "\n",
    "Compute ROUGE scores using the same methodology as Experiments 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "rouge-setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_rouge(predictions: list, references: list) -> dict:\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores for predictions vs references.\n",
    "    \n",
    "    Uses the same configuration as Experiments 1 and 2 for consistency.\n",
    "    \n",
    "    Returns dict with rouge1, rouge2, rougeL, rougeLsum (as floats 0-1).\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    def clean_text(text):\n",
    "        if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "            return \"\"\n",
    "        return str(text).strip()\n",
    "    \n",
    "    predictions = [clean_text(p) for p in predictions]\n",
    "    references = [clean_text(r) for r in references]\n",
    "    \n",
    "    result = rouge_metric.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        use_stemmer=True,  # Same as experiments 1 & 2\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"ROUGE evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rouge-eval-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ROUGE EVALUATION\n",
      "======================================================================\n",
      "\n",
      "ROUGE Scores (sorted by ROUGE-L):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kimi_k2</th>\n",
       "      <td>0.433138</td>\n",
       "      <td>0.102342</td>\n",
       "      <td>0.345211</td>\n",
       "      <td>0.345084</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen25_72b</th>\n",
       "      <td>0.458951</td>\n",
       "      <td>0.106002</td>\n",
       "      <td>0.315847</td>\n",
       "      <td>0.316831</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_25_flash</th>\n",
       "      <td>0.458116</td>\n",
       "      <td>0.135972</td>\n",
       "      <td>0.315497</td>\n",
       "      <td>0.316654</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_45_haiku</th>\n",
       "      <td>0.427340</td>\n",
       "      <td>0.134305</td>\n",
       "      <td>0.293141</td>\n",
       "      <td>0.294403</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt5_mini</th>\n",
       "      <td>0.409726</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>0.283475</td>\n",
       "      <td>0.281346</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rouge1    rouge2    rougeL  rougeLsum  n_samples\n",
       "model                                                              \n",
       "kimi_k2          0.433138  0.102342  0.345211   0.345084         10\n",
       "qwen25_72b       0.458951  0.106002  0.315847   0.316831         10\n",
       "gemini_25_flash  0.458116  0.135972  0.315497   0.316654         10\n",
       "claude_45_haiku  0.427340  0.134305  0.293141   0.294403         10\n",
       "gpt5_mini        0.409726  0.117771  0.283475   0.281346         10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ROUGE EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rouge_scores = {}\n",
    "sample_counts = {}\n",
    "\n",
    "for label, df in results_by_model.items():\n",
    "    # Filter out API errors\n",
    "    valid_mask = ~df[\"model_summary\"].str.startswith(ERROR_PREFIX)\n",
    "    valid_df = df[valid_mask]\n",
    "    \n",
    "    if len(valid_df) == 0:\n",
    "        print(f\"‚ùå {label}: No valid responses (all failed)\")\n",
    "        continue\n",
    "    \n",
    "    error_count = len(df) - len(valid_df)\n",
    "    if error_count > 0:\n",
    "        error_pct = error_count / len(df) * 100\n",
    "        print(f\"‚ö†Ô∏è  {label}: {error_count} errors ({error_pct:.1f}%), evaluating {len(valid_df)} responses\")\n",
    "    \n",
    "    # Compute ROUGE\n",
    "    scores = compute_rouge(\n",
    "        predictions=valid_df[\"model_summary\"].tolist(),\n",
    "        references=valid_df[\"reference_summary\"].tolist(),\n",
    "    )\n",
    "    \n",
    "    rouge_scores[label] = scores\n",
    "    sample_counts[label] = len(valid_df)\n",
    "\n",
    "# Create summary DataFrame\n",
    "if rouge_scores:\n",
    "    rouge_df = pd.DataFrame.from_dict(rouge_scores, orient=\"index\")\n",
    "    rouge_df.index.name = \"model\"\n",
    "    rouge_df[\"n_samples\"] = pd.Series(sample_counts)\n",
    "    rouge_df = rouge_df.sort_values(by=\"rougeL\", ascending=False)\n",
    "    \n",
    "    # Check for comparability\n",
    "    min_samples = rouge_df[\"n_samples\"].min()\n",
    "    max_samples = rouge_df[\"n_samples\"].max()\n",
    "    \n",
    "    if min_samples != max_samples:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚ö†Ô∏è  COMPARABILITY WARNING\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Models evaluated on different sample sizes ({min_samples} to {max_samples})\")\n",
    "        print(\"ROUGE scores may not be directly comparable.\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nROUGE Scores (sorted by ROUGE-L):\")\n",
    "    display(rouge_df)\n",
    "    \n",
    "else:\n",
    "    rouge_df = None\n",
    "    print(\"No ROUGE scores to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latency-header",
   "metadata": {},
   "source": [
    "## 9. Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "latency-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LATENCY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Latency Statistics (seconds, sorted by mean):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>p50</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini_25_flash</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.698381</td>\n",
       "      <td>0.322236</td>\n",
       "      <td>0.511316</td>\n",
       "      <td>0.597121</td>\n",
       "      <td>0.819191</td>\n",
       "      <td>1.204699</td>\n",
       "      <td>1.590208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt5_mini</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.210712</td>\n",
       "      <td>0.230898</td>\n",
       "      <td>0.913929</td>\n",
       "      <td>1.113923</td>\n",
       "      <td>1.524753</td>\n",
       "      <td>1.589381</td>\n",
       "      <td>1.654009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_45_haiku</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.493662</td>\n",
       "      <td>0.182003</td>\n",
       "      <td>1.301841</td>\n",
       "      <td>1.506569</td>\n",
       "      <td>1.712912</td>\n",
       "      <td>1.744252</td>\n",
       "      <td>1.775593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kimi_k2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.522420</td>\n",
       "      <td>1.508272</td>\n",
       "      <td>0.342856</td>\n",
       "      <td>0.678711</td>\n",
       "      <td>3.593120</td>\n",
       "      <td>3.876249</td>\n",
       "      <td>4.159378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen25_72b</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.303752</td>\n",
       "      <td>1.787857</td>\n",
       "      <td>0.688436</td>\n",
       "      <td>1.483659</td>\n",
       "      <td>4.827748</td>\n",
       "      <td>5.421455</td>\n",
       "      <td>6.015162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean       std       min       p50       p90  \\\n",
       "model                                                                      \n",
       "gemini_25_flash   10.0  0.698381  0.322236  0.511316  0.597121  0.819191   \n",
       "gpt5_mini         10.0  1.210712  0.230898  0.913929  1.113923  1.524753   \n",
       "claude_45_haiku   10.0  1.493662  0.182003  1.301841  1.506569  1.712912   \n",
       "kimi_k2           10.0  1.522420  1.508272  0.342856  0.678711  3.593120   \n",
       "qwen25_72b        10.0  2.303752  1.787857  0.688436  1.483659  4.827748   \n",
       "\n",
       "                      p95       max  \n",
       "model                                \n",
       "gemini_25_flash  1.204699  1.590208  \n",
       "gpt5_mini        1.589381  1.654009  \n",
       "claude_45_haiku  1.744252  1.775593  \n",
       "kimi_k2          3.876249  4.159378  \n",
       "qwen25_72b       5.421455  6.015162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LATENCY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "latency_stats = {}\n",
    "\n",
    "for label, df in results_by_model.items():\n",
    "    latencies = df[\"latency_seconds\"].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(latencies) == 0:\n",
    "        continue\n",
    "    \n",
    "    stats = latencies.describe(percentiles=[0.5, 0.9, 0.95])\n",
    "    latency_stats[label] = stats\n",
    "\n",
    "if latency_stats:\n",
    "    latency_df = pd.DataFrame(latency_stats).T\n",
    "    latency_df.index.name = \"model\"\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    latency_df = latency_df.rename(columns={\n",
    "        \"50%\": \"p50\",\n",
    "        \"90%\": \"p90\",\n",
    "        \"95%\": \"p95\",\n",
    "    })\n",
    "    \n",
    "    # Sort by mean latency\n",
    "    latency_df = latency_df.sort_values(by=\"mean\", ascending=True)\n",
    "    \n",
    "    print(\"\\nLatency Statistics (seconds, sorted by mean):\")\n",
    "    display(latency_df[[\"count\", \"mean\", \"std\", \"min\", \"p50\", \"p90\", \"p95\", \"max\"]])\n",
    "    \n",
    "else:\n",
    "    latency_df = None\n",
    "    print(\"No latency data to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## 10. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "visualization-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/rouge_latency_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if rouge_df is not None and len(rouge_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROUGE scores bar chart\n",
    "    ax = axes[0]\n",
    "    rouge_plot = rouge_df[[\"rouge1\", \"rouge2\", \"rougeL\"]].sort_values(\"rougeL\", ascending=True)\n",
    "    rouge_plot.plot(kind=\"barh\", ax=ax)\n",
    "    ax.set_xlabel(\"Score\")\n",
    "    ax.set_title(\"Experiment 3 ‚Äî ROUGE Scores by Model\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "    \n",
    "    # Latency bar chart\n",
    "    ax = axes[1]\n",
    "    if latency_df is not None and len(latency_df) > 0:\n",
    "        latency_plot = latency_df[\"mean\"].sort_values(ascending=True)\n",
    "        latency_plot.plot(kind=\"barh\", ax=ax, color=\"coral\")\n",
    "        ax.set_xlabel(\"Mean Latency (seconds)\")\n",
    "        ax.set_title(\"Experiment 3 ‚Äî API Latency by Model\")\n",
    "        ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No latency data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.set_title(\"API Latency by Model\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = OUTPUT_DIR / \"rouge_latency_comparison.png\"\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to: {fig_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualitative-header",
   "metadata": {},
   "source": [
    "## 11. Test Set Qualitative Examples\n",
    "\n",
    "Examine sample outputs from each model to understand quality beyond ROUGE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "qualitative-single-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Qualitative Examples: gpt5_mini\n",
      "======================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Harris: How are U?\n",
      "Lena: Fine, U?\n",
      "Harris: Been better.\n",
      "Lena: ?\n",
      "Harris: My friend Aoki died yesterday.\n",
      "Lena: O No!\n",
      "Harris: Yeah.\n",
      "Lena: What happened?\n",
      "Harris: Not sure yet. Thinking the worst...\n",
      "Lena: O how awful!\n",
      "Harris: Yes.\n",
      "Lena: You just never know.\n",
      "Harris: True.\n",
      "Lena: Had you seen her lately?\n",
      "Harris: Not for a few months. She lives in Michigan.\n",
      "Lena: Oh, that's far.\n",
      "Harris: Not too far but far enough.\n",
      "Lena: Right.\n",
      "Harris: Got to go, mom's calling.\n",
      "Lena: K bi. Feel better!\n",
      "Harris: K will do\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Harris' friend, Aoki, who lives in Michigan, died yesterday. Harris hasn't seen her for a few months.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Harris tells Lena his friend Aoki died and he‚Äôs distraught and uncertain about the cause; Lena expresses sympathy and asks questions before Harris leaves.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did she pay?\n",
      "Judie: it was a 1000\n",
      "Javier: fuck\n",
      "Javier: let me just get a tatttoo back in colombia then, thx\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Javier asks for English-speaking tattoo parlors; Judie recommends Warsaw Ink and shares a photo of her girlfriend‚Äôs $1,000 tattoo, so Javier decides to get inked in Colombia instead.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just don't get anything at all then.\n",
      "Pete: OK.\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Pete will get a pear yogurt for Jen if they have it.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Pete asks which yogurt flavor Jen wants; she says pear only and to get nothing if pear isn't available.\n",
      "--------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "Qualitative Examples: gemini_25_flash\n",
      "======================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Harris: How are U?\n",
      "Lena: Fine, U?\n",
      "Harris: Been better.\n",
      "Lena: ?\n",
      "Harris: My friend Aoki died yesterday.\n",
      "Lena: O No!\n",
      "Harris: Yeah.\n",
      "Lena: What happened?\n",
      "Harris: Not sure yet. Thinking the worst...\n",
      "Lena: O how awful!\n",
      "Harris: Yes.\n",
      "Lena: You just never know.\n",
      "Harris: True.\n",
      "Lena: Had you seen her lately?\n",
      "Harris: Not for a few months. She lives in Michigan.\n",
      "Lena: Oh, that's far.\n",
      "Harris: Not too far but far enough.\n",
      "Lena: Right.\n",
      "Harris: Got to go, mom's calling.\n",
      "Lena: K bi. Feel better!\n",
      "Harris: K will do\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Harris' friend, Aoki, who lives in Michigan, died yesterday. Harris hasn't seen her for a few months.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Harris's friend Aoki died, and he is upset. He is unsure of the cause but suspects the worst.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did she pay?\n",
      "Judie: it was a 1000\n",
      "Javier: fuck\n",
      "Javier: let me just get a tatttoo back in colombia then, thx\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Javier asked Judie for English-speaking tattoo parlor recommendations. Judie suggested Warsaw Ink, but Javier decided against it due to the high price.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just don't get anything at all then.\n",
      "Pete: OK.\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Pete will get a pear yogurt for Jen if they have it.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Jen wants pear yogurt only; if unavailable, Pete should buy no yogurt.\n",
      "--------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "Qualitative Examples: claude_45_haiku\n",
      "======================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Harris: How are U?\n",
      "Lena: Fine, U?\n",
      "Harris: Been better.\n",
      "Lena: ?\n",
      "Harris: My friend Aoki died yesterday.\n",
      "Lena: O No!\n",
      "Harris: Yeah.\n",
      "Lena: What happened?\n",
      "Harris: Not sure yet. Thinking the worst...\n",
      "Lena: O how awful!\n",
      "Harris: Yes.\n",
      "Lena: You just never know.\n",
      "Harris: True.\n",
      "Lena: Had you seen her lately?\n",
      "Harris: Not for a few months. She lives in Michigan.\n",
      "Lena: Oh, that's far.\n",
      "Harris: Not too far but far enough.\n",
      "Lena: Right.\n",
      "Harris: Got to go, mom's calling.\n",
      "Lena: K bi. Feel better!\n",
      "Harris: K will do\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Harris' friend, Aoki, who lives in Michigan, died yesterday. Harris hasn't seen her for a few months.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Harris shared that his friend Aoki died yesterday and is uncertain about the cause. Lena offered condolences before Harris ended the conversation to attend to his mother.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did she pay?\n",
      "Judie: it was a 1000\n",
      "Javier: fuck\n",
      "Javier: let me just get a tatttoo back in colombia then, thx\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Javier asks Judie for English-speaking tattoo parlor recommendations. Judie suggests Warsaw Ink, where her girlfriend got a tattoo for 1000 (currency unspecified), prompting Javier to consider getting one in Colombia instead.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just don't get anything at all then.\n",
      "Pete: OK.\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Pete will get a pear yogurt for Jen if they have it.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Pete will buy pear yogurt for Jen if available; otherwise, he won't purchase any yogurt.\n",
      "--------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "Qualitative Examples: qwen25_72b\n",
      "======================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Harris: How are U?\n",
      "Lena: Fine, U?\n",
      "Harris: Been better.\n",
      "Lena: ?\n",
      "Harris: My friend Aoki died yesterday.\n",
      "Lena: O No!\n",
      "Harris: Yeah.\n",
      "Lena: What happened?\n",
      "Harris: Not sure yet. Thinking the worst...\n",
      "Lena: O how awful!\n",
      "Harris: Yes.\n",
      "Lena: You just never know.\n",
      "Harris: True.\n",
      "Lena: Had you seen her lately?\n",
      "Harris: Not for a few months. She lives in Michigan.\n",
      "Lena: Oh, that's far.\n",
      "Harris: Not too far but far enough.\n",
      "Lena: Right.\n",
      "Harris: Got to go, mom's calling.\n",
      "Lena: K bi. Feel better!\n",
      "Harris: K will do\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Harris' friend, Aoki, who lives in Michigan, died yesterday. Harris hasn't seen her for a few months.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Harris informs Lena about the recent death of his friend Aoki, expressing uncertainty about the cause and his emotional struggle.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did she pay?\n",
      "Judie: it was a 1000\n",
      "Javier: fuck\n",
      "Javier: let me just get a tatttoo back in colombia then, thx\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Javier considers getting a tattoo at Warsaw Ink but decides against it due to the high cost, opting for a cheaper option in Colombia instead.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just don't get anything at all then.\n",
      "Pete: OK.\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Pete will get a pear yogurt for Jen if they have it.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Pete will check for pear-flavored yogurt; if unavailable, he won't get any yogurt.\n",
      "--------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "Qualitative Examples: kimi_k2\n",
      "======================================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Harris: How are U?\n",
      "Lena: Fine, U?\n",
      "Harris: Been better.\n",
      "Lena: ?\n",
      "Harris: My friend Aoki died yesterday.\n",
      "Lena: O No!\n",
      "Harris: Yeah.\n",
      "Lena: What happened?\n",
      "Harris: Not sure yet. Thinking the worst...\n",
      "Lena: O how awful!\n",
      "Harris: Yes.\n",
      "Lena: You just never know.\n",
      "Harris: True.\n",
      "Lena: Had you seen her lately?\n",
      "Harris: Not for a few months. She lives in Michigan.\n",
      "Lena: Oh, that's far.\n",
      "Harris: Not too far but far enough.\n",
      "Lena: Right.\n",
      "Harris: Got to go, mom's calling.\n",
      "Lena: K bi. Feel better!\n",
      "Harris: K will do\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Harris' friend, Aoki, who lives in Michigan, died yesterday. Harris hasn't seen her for a few months.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Harris tells Lena his friend Aoki died yesterday; they briefly discuss the loss before Harris leaves.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Javier: Hey do you know any tattoo parlors over here with English speaking employees?\n",
      "Judie: Oh there's Warsaw ink\n",
      "Javier: the name sounds neat... have you had a tattoo done there?\n",
      "Judie: nope but my gf has\n",
      "Javier: got a pic?\n",
      "Judie: <file_photo>\n",
      "Javier: wow that looks amazing\n",
      "Javier: how much did she pay?\n",
      "Judie: it was a 1000\n",
      "Javier: fuck\n",
      "Javier: let me just get a tatttoo back in colombia then, thx\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Javier was initially eager to have a tatoo done at Warsaw Ink but the price turned out to be too high. Javier decided to have a tatoo done in Colombia.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Javier asked about English-speaking tattoo parlors; Judie recommended Warsaw Ink, but the 1000 price tag sent him back to Colombia.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "[DIALOGUE]\n",
      "Pete: What flavour yogurt did you want again? My brain is like a sieve today.\n",
      "Jen: Pear but only if they've got it. Otherwise don't worry about it.\n",
      "Pete: I'll have a look around. If they don't have pear can I get a different flavour?\n",
      "Jen: I don't like any other flavour. If they don't have pear just don't get anything at all then.\n",
      "Pete: OK.\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Pete will get a pear yogurt for Jen if they have it.\n",
      "\n",
      "[MODEL SUMMARY]\n",
      "Jen wants pear yogurt only; if it's unavailable, she prefers nothing.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def show_qualitative_examples(df, model_label, n=3, max_dialogue_chars=500, seed=42):\n",
    "    \"\"\"\n",
    "    Display qualitative examples for a single model.\n",
    "    \n",
    "    Shows dialogue, human reference, and model prediction side by side.\n",
    "    \"\"\"\n",
    "    # Filter out errors\n",
    "    valid_df = df[~df[\"model_summary\"].str.startswith(ERROR_PREFIX)]\n",
    "    \n",
    "    if len(valid_df) == 0:\n",
    "        print(f\"No valid examples for {model_label}\")\n",
    "        return\n",
    "    \n",
    "    # Sample examples\n",
    "    sample = valid_df.sample(n=min(n, len(valid_df)), random_state=seed)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Qualitative Examples: {model_label}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for i, (_, row) in enumerate(sample.iterrows(), 1):\n",
    "        dialogue = row[\"dialogue\"]\n",
    "        if len(dialogue) > max_dialogue_chars:\n",
    "            dialogue = dialogue[:max_dialogue_chars] + \"...\"\n",
    "        \n",
    "        print(f\"\\n--- Example {i} ---\")\n",
    "        print(f\"\\n[DIALOGUE]\\n{dialogue}\")\n",
    "        print(f\"\\n[HUMAN SUMMARY]\\n{row['reference_summary']}\")\n",
    "        print(f\"\\n[MODEL SUMMARY]\\n{row['model_summary']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Show examples for each model\n",
    "for label in results_by_model:\n",
    "    show_qualitative_examples(results_by_model[label], label, n=3, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## 12. Side-by-Side Model Comparison\n",
    "\n",
    "Compare how different models summarize the same dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "comparison-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SIDE-BY-SIDE MODEL COMPARISON\n",
      "======================================================================\n",
      "Found 10 dialogues common to all 5 models.\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 1\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Olafur: are we doing anything for New Year's Eve?\n",
      "Nathalie: I was thinking about something classy, like opera or sth like that\n",
      "Zoe: how much does it cost?\n",
      "Olafur: opera is not for me\n",
      "Nathalie: so what do you propose?\n",
      "Nathalie: it's 100$ \n",
      "Olafur: I was thinking about partying somewhere\n",
      "Nathalie: partying sounds fun, as long as it will be classy\n",
      "Zoe: <file_link>\n",
      "Zoe: Breakfast at Tiffany's party sou...\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Nathalie, Olafur and Zoe are planning the New Year's Eve. Nathalie wants something classy. Olafur doesn't like opera. They want to go to the Breakfast at Tiffany's party in Soho.\n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : They decide to celebrate New Year's Eve in a classy way by going to a Soho club/Breakfast at Tiffany's‚Äìstyle party instead of the opera, and agree to ...\n",
      "  gemini_25_flash     : The group decided to go to a club in Soho for New Year's Eve, after considering opera and a \"Breakfast at Tiffany's\" themed party. They need to buy ti...\n",
      "  claude_45_haiku     : The group decided to celebrate New Year's Eve at a classy club in Soho instead of the opera, and agreed to purchase tickets soon.\n",
      "  qwen25_72b          : The group decided to attend a \"Breakfast at Tiffany's\" themed party at a club in Soho for New Year's Eve, aiming for a classy yet fun experience.\n",
      "  kimi_k2             : They ditched the opera, agreed on a ‚ÄúBreakfast at Tiffany‚Äôs‚Äù party at a Soho club, and plan to buy tickets quickly.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 2\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don't, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it's from Crazy Lenses. They have quite reasonable prices and very fast shipping.\n",
      "Martha: Thanks!!! I'll check them :)\n",
      "Ophelia: No problem :)\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Martha likes Ophelia's lenses and wants to buy similar ones. Ophelia got them from Crazy Lenses.\n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : Martha asked where Ophelia got the lenses in her profile picture; Ophelia said they‚Äôre from Crazy Lenses, which has good prices and fast shipping.\n",
      "  gemini_25_flash     : Martha asked Ophelia about her contact lenses. Ophelia recommended Crazy Lenses, citing reasonable prices and fast shipping.\n",
      "  claude_45_haiku     : Martha asked Ophelia about lenses from her profile picture. Ophelia recommended Crazy Lenses, noting their reasonable prices and fast shipping.\n",
      "  qwen25_72b          : Ophelia recommended Crazy Lenses to Martha for buying similar lenses as seen in her profile picture.\n",
      "  kimi_k2             : Martha asked Ophelia where she got her lenses; Ophelia identified the brand as Crazy Lenses.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "COMPARISON EXAMPLE 3\n",
      "======================================================================\n",
      "\n",
      "[DIALOGUE]\n",
      "Miranda: Hi S, could we cancel tomorrow's meeting?\n",
      "Stephanie: again? what happened?\n",
      "Miranda: I have to work :(\n",
      "Stephanie: you work 20 hours a day!\n",
      "Miranda: that's what young doctors do\n",
      "Stephanie: they kill themselves working\n",
      "Miranda: no they come close to death but survive and it makes them immortal\n",
      "Stephanie: as long as you have an explanation :D\n",
      "\n",
      "[HUMAN SUMMARY]\n",
      "Miranda can't make her meeting with Stephanie as she has to work. \n",
      "\n",
      "[MODEL SUMMARIES]\n",
      "  gpt5_mini           : Miranda asks to cancel tomorrow‚Äôs meeting because she has to work long hours as a young doctor, and Stephanie reacts with concern and humor.\n",
      "  gemini_25_flash     : Miranda requested to cancel tomorrow's meeting due to work, which Stephanie accepted after Miranda's explanation.\n",
      "  claude_45_haiku     : Miranda requests to cancel tomorrow's meeting due to work obligations. Stephanie agrees after Miranda explains her demanding schedule as a young docto...\n",
      "  qwen25_72b          : Miranda cancels tomorrow's meeting due to work, explaining her busy schedule as a young doctor. Stephanie jokes about the demanding nature of the prof...\n",
      "  kimi_k2             : Miranda asked to cancel tomorrow‚Äôs meeting because of work; Stephanie reluctantly agreed.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SIDE-BY-SIDE MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(results_by_model) < 2:\n",
    "    print(\"Need at least 2 models for comparison.\")\n",
    "else:\n",
    "    # Find dialogues common to all models\n",
    "    dialogue_sets = {\n",
    "        label: set(df[\"dialogue\"].tolist())\n",
    "        for label, df in results_by_model.items()\n",
    "    }\n",
    "    \n",
    "    common_dialogues = set.intersection(*dialogue_sets.values())\n",
    "    \n",
    "    if len(common_dialogues) == 0:\n",
    "        print(\"No common dialogues across all models.\")\n",
    "    else:\n",
    "        print(f\"Found {len(common_dialogues)} dialogues common to all {len(results_by_model)} models.\")\n",
    "        \n",
    "        # Sample a few for comparison\n",
    "        n_compare = min(3, len(common_dialogues))\n",
    "        common_list = list(common_dialogues)\n",
    "        \n",
    "        rng = np.random.default_rng(SEED)\n",
    "        sample_indices = rng.choice(len(common_list), size=n_compare, replace=False)\n",
    "        sample_dialogues = [common_list[i] for i in sample_indices]\n",
    "        \n",
    "        # Get reference from first model's data\n",
    "        first_model = list(results_by_model.keys())[0]\n",
    "        first_df = results_by_model[first_model]\n",
    "        \n",
    "        for i, dialogue in enumerate(sample_dialogues, 1):\n",
    "            ref_row = first_df[first_df[\"dialogue\"] == dialogue].iloc[0]\n",
    "            reference = ref_row[\"reference_summary\"]\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"COMPARISON EXAMPLE {i}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # Truncate long dialogues\n",
    "            display_dialogue = dialogue[:400] + \"...\" if len(dialogue) > 400 else dialogue\n",
    "            print(f\"\\n[DIALOGUE]\\n{display_dialogue}\")\n",
    "            print(f\"\\n[HUMAN SUMMARY]\\n{reference}\")\n",
    "            print(f\"\\n[MODEL SUMMARIES]\")\n",
    "            \n",
    "            for label, df in results_by_model.items():\n",
    "                match = df[df[\"dialogue\"] == dialogue]\n",
    "                if len(match) > 0:\n",
    "                    summary = match.iloc[0][\"model_summary\"]\n",
    "                    # Truncate long summaries\n",
    "                    if len(summary) > 150:\n",
    "                        summary = summary[:150] + \"...\"\n",
    "                    print(f\"  {label:20s}: {summary}\")\n",
    "                else:\n",
    "                    print(f\"  {label:20s}: [NOT FOUND]\")\n",
    "            \n",
    "            print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-analysis-header",
   "metadata": {},
   "source": [
    "## 13. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "error-analysis-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Error Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>total_requests</th>\n",
       "      <th>errors</th>\n",
       "      <th>error_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt5_mini</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemini_25_flash</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude_45_haiku</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen25_72b</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimi_k2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  total_requests  errors error_rate\n",
       "0        gpt5_mini              10       0       0.0%\n",
       "1  gemini_25_flash              10       0       0.0%\n",
       "2  claude_45_haiku              10       0       0.0%\n",
       "3       qwen25_72b              10       0       0.0%\n",
       "4          kimi_k2              10       0       0.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "error_summary = []\n",
    "\n",
    "for label, df in results_by_model.items():\n",
    "    total = len(df)\n",
    "    errors = df[\"model_summary\"].str.startswith(ERROR_PREFIX).sum()\n",
    "    error_rate = errors / total * 100 if total > 0 else 0\n",
    "    \n",
    "    error_summary.append({\n",
    "        \"model\": label,\n",
    "        \"total_requests\": total,\n",
    "        \"errors\": errors,\n",
    "        \"error_rate\": f\"{error_rate:.1f}%\",\n",
    "    })\n",
    "    \n",
    "    # Show sample errors\n",
    "    if errors > 0:\n",
    "        error_samples = df[df[\"model_summary\"].str.startswith(ERROR_PREFIX)][\"model_summary\"].head(2).tolist()\n",
    "        print(f\"\\n{label}: {errors} errors ({error_rate:.1f}%)\")\n",
    "        for err in error_samples:\n",
    "            print(f\"  - {err[:80]}...\")\n",
    "\n",
    "error_df = pd.DataFrame(error_summary)\n",
    "print(\"\\nError Summary:\")\n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-results-header",
   "metadata": {},
   "source": [
    "## 14. Save Test Results\n",
    "\n",
    "Save final results for comparison with Experiments 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "save-results-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "‚úì Saved ROUGE summary to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/rouge_summary.csv\n",
      "‚úì Saved latency summary to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/latency_summary.csv\n",
      "‚úì Saved test results to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/test_results.csv\n",
      "\n",
      "Test Results (for comparison with Experiments 1 & 2):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimi_k2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.313766</td>\n",
       "      <td>10.234191</td>\n",
       "      <td>34.521090</td>\n",
       "      <td>34.508377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen25_72b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.895132</td>\n",
       "      <td>10.600222</td>\n",
       "      <td>31.584733</td>\n",
       "      <td>31.683086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemini_25_flash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.811580</td>\n",
       "      <td>13.597183</td>\n",
       "      <td>31.549697</td>\n",
       "      <td>31.665403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude_45_haiku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.733950</td>\n",
       "      <td>13.430465</td>\n",
       "      <td>29.314080</td>\n",
       "      <td>29.440342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt5_mini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.972597</td>\n",
       "      <td>11.777140</td>\n",
       "      <td>28.347514</td>\n",
       "      <td>28.134567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  test_loss     rouge1     rouge2     rougeL  rougeLsum\n",
       "0          kimi_k2        NaN  43.313766  10.234191  34.521090  34.508377\n",
       "1       qwen25_72b        NaN  45.895132  10.600222  31.584733  31.683086\n",
       "2  gemini_25_flash        NaN  45.811580  13.597183  31.549697  31.665403\n",
       "3  claude_45_haiku        NaN  42.733950  13.430465  29.314080  29.440342\n",
       "4        gpt5_mini        NaN  40.972597  11.777140  28.347514  28.134567"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Predictions saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/predictions\n",
      "  - gpt5_mini_test_predictions.csv\n",
      "  - gemini_25_flash_test_predictions.csv\n",
      "  - claude_45_haiku_test_predictions.csv\n",
      "  - qwen25_72b_test_predictions.csv\n",
      "  - kimi_k2_test_predictions.csv\n",
      "\n",
      "‚úì Saved evaluation metadata to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier/evaluation_metadata.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save ROUGE summary\n",
    "if rouge_df is not None:\n",
    "    rouge_summary_path = OUTPUT_DIR / \"rouge_summary.csv\"\n",
    "    rouge_df.to_csv(rouge_summary_path)\n",
    "    print(f\"\\n‚úì Saved ROUGE summary to: {rouge_summary_path}\")\n",
    "\n",
    "# Save latency summary\n",
    "if latency_df is not None:\n",
    "    latency_summary_path = OUTPUT_DIR / \"latency_summary.csv\"\n",
    "    latency_df.to_csv(latency_summary_path)\n",
    "    print(f\"‚úì Saved latency summary to: {latency_summary_path}\")\n",
    "\n",
    "# Save combined test results (for notebook 05 comparison)\n",
    "if rouge_df is not None:\n",
    "    test_results_data = []\n",
    "    \n",
    "    for model in rouge_df.index:\n",
    "        row = {\n",
    "            \"model\": model,\n",
    "            \"test_loss\": np.nan,  # N/A for API models\n",
    "            \"rouge1\": rouge_df.loc[model, \"rouge1\"] * 100,  # Convert to percentage\n",
    "            \"rouge2\": rouge_df.loc[model, \"rouge2\"] * 100,\n",
    "            \"rougeL\": rouge_df.loc[model, \"rougeL\"] * 100,\n",
    "            \"rougeLsum\": rouge_df.loc[model, \"rougeLsum\"] * 100,\n",
    "        }\n",
    "        test_results_data.append(row)\n",
    "    \n",
    "    test_results_df = pd.DataFrame(test_results_data)\n",
    "    test_results_df.to_csv(TEST_RESULTS_PATH, index=False)\n",
    "    print(f\"‚úì Saved test results to: {TEST_RESULTS_PATH}\")\n",
    "    \n",
    "    print(\"\\nTest Results (for comparison with Experiments 1 & 2):\")\n",
    "    display(test_results_df)\n",
    "\n",
    "# Save predictions for each model\n",
    "print(f\"\\n‚úì Predictions saved to: {PREDICTIONS_DIR}\")\n",
    "for label, df in results_by_model.items():\n",
    "    pred_path = PREDICTIONS_DIR / f\"{label}_test_predictions.csv\"\n",
    "    df.to_csv(pred_path, index=False)\n",
    "    print(f\"  - {pred_path.name}\")\n",
    "\n",
    "# Save evaluation metadata\n",
    "eval_metadata = {\n",
    "    \"evaluation_mode\": EVALUATION_MODE,\n",
    "    \"n_samples\": len(eval_df),\n",
    "    \"seed\": SEED,\n",
    "    \"models_evaluated\": list(results_by_model.keys()),\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "}\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"evaluation_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(eval_metadata, f, indent=2)\n",
    "print(f\"\\n‚úì Saved evaluation metadata to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 15. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPERIMENT 3 ‚Äî FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Evaluation Configuration:\n",
      "  Mode: test\n",
      "  Test samples: 10\n",
      "  Models evaluated: 5\n",
      "\n",
      "Generation Parameters:\n",
      "  Max output tokens: 128\n",
      "  Temperature: 0.2\n",
      "\n",
      "Test Set Performance (sorted by ROUGE-L):\n",
      "\n",
      "  kimi_k2:\n",
      "    ROUGE-1: 43.31\n",
      "    ROUGE-2: 10.23\n",
      "    ROUGE-L: 34.52\n",
      "    (n=10 samples)\n",
      "\n",
      "  qwen25_72b:\n",
      "    ROUGE-1: 45.90\n",
      "    ROUGE-2: 10.60\n",
      "    ROUGE-L: 31.58\n",
      "    (n=10 samples)\n",
      "\n",
      "  gemini_25_flash:\n",
      "    ROUGE-1: 45.81\n",
      "    ROUGE-2: 13.60\n",
      "    ROUGE-L: 31.55\n",
      "    (n=10 samples)\n",
      "\n",
      "  claude_45_haiku:\n",
      "    ROUGE-1: 42.73\n",
      "    ROUGE-2: 13.43\n",
      "    ROUGE-L: 29.31\n",
      "    (n=10 samples)\n",
      "\n",
      "  gpt5_mini:\n",
      "    ROUGE-1: 40.97\n",
      "    ROUGE-2: 11.78\n",
      "    ROUGE-L: 28.35\n",
      "    (n=10 samples)\n",
      "\n",
      "  Best Model: kimi_k2 (ROUGE-L: 34.52)\n",
      "\n",
      "  Fastest Model: gemini_25_flash (mean: 0.70s)\n",
      "\n",
      "Artifacts saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/api-frontier\n",
      "  - ROUGE summary: rouge_summary.csv\n",
      "  - Latency summary: latency_summary.csv\n",
      "  - Test results: test_results.csv\n",
      "  - Predictions: predictions/\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT 3 ‚Äî FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nEvaluation Configuration:\")\n",
    "print(f\"  Mode: {EVALUATION_MODE}\")\n",
    "print(f\"  Test samples: {len(eval_df)}\")\n",
    "print(f\"  Models evaluated: {len(results_by_model)}\")\n",
    "\n",
    "print(f\"\\nGeneration Parameters:\")\n",
    "print(f\"  Max output tokens: {MAX_OUTPUT_TOKENS}\")\n",
    "print(f\"  Temperature: {TEMPERATURE}\")\n",
    "\n",
    "if rouge_df is not None and len(rouge_df) > 0:\n",
    "    print(f\"\\nTest Set Performance (sorted by ROUGE-L):\")\n",
    "    \n",
    "    for model in rouge_df.index:\n",
    "        r1 = rouge_df.loc[model, \"rouge1\"] * 100\n",
    "        r2 = rouge_df.loc[model, \"rouge2\"] * 100\n",
    "        rL = rouge_df.loc[model, \"rougeL\"] * 100\n",
    "        n = rouge_df.loc[model, \"n_samples\"]\n",
    "        \n",
    "        print(f\"\\n  {model}:\")\n",
    "        print(f\"    ROUGE-1: {r1:.2f}\")\n",
    "        print(f\"    ROUGE-2: {r2:.2f}\")\n",
    "        print(f\"    ROUGE-L: {rL:.2f}\")\n",
    "        print(f\"    (n={int(n)} samples)\")\n",
    "    \n",
    "    # Best model\n",
    "    best_model = rouge_df.index[0]  # Already sorted by rougeL descending\n",
    "    best_rougeL = rouge_df.loc[best_model, \"rougeL\"] * 100\n",
    "    \n",
    "    print(f\"\\n  Best Model: {best_model} (ROUGE-L: {best_rougeL:.2f})\")\n",
    "\n",
    "if latency_df is not None and len(latency_df) > 0:\n",
    "    fastest = latency_df[\"mean\"].idxmin()\n",
    "    fastest_latency = latency_df.loc[fastest, \"mean\"]\n",
    "    print(f\"\\n  Fastest Model: {fastest} (mean: {fastest_latency:.2f}s)\")\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {OUTPUT_DIR}\")\n",
    "print(f\"  - ROUGE summary: rouge_summary.csv\")\n",
    "print(f\"  - Latency summary: latency_summary.csv\")\n",
    "print(f\"  - Test results: test_results.csv\")\n",
    "print(f\"  - Predictions: predictions/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways-header",
   "metadata": {},
   "source": [
    "## 16. Key Takeaways\n",
    "\n",
    "### Zero-Shot Performance\n",
    "\n",
    "**Approach:**\n",
    "- No training required ‚Äî pure inference via API\n",
    "- Single prompt design used for all models\n",
    "- Temperature 0.2 for consistent, deterministic outputs\n",
    "\n",
    "**Performance:**\n",
    "- *[Fill in after running with EVALUATION_MODE = \"full\"]*\n",
    "- Best performing model: [TBD]\n",
    "- ROUGE-L range: [TBD]\n",
    "\n",
    "### Comparison to Experiments 1 & 2\n",
    "\n",
    "These frontier models serve as the **upper-bound baseline**:\n",
    "- They have orders of magnitude more parameters\n",
    "- They were trained on vastly more data\n",
    "- They benefit from RLHF and instruction tuning\n",
    "\n",
    "The comparison in notebook 05 will show:\n",
    "- How close our fine-tuned models get to frontier performance\n",
    "- The trade-off between local fine-tuning vs API costs\n",
    "- Which fine-tuned architecture performs best relative to the gap\n",
    "\n",
    "### Cost & Latency Considerations\n",
    "\n",
    "**Trade-offs:**\n",
    "- API models: No training cost, but per-query inference cost\n",
    "- Fine-tuned models: Training cost, but free inference\n",
    "- For production: Break-even point depends on query volume\n",
    "\n",
    "**Latency:**\n",
    "- *[Fill in after running]*\n",
    "- Fastest model: [TBD]\n",
    "- Slowest model: [TBD]\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run with `EVALUATION_MODE = \"full\"` for final results\n",
    "- Compare all experiments in **notebook 05_evaluation_and_comparison.ipynb**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
