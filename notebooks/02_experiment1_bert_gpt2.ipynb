{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeec5534",
   "metadata": {},
   "source": [
    "# ![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "---\n",
    "# Experiment 1 ‚Äî BERT Encoder ‚Üí GPT-2 Decoder  \n",
    "### *‚ÄúFrankenstein‚Äù Encoder‚ÄìDecoder Summarization Model*\n",
    "---\n",
    "\n",
    "This notebook runs Experiment 1 for the project:\n",
    "\n",
    "**Goal:**  \n",
    "Evaluate a custom encoder‚Äìdecoder architecture where:\n",
    "\n",
    "- **Encoder:** `bert-base-uncased`  \n",
    "- **Decoder:** `gpt2` (augmented with cross-attention by HuggingFace)  \n",
    "\n",
    "This is intentionally *not* a pretrained summarization model.  \n",
    "The purpose is to test whether a glued-together architecture can learn dialogue summarization with curriculum training (warmup ‚Üí finetune).\n",
    "\n",
    "All reusable code is imported from `src/`, keeping this notebook clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e5fc7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad5129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable tokenizers parallelism warning\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure project root is importable\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "import sys\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Mem Efficient attention\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*copy construct from a tensor.*\"\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\".*better way to train encoder-decoder models.*\"\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*requires_grad=True.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Flash Efficient attention.*\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd8db7",
   "metadata": {},
   "source": [
    "## 2. Project Imports (Shared Utilities)\n",
    "We import:\n",
    "- SAMSum loader  \n",
    "- Dataset wrapper  \n",
    "- Model builder  \n",
    "- Trainer  \n",
    "- Qualitative preview  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fab902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timnevits/miniconda3/envs/rocm312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_samsum\n",
    "from src.data.preprocess import SummaryDataset\n",
    "from src.models.build_bert_gpt2 import build_bert_gpt2_model\n",
    "from src.train.trainer_seq2seq import train_model\n",
    "from src.eval.qualitative import qualitative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bb1e1",
   "metadata": {},
   "source": [
    "## 3. Constants & Hyperparameters  \n",
    "These values were chosen based on EDA and practical training needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f99288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup configuration:\n",
      "  Target batches:           3000\n",
      "  Gradient accumulation:    4\n",
      "  Expected weight updates:  750\n",
      "  (Actual numbers will be confirmed after data loading)\n"
     ]
    }
   ],
   "source": [
    "MAX_SOURCE_LEN = 512       # <= BERT's max_position_embeddings\n",
    "MAX_TARGET_LEN = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "GRAD_ACCUM = 4             # Accumulate gradients over 4 batches before updating\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "BRIDGE_LR = 1e-3\n",
    "\n",
    "RUN_TRAINING = True\n",
    "\n",
    "# =============================================================================\n",
    "# WARMUP CONFIGURATION\n",
    "# =============================================================================\n",
    "# The BERT encoder and GPT-2 decoder were pretrained separately.\n",
    "# The cross-attention layers that connect them are RANDOMLY INITIALIZED.\n",
    "# \n",
    "# Warmup trains ONLY the decoder (including cross-attention) while keeping\n",
    "# the encoder frozen. This helps the cross-attention layers learn to \"read\"\n",
    "# the encoder's output before we fine-tune everything together.\n",
    "#\n",
    "# WARMUP_TARGET_BATCHES: How many batches we WANT to process\n",
    "#   - If the dataset has fewer batches, warmup will end early (that's OK)\n",
    "#   - One epoch of SAMSum training ‚âà 14,732 batches (with batch_size=1)\n",
    "#   - So 3000 batches ‚âà 20% of one epoch\n",
    "#\n",
    "# Actual weight updates = batches / GRAD_ACCUM\n",
    "#   - With 3000 batches and GRAD_ACCUM=4: 750 weight updates\n",
    "# =============================================================================\n",
    "\n",
    "WARMUP_TARGET_BATCHES = 3000  # Target number of batches (may be less if dataset is smaller)\n",
    "\n",
    "# Pre-calculate expected updates (will be confirmed when we know dataset size)\n",
    "WARMUP_EXPECTED_UPDATES = WARMUP_TARGET_BATCHES // GRAD_ACCUM\n",
    "\n",
    "print(f\"Warmup configuration:\")\n",
    "print(f\"  Target batches:           {WARMUP_TARGET_BATCHES}\")\n",
    "print(f\"  Gradient accumulation:    {GRAD_ACCUM}\")\n",
    "print(f\"  Expected weight updates:  {WARMUP_EXPECTED_UPDATES}\")\n",
    "print(f\"  (Actual numbers will be confirmed after data loading)\")\n",
    "\n",
    "HIST_PATH = PROJECT_ROOT / \"models\" / \"bert-gpt2\" / \"history.csv\"\n",
    "BEST_DIR = PROJECT_ROOT / \"models\" / \"bert-gpt2\" / \"best\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d7ff0",
   "metadata": {},
   "source": [
    "## 4. Load SAMSum Data\n",
    "Data is pulled from `src/data/load_data.py`.  \n",
    "Local parquet cache is used automatically if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84967592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14731, 818, 819)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = load_samsum()\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366698e",
   "metadata": {},
   "source": [
    "## 5. Tokenizers & Datasets\n",
    "\n",
    "GPT-2 has **no pad token**, so we set pad = eos.  \n",
    "\n",
    "We then build the shared `SummaryDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19205bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Tokenizer Configuration:\n",
      "  pad_token: '<|endoftext|>' (id: 50256)\n",
      "  bos_token: '<|endoftext|>' (id: 50256)\n",
      "  eos_token: '<|endoftext|>' (id: 50256)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, GPT2Tokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer.model_max_length = 512  # native BERT limit\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# =============================================================================\n",
    "# FIX: GPT-2 doesn't have pad_token or bos_token by default\n",
    "# We need to set these explicitly for the encoder-decoder model to work\n",
    "# =============================================================================\n",
    "\n",
    "# Set pad token to eos token (common practice for GPT-2)\n",
    "if gpt_tokenizer.pad_token is None:\n",
    "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "    # Note: We use assignment instead of add_special_tokens to avoid resizing\n",
    "    # the embedding matrix unnecessarily when we're just aliasing an existing token\n",
    "\n",
    "# Set bos token to eos token as well (GPT-2 uses eos as a general delimiter)\n",
    "# This is crucial for decoder_start_token_id in encoder-decoder models\n",
    "if gpt_tokenizer.bos_token is None:\n",
    "    gpt_tokenizer.bos_token = gpt_tokenizer.eos_token\n",
    "\n",
    "# Verify the tokens are set correctly\n",
    "print(f\"GPT-2 Tokenizer Configuration:\")\n",
    "print(f\"  pad_token: '{gpt_tokenizer.pad_token}' (id: {gpt_tokenizer.pad_token_id})\")\n",
    "print(f\"  bos_token: '{gpt_tokenizer.bos_token}' (id: {gpt_tokenizer.bos_token_id})\")\n",
    "print(f\"  eos_token: '{gpt_tokenizer.eos_token}' (id: {gpt_tokenizer.eos_token_id})\")\n",
    "\n",
    "# Use RIGHT padding for training (labels need to be left-aligned)\n",
    "gpt_tokenizer.padding_side = \"right\"\n",
    "\n",
    "gpt_tokenizer.model_max_length = 1024\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch datasets\n",
    "train_dataset = SummaryDataset(train_df, bert_tokenizer, gpt_tokenizer,\n",
    "                               MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "val_dataset = SummaryDataset(val_df, bert_tokenizer, gpt_tokenizer,\n",
    "                             MAX_SOURCE_LEN, MAX_TARGET_LEN)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb66f7",
   "metadata": {},
   "source": [
    "## 6. Build the BERT‚ÜíGPT-2 Model\n",
    "This calls the modular builder in `src/models/build_bert_gpt2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d742879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['transformer.h.0.crossattention.c_attn.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.0.crossattention.q_attn.bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.0.ln_cross_attn.bias', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.1.crossattention.c_attn.bias', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.1.crossattention.q_attn.bias', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.1.ln_cross_attn.bias', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.10.crossattention.c_attn.bias', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.10.crossattention.q_attn.bias', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.10.ln_cross_attn.bias', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.11.crossattention.c_attn.bias', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.11.crossattention.q_attn.bias', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.11.ln_cross_attn.bias', 'transformer.h.11.ln_cross_attn.weight', 'transformer.h.2.crossattention.c_attn.bias', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.2.crossattention.q_attn.bias', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.2.ln_cross_attn.bias', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.3.crossattention.c_attn.bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.3.crossattention.q_attn.bias', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.3.ln_cross_attn.bias', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.4.crossattention.c_attn.bias', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.4.crossattention.q_attn.bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.4.ln_cross_attn.bias', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.5.crossattention.c_attn.bias', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.5.crossattention.q_attn.bias', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.5.ln_cross_attn.bias', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.6.crossattention.c_attn.bias', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.6.crossattention.q_attn.bias', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.6.ln_cross_attn.bias', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.7.crossattention.c_attn.bias', 'transformer.h.7.crossattention.c_attn.weight', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.7.crossattention.q_attn.bias', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.7.ln_cross_attn.bias', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.8.crossattention.c_attn.bias', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.8.crossattention.c_proj.bias', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.8.crossattention.q_attn.bias', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.8.ln_cross_attn.bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.9.crossattention.c_attn.bias', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.9.crossattention.q_attn.bias', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.9.ln_cross_attn.bias', 'transformer.h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/timnevits/miniconda3/envs/rocm312/lib/python3.12/site-packages/torch/nn/modules/module.py:1329: UserWarning: expandable_segments not supported on this platform (Triggered internally at /pytorch/c10/hip/HIPAllocatorConfig.h:29.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=2304, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=1536, nx=768)\n",
       "            (q_attn): Conv1D(nf=768, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=3072, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=3072)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_bert_gpt2_model(\n",
    "    gpt_pad_token_id=gpt_tokenizer.pad_token_id,\n",
    "    gpt_bos_token_id=gpt_tokenizer.bos_token_id,\n",
    "    decoder_tokenizer=gpt_tokenizer,\n",
    "    max_length=MAX_TARGET_LEN,\n",
    ").to(device)\n",
    "\n",
    "# Disable cache for gradient checkpointing\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Turn on gradient checkpointing\n",
    "model.encoder.gradient_checkpointing_enable()\n",
    "model.decoder.gradient_checkpointing_enable()\n",
    "\n",
    "# or, if your HF version supports it:\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a39f8",
   "metadata": {},
   "source": [
    "## 7. Optimizer (Warm-up ‚Üí Fine-tune)\n",
    "\n",
    "The training loop is shared, but **Experiment-1‚Äôs warmup logic is unique**.  \n",
    "We handle it here in the notebook and pass the correct optimizer into `train_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b4d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params in warmup: 244\n",
      "Decoder-only params: 244\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Phase 1 ‚Äî train decoder only (encoder frozen)\n",
    "for name, p in model.named_parameters():\n",
    "    if name.startswith(\"encoder.\"):\n",
    "        p.requires_grad = False\n",
    "    else:\n",
    "        p.requires_grad = True\n",
    "\n",
    "decoder_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "print(\"Trainable params in warmup:\", sum(p.requires_grad for p in model.parameters()))\n",
    "print(\"Decoder-only params:\", len(decoder_params))\n",
    "\n",
    "optimizer = optim.AdamW(decoder_params, lr=BRIDGE_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e211ed",
   "metadata": {},
   "source": [
    "## 8. Warm-Up Phase (Train Only Cross-Attention)\n",
    "\n",
    "We warm up for `WARMUP_TARGET_BATCHES` batches (or fewer if the dataset is smaller), then unfreeze the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40b6449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WARMUP PHASE\n",
      "============================================================\n",
      "Dataset size:        14731 batches\n",
      "Target batches:      3000\n",
      "Actual batches:      3000\n",
      "Gradient accum:      4\n",
      "Weight updates:      ~750\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timnevits/miniconda3/envs/rocm312/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:413: UserWarning: Using AOTriton backend for Efficient Attention forward... (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/attention.hip:1180.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/timnevits/miniconda3/envs/rocm312/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Using AOTriton backend for Efficient Attention backward... (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/attention_backward.hip:463.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Update  100 | Batch   400/3000 ( 13.3%) | Loss: 5.4998\n",
      "  Update  200 | Batch   800/3000 ( 26.7%) | Loss: 5.3703\n",
      "  Update  300 | Batch  1200/3000 ( 40.0%) | Loss: 5.1956\n",
      "  Update  400 | Batch  1600/3000 ( 53.3%) | Loss: 4.2455\n",
      "  Update  500 | Batch  2000/3000 ( 66.7%) | Loss: 4.6977\n",
      "  Update  600 | Batch  2400/3000 ( 80.0%) | Loss: 4.9083\n",
      "  Update  700 | Batch  2800/3000 ( 93.3%) | Loss: 3.8006\n",
      "------------------------------------------------------------\n",
      "Warmup complete!\n",
      "  Batches processed:    3000\n",
      "  Gradient updates:     750\n",
      "  Final loss:           4.0481\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if RUN_TRAINING:\n",
    "\n",
    "    # =================================================================\n",
    "    # WARMUP PHASE: Train decoder only (encoder frozen)\n",
    "    # =================================================================\n",
    "    \n",
    "    total_available_batches = len(train_loader)\n",
    "    \n",
    "    # Determine actual number of batches to process\n",
    "    # We can't process more batches than exist in the dataset\n",
    "    actual_warmup_batches = min(WARMUP_TARGET_BATCHES, total_available_batches)\n",
    "    actual_warmup_updates = actual_warmup_batches // GRAD_ACCUM\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"WARMUP PHASE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Dataset size:        {total_available_batches} batches\")\n",
    "    print(f\"Target batches:      {WARMUP_TARGET_BATCHES}\")\n",
    "    print(f\"Actual batches:      {actual_warmup_batches}\", end=\"\")\n",
    "    \n",
    "    if actual_warmup_batches < WARMUP_TARGET_BATCHES:\n",
    "        print(f\"  ‚ö†Ô∏è  (limited by dataset size)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    print(f\"Gradient accum:      {GRAD_ACCUM}\")\n",
    "    print(f\"Weight updates:      ~{actual_warmup_updates}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    batch_count = 0          # How many batches we've processed\n",
    "    gradient_updates = 0     # How many times we've updated weights\n",
    "    accumulated_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    loss_trace = []\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch_count += 1\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        scaled_loss = loss / GRAD_ACCUM\n",
    "        scaled_loss.backward()\n",
    "        \n",
    "        accumulated_loss += loss.item()\n",
    "\n",
    "        # Update weights every GRAD_ACCUM batches\n",
    "        if batch_count % GRAD_ACCUM == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            gradient_updates += 1\n",
    "            avg_loss = accumulated_loss / GRAD_ACCUM\n",
    "            loss_trace.append(avg_loss)\n",
    "            \n",
    "            # Progress update every 100 gradient updates\n",
    "            if gradient_updates % 100 == 0:\n",
    "                pct_complete = batch_count / actual_warmup_batches * 100\n",
    "                print(f\"  Update {gradient_updates:4d} | \"\n",
    "                      f\"Batch {batch_count:5d}/{actual_warmup_batches} ({pct_complete:5.1f}%) | \"\n",
    "                      f\"Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            accumulated_loss = 0.0\n",
    "\n",
    "        # Stop when we've processed enough batches\n",
    "        if batch_count >= actual_warmup_batches:\n",
    "            break\n",
    "    \n",
    "    # Handle any remaining gradients from incomplete accumulation\n",
    "    remaining = batch_count % GRAD_ACCUM\n",
    "    if remaining != 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        gradient_updates += 1\n",
    "        avg_loss = accumulated_loss / remaining\n",
    "        loss_trace.append(avg_loss)\n",
    "        print(f\"  Final partial update ({remaining} batches), Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Warmup complete!\")\n",
    "    print(f\"  Batches processed:    {batch_count}\")\n",
    "    print(f\"  Gradient updates:     {gradient_updates}\")\n",
    "    print(f\"  Final loss:           {loss_trace[-1]:.4f}\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa0179",
   "metadata": {},
   "source": [
    "## 9. Fine-Tune Phase (Unfreeze All Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65587b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "\n",
    "    # Unfreeze all parameters\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a7c7a",
   "metadata": {},
   "source": [
    "## 10. Full Training Loop  \n",
    "This uses the shared `train_model()` from `src/train/trainer_seq2seq.py`  \n",
    "which handles:\n",
    "- training epochs  \n",
    "- validation  \n",
    "- ROUGE metrics  \n",
    "- returns a summary DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25bbae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:32<00:00,  4.12it/s, loss=2.627] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:02<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 complete.\n",
      "  Train loss: 4.1439\n",
      "  Val loss:   4.0878\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:25<00:00,  4.13it/s, loss=3.784] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 complete.\n",
      "  Train loss: 3.6922\n",
      "  Val loss:   3.8542\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:22<00:00,  4.14it/s, loss=3.475] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:06<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 complete.\n",
      "  Train loss: 3.3778\n",
      "  Val loss:   3.7166\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:18<00:00,  4.14it/s, loss=3.171] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:04<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 complete.\n",
      "  Train loss: 3.1169\n",
      "  Val loss:   3.6231\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:20<00:00,  4.14it/s, loss=3.073] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 complete.\n",
      "  Train loss: 2.8912\n",
      "  Val loss:   3.5423\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:37<00:00,  4.12it/s, loss=4.232] \n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:28<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 complete.\n",
      "  Train loss: 2.6909\n",
      "  Val loss:   3.5186\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:27<00:00,  4.13it/s, loss=3.218]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:21<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 complete.\n",
      "  Train loss: 2.5114\n",
      "  Val loss:   3.4757\n",
      "  ‚úì New best validation loss!\n",
      "    Saving checkpoint to /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:31<00:00,  4.12it/s, loss=1.992]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:24<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 complete.\n",
      "  Train loss: 2.3470\n",
      "  Val loss:   3.5017\n",
      "  No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14731/14731 [59:45<00:00,  4.11it/s, loss=3.547]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 818/818 [19:41<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 complete.\n",
      "  Train loss: 2.1945\n",
      "  Val loss:   3.4895\n",
      "  No improvement for 2 epoch(s).\n",
      "\n",
      "üõë Early stopping triggered!\n",
      "\n",
      "üì¶ Reloading best model from epoch 7...\n",
      "  ‚úì Best model weights restored successfully.\n",
      "    Verified: Model is now from epoch 7\n",
      "  Saved training metadata to: /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best/training_metadata.json\n",
      "Best checkpoint saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/best\n",
      "Saved training history to: /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2/history.csv\n"
     ]
    }
   ],
   "source": [
    "if RUN_TRAINING:\n",
    "        \n",
    "    history_df = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        tokenizer=gpt_tokenizer,\n",
    "        device=device,\n",
    "        epochs=EPOCHS,\n",
    "        max_target_len=MAX_TARGET_LEN,\n",
    "        checkpoint_dir=str(BEST_DIR),\n",
    "        patience=2,\n",
    "        grad_accum_steps=GRAD_ACCUM, \n",
    "    )\n",
    "    print(\"Best checkpoint saved to:\", BEST_DIR)\n",
    "\n",
    "    # --- SAVE HISTORY CSV ---\n",
    "    \n",
    "    history_df.to_csv(HIST_PATH, index=False)\n",
    "    print(\"Saved training history to:\", HIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1659cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_TRAINING:\n",
    "    \n",
    "    print(\"Skipping training and loading best saved model...\")\n",
    "    from transformers import EncoderDecoderModel, GenerationConfig\n",
    "    import json\n",
    "\n",
    "    # Load Model\n",
    "    model = EncoderDecoderModel.from_pretrained(BEST_DIR).to(device)\n",
    "    \n",
    "    # Load Generation Config (if it was saved)\n",
    "    try:\n",
    "        saved_config = GenerationConfig.from_pretrained(BEST_DIR)\n",
    "        print(\"Found saved generation config.\")\n",
    "    except Exception:\n",
    "        saved_config = None\n",
    "        print(\"No saved generation config found.\")\n",
    "    \n",
    "    # ALWAYS set generation config to match current notebook settings\n",
    "    gen_cfg = model.generation_config\n",
    "    gen_cfg.pad_token_id = gpt_tokenizer.pad_token_id\n",
    "    gen_cfg.bos_token_id = gpt_tokenizer.bos_token_id\n",
    "    gen_cfg.max_length = MAX_TARGET_LEN\n",
    "    gen_cfg.min_length = 5\n",
    "    gen_cfg.no_repeat_ngram_size = 3\n",
    "    gen_cfg.early_stopping = True\n",
    "    gen_cfg.length_penalty = 2.0\n",
    "    gen_cfg.num_beams = 4\n",
    "    \n",
    "    print(f\"Generation config set: max_length={MAX_TARGET_LEN}\")\n",
    "\n",
    "    # Load training metadata (if available)\n",
    "    metadata_path = BEST_DIR / \"training_metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            training_metadata = json.load(f)\n",
    "        print(f\"Loaded training metadata:\")\n",
    "        print(f\"  Best epoch: {training_metadata.get('best_epoch')}\")\n",
    "        print(f\"  Weights from epoch: {training_metadata.get('weights_epoch')}\")\n",
    "        print(f\"  Note: {training_metadata.get('weights_note')}\")\n",
    "    else:\n",
    "        print(\"No training metadata found (older checkpoint format).\")\n",
    "\n",
    "    # Load History\n",
    "    history_df = pd.read_csv(HIST_PATH)\n",
    "    print(\"Loaded saved training history from:\", HIST_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240abaee",
   "metadata": {},
   "source": [
    "## 11. Loss Curves  \n",
    "(Optional small plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21299fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_df[\"epoch\"], history_df[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history_df[\"epoch\"], history_df[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Experiment 1 ‚Äî Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e99a46",
   "metadata": {},
   "source": [
    "## 12. Qualitative Examples  \n",
    "\n",
    "Shows 5 model summaries vs human summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea70393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5 qualitative samples (seed=42) ---\n",
      "ID 86\n",
      "DIALOGUE: Edd: wow, did you hear that they're transferring us to a different department? | Rose: whaaaaat :o | Rose: no! where'd you hear that? | Edd: well, it's quite official | Edd: Anderson just told us | Rose: and do you know what it changes for us? | Edd: they won't change the professors | Edd: but i know the paperwor ...\n",
      "HUMAN: Rose and Edd will be transferred to a new department. Their professors will not change but paperwork will become more difficult.\n",
      "MODEL: Eddie and Beatrice are going to give their university transfer to the professor. Beatrice is not sure if they need to change the university.    The university will change the paperwork. They will try to change their paperwork.  They will do the paperwork in the future, as Beatrice has already been given to the university, but it's not working for the university and they need more than the end of the current classes. They need to do it. They are not change the current students. They're going to change it now. They'll try to get more more more than they will change their current issues. \n",
      "--------------------------------------------------------------------------------\n",
      "ID 431\n",
      "DIALOGUE: Tom: Where is the \"Sala del Capitolo\" | Kevin: it's in the main building | Martin: The one with the huge round table | Tom: ok! I know. | Tom: Thx ...\n",
      "HUMAN: \"Sala del Capitolo\" Tom is looking for is in the main building.\n",
      "MODEL: Tom, Tom and Tom are in the capital of La Laira de la la Laira. Tom is in the top of the main house. Tom will be there in the city centre.    in the same place. Tom's place is in La La La la la la de la La la La La de la de La La Maro de la Maro. Tom has found a table on the right now. Tom found it in the main hall. Tom and they will have a table in the next to the main table. They will be in the right next to see the main La LaLa La La Santa La La\n",
      "--------------------------------------------------------------------------------\n",
      "ID 798\n",
      "DIALOGUE: Patricia: The rowing practice is cancelled! | Kate: Why?  | Lindsey: What a shame...  | Lindsey: I was really looking forward | Patricia: I just got this email | Patricia: <photo_file> | Kate: I also got it | Kate: I just saw it now | Patricia: Few of the members have injuries, some are sick | Patricia: And we cannot ...\n",
      "HUMAN: The rowing practice is cancelled. A few members have injuries and some are sick. People are sick in Kate's college.\n",
      "MODEL: Kate's training is cancelled, because she's not feeling well. She's not sure if she's going to the rugby club. Kate and Kate are worried about it. Kate is worried about the sport. Kate's team won't be able to be held.    Patricia's team has been injured.  The training schedule has been cancelled since the end of the year, but she's been cancelled. Kate won't go to the university. Kate, who has a sports conference. Kate has a few days ago. Kate had a sports disciplinary disciplinary disciplinary issues. Kate will be cancelled. She has been held. Kate. \n",
      "--------------------------------------------------------------------------------\n",
      "ID 497\n",
      "DIALOGUE: Tom: U OK? | Alex: Yeah, pretty good. U? | Tom: <file_gif> | Alex: hahaha so a hangover, huh? | Tom: Don‚Äôt tell me you‚Äôre surprised! Vodka was my middle name yesterday. | Alex: What can I say? Friday, baby! | Tom: So much fun, though | Alex: Yeah, you definitely had fun | Tom: :P | Alex: Especially when you called Er ...\n",
      "HUMAN: Tom and Alex had fun last night. They drank a lot and Tom has a hangover now. \n",
      "MODEL: Alex had a terrible hangover last Friday. He was drinking vodka on Friday. His girlfriend was drunk. Tom was drunk at Alex's. Alex is going to tell her about it.    Amber's going to cheer him up. Alex's going out with Alex.  Amber is going out on Friday to tell him about it again.  She's going back on Friday after work. Alex has a joke about it on Thursday.  she's sending Alex's sending him a fake message. He's sending her back from Alex's post on Friday morning. She's name.  he's name on Friday, but she's\n",
      "--------------------------------------------------------------------------------\n",
      "ID 805\n",
      "DIALOGUE: Patricia: Hello, here's the fair-trade brand I've been talking about <file_other> | Elle: Oh, thanks! | Florence: Looks great! | Patricia: I'm glad, I hope you enjoy it. The quality's really great and knowing where it came from makes it easier to spend the extra dollar ;) | Elle: I'll look into it :) | Floren ...\n",
      "HUMAN: Patricia recommends a fair-trade brand she talked about to Florence and Elle.\n",
      "MODEL: Margaret sends a picture of a new high price of the land. The price is good.    The price will look good. Margaret will look at it soon. Marga will look for it. Margot will look forward to the price. Margaire will look if it's cheap. Margery will look on it.  Margaret. Margaux will look it on the price of her own. Margal. Margeline's opinion on the market. Margaret. They will try to find something nice. Marger.  They will look. Margine will look over the price, but they will look\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qualitative_samples(\n",
    "    df=val_df,\n",
    "    model=model,\n",
    "    encoder_tokenizer=bert_tokenizer,\n",
    "    decoder_tokenizer=gpt_tokenizer,\n",
    "    device=device,\n",
    "    max_source_len=MAX_SOURCE_LEN,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    source_prefix=\"\",  # No prefix for BERT-GPT2\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f7de4",
   "metadata": {},
   "source": [
    "## 13. Save Model + Tokenizers\n",
    "\n",
    "Matches your README exactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88f3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: /home/timnevits/projects/flatiron-language-models-for-ai/models/bert-gpt2\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = PROJECT_ROOT / \"models\" / \"bert-gpt2\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(SAVE_DIR)\n",
    "bert_tokenizer.save_pretrained(SAVE_DIR)\n",
    "gpt_tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(\"Model saved to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e1435",
   "metadata": {},
   "source": [
    "# Key Takeaways for Experiment-1\n",
    "\n",
    "This section will be finished after training, but expected themes:\n",
    "\n",
    "- Cross-attention warm-up stabilizes training  \n",
    "- ROUGE improves slowly but plateaus early  \n",
    "- Model tends to produce chatty, narrative summaries  \n",
    "- Strong evidence this architecture is sub-optimal compared to BART/T5  \n",
    "\n",
    "This notebook demonstrates the feasibility and limitations of a hand-assembled encoder‚Äìdecoder system versus pretrained seq2seq models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
